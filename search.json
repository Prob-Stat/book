[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "確率・統計入門",
    "section": "",
    "text": "前書き\nこれは確率論と統計学の入門書である。 確率論を数学的に取り扱うには通常は測度論とルベーグ積分を用いる。 本書では測度論を学ぶ前の数学専攻の学生を対象に確率論と統計学の基礎を解説する。 測度論とルベーグ積分を省略するため、しばしば積分と極限の交換などの等式を証明なしに用いる。 後で測度論を学んだ後にぜひ振り返って欲しい。",
    "crumbs": [
      "前書き"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  はじめに",
    "section": "",
    "text": "1.1 なぜ確率論と統計学を学ぶか？\nThis is a book created from markdown and executable code.",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "intro.html#本書の構成",
    "href": "intro.html#本書の構成",
    "title": "1  はじめに",
    "section": "1.2 本書の構成",
    "text": "1.2 本書の構成",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "intro.html#その他の参考文献",
    "href": "intro.html#その他の参考文献",
    "title": "1  はじめに",
    "section": "1.3 その他の参考文献",
    "text": "1.3 その他の参考文献",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>はじめに</span>"
    ]
  },
  {
    "objectID": "sets.html",
    "href": "sets.html",
    "title": "2  集合論",
    "section": "",
    "text": "2.1 集合\n集合は対象の集まりである。例えば \\[\\begin{align*}\nA&=\\{1,2,3\\},& B&=\\{赤,青,黄,緑\\}\n\\end{align*}\\] のように表す。 集合を構成するものを要素もしくは元という。\nを表す。\n\\(|A|\\) で集合 \\(A\\) の要素数を表すことにする。 要素数が無限の集合を考えることもできる。 例えば \\[\\begin{align*}\nA&=\\{n\\in\\mathbb{N}\\mid \\text{$n$ は偶数}\\},& B&=\\{x\\in\\mathbb{R}\\mid \\text{$x$ は無理数} \\}\n\\end{align*}\\]\nという集合は無限集合の例となる。 何も要素を持たない集合(要素数が零の集合)を空集合といい、\\(\\varnothing\\) で表す。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "sets.html#集合",
    "href": "sets.html#集合",
    "title": "2  集合論",
    "section": "",
    "text": "\\(x\\in A\\) で要素 \\(x\\) は集合 \\(A\\) に含まれる\n\\(x\\notin A\\) で要素 \\(x\\) は集合 \\(A\\) に含まれない",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "sets.html#集合の関係",
    "href": "sets.html#集合の関係",
    "title": "2  集合論",
    "section": "2.2 集合の関係",
    "text": "2.2 集合の関係\n集合 \\(A\\) の要素がすべて集合 \\(B\\) に含まれるとき、\\(A\\) を \\(B\\) の部分集合 という。 部分集合に関連する集合関係について記号を以下のように定義する。 \\[\\begin{align*}\nA\\subseteq B &\\defiff \\forall x\\,(x\\in A\\implies x \\in B)&\\text{($A$ は $B$ の部分集合)}\\\\\nA\\supseteq B &\\defiff B\\subseteq A&\\text{($A$ は $B$ の上位集合)}\\\\\nA = B &\\defiff (A\\subseteq B\\land A\\supseteq B)& \\text{($A$ と $B$ は等しい)}\\\\\nA \\ne B &\\defiff \\lnot(A = B)& \\text{($A$ と $B$ は等しくない)}\n\\end{align*}\\]\nまた、 \\[\\begin{align*}\nA\\subsetneq B &\\defiff (A\\subseteq B \\land A\\ne B)&\\text{($A$ は $B$ の真部分集合)}\\\\\nA\\supsetneq B &\\defiff B\\subsetneq A&\\text{($A$ は $B$ の真上位集合)}\n\\end{align*}\\]\nとする。 部分集合や上位集合のような集合間の関係を包含関係という。 集合 \\(A,\\,B\\) について、\\(A\\subseteq B\\) と \\(B\\subseteq A\\) のどちらかが成り立つとき、「\\(A\\) と \\(B\\) の間に包含関係が成り立つ」という。\n包含関係は以下の三条件を満たす。\n\n(反射律) \\(\\quad A\\subseteq A\\).\n(反対称律) \\(\\quad (A\\subseteq B\\land B\\subseteq A) \\iff A = B\\).\n(推移律) \\(\\quad (A\\subseteq B\\land B\\subseteq C)\\implies A\\subseteq C\\).",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "sets.html#集合の演算",
    "href": "sets.html#集合の演算",
    "title": "2  集合論",
    "section": "2.3 集合の演算",
    "text": "2.3 集合の演算\n複数の集合から新しい集合を作る演算がある。 \\[\\begin{align*}\nA\\cup B &\\coloneqq\\left\\{x\\mid x\\in A \\textsf{ または } x \\in B\\right\\}\\qquad\\textsf{(和集合)}\\\\\nA\\cap B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\in B\\right\\}\\qquad\\textsf{(積集合)}\\\\\nA\\setminus B &\\coloneqq \\left\\{x\\mid x\\in A \\textsf{ かつ } x \\notin B\\right\\}\\qquad\\textsf{(差集合)}\n\\end{align*}\\]\nこれらの演算は以下の法則を満たす。\n\n(交換法則) \\(\\quad A\\cup B = B\\cup A, \\quad A\\cap B = B\\cap A\\).\n(結合法則) \\(\\quad (A\\cup B)\\cup C = A\\cup (B\\cup C), \\quad (A\\cap B)\\cap C=A\\cap(B\\cap C)\\).\n(分配法則) \\(\\quad A\\cup(B\\cap C) = (A\\cup B)\\cap (A\\cup C),\\quad A\\cap (B\\cup C) = (A\\cap B)\\cup (A\\cap C)\\).\n(冪等法則) \\(\\quad A \\cup A = A, \\quad A\\cap A = A\\).\n(吸収法則) \\(\\quad A \\cup (A\\cap B) = A, \\quad A\\cap (A\\cup B) = A\\).\n\\(A\\cup \\varnothing = A,\\quad A\\cap\\varnothing = \\varnothing\\).\n\n和集合と積集合は結合法則満たすことから、括弧を使わずに \\(A\\cup B\\cup C\\) と表すことができる。 集合 \\(A\\) と \\(B\\) が \\(A\\cap B=\\varnothing\\) を満たすとき、確率論文脈では、「\\(A\\) と \\(B\\) は排反である」(集合論文脈では「互いに素である」)という。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "sets.html#補集合",
    "href": "sets.html#補集合",
    "title": "2  集合論",
    "section": "2.4 補集合",
    "text": "2.4 補集合\n全体の集合 \\(\\Omega\\) というのが文脈上存在する場合は、 \\[\\begin{align*}\nA^\\mathrm{c} &\\coloneqq \\Omega\\setminus A\\qquad\\textsf{(補集合)}\n\\end{align*}\\]\nと定義する。\n補集合に関連して以下の法則が成り立つ。\n\n\\(\\Omega^\\mathrm{c} = \\varnothing,\\quad \\varnothing^\\mathrm{c} = \\Omega\\).\n\\(A\\cup \\Omega = \\Omega,\\quad A\\cap\\Omega = A\\).\n\\(A\\cup A^\\mathrm{c} = \\Omega,\\quad A\\cap A^\\mathrm{c} =\\varnothing\\).\n(二重補集合の法則) \\(\\quad (A^\\mathrm{c})^\\mathrm{c} = A\\).\n(ド・モルガンの法則) \\(\\quad(A\\cup B)^\\mathrm{c} = A^\\mathrm{c} \\cap B^\\mathrm{c},\\quad(A\\cap B)^\\mathrm{c} = A^\\mathrm{c} \\cup B^\\mathrm{c}\\)",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "sets.html#集合族",
    "href": "sets.html#集合族",
    "title": "2  集合論",
    "section": "2.5 集合族",
    "text": "2.5 集合族\n集合 \\(\\Omega\\) について \\(2^\\Omega\\) を \\(\\Omega\\) のすべての部分集合からなる集合を表す。 \\[\\begin{align*}\n2^\\Omega &\\coloneqq \\left\\{A\\subseteq\\Omega\\right\\}.\n\\end{align*}\\]\nこれを \\(\\Omega\\) の冪集合という。 例えば \\(\\Omega=\\{1,2,3\\}\\) のとき、\n\\[\n2^\\Omega = \\left\\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\},\\{2,3\\},\\{1,3\\},\\{1,2,3\\}\\right\\}\n\\]\nである。 \\(\\Omega\\) が有限集合のとき、\\(|2^\\Omega|=2^{|\\Omega|}\\) が成り立つ。 また、\\(2^\\Omega\\) の部分集合を \\(\\Omega\\) 上の(部分)集合族と呼ぶ。 集合 \\(\\Lambda\\) の各 \\(\\lambda\\in\\Lambda\\) に対して集合 \\(A_\\lambda\\subseteq\\Omega\\) が存在するとき、集合族\n\\[\n\\left\\{A_\\lambda\\subseteq\\Omega\\mid \\lambda\\in\\Lambda\\right\\}\\subseteq 2^\\Omega\n\\]\nを添字集合 \\(\\Lambda\\) で添字付けられた \\(\\Omega\\) 上の集合族という。 添字集合が有限集合の場合は集合族全体の和集合や積集合は二つの集合の和集合と積集合の定義を繰り返し用いることで定義できる。 それらは以下のように表す。\n\\[\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda \\quad,\\quad\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda.\n\\]\n添字集合 \\(\\Lambda\\) が無限集合の場合は和集合と積集合を以下で定義する。 \\[\\begin{align*}\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\exists \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\\\\\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\n&\\coloneqq\n\\left\\{x\\in\\Omega\\mid \\forall \\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right\\}\n\\end{align*}\\]\nこの定義は \\(\\Lambda\\) が有限集合の場合も正しいものである。 この場合もド・モルガンの法則は成り立つ。つまり、 \\[\\begin{align*}\n\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c}\\\\\n\\left(\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&=\n\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda^\\mathrm{c}\n\\end{align*}\\]\nが成り立つ。\n証明: \\(x\\in\\Omega\\) について、 \\[\\begin{align*}\nx\\in\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)^\\mathrm{c}\n&\\iff x\\notin\\left(\\bigcup_{\\lambda\\in\\Lambda} A_\\lambda\\right)\\\\\n&\\iff \\lnot\\left(\\exists\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda\\right)\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\notin A_\\lambda\\\\\n&\\iff \\forall\\lambda\\in\\Lambda,\\quad x\\in A_\\lambda^\\mathrm{c}\\\\\n&\\iff x\\in\\bigcap_{\\lambda\\in\\Lambda} A_\\lambda^{\\mathrm{c}}.\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>集合論</span>"
    ]
  },
  {
    "objectID": "prob-space.html",
    "href": "prob-space.html",
    "title": "3  確率空間",
    "section": "",
    "text": "3.1 確率論を数学的に定式化するには\n確率は身近に現れる(感じられる)ものであるが、それを数学的に定式化することは自明な問題ではない。 実際に確率論には複数の数学的定式化が存在する。 その中で圧倒的に一般的なのが測度論的確率論と呼ばれる定式化である。 測度というのは集合の「面積」のようなものであり、確率を測度と捉えるのが測度論的確率論である。 これは多くの人間の直感にも自然なものであろう。\nまず、確率を考える集合について考えよう。 例えばコインを投げて表もしくは裏が出る確率を考えたいときは \\[\n\\Omega = \\{\\mathrm{H},\\,\\mathrm{T}\\}\n\\] という集合になる。 また、明日の天気の確率を考えたいときは \\[\n\\Omega = \\{\\text{\"晴\"},\\, \\text{\"雨\"},\\, \\text{\"雪\"}\\}\n\\] という集合になるだろう。 この \\(\\Omega\\) の部分集合に確率を与える関数 \\(P\\colon 2^\\Omega\\to\\mathbb{R}\\) を定義しよう。 偏りのないコインの場合は以下のようになる。 \\[\\begin{align*}\nP(\\varnothing) &= 0,& P(\\{\\mathrm{H}\\}) &= \\frac12,&\nP(\\{\\mathrm{T}\\}) &= \\frac12,& P(\\{\\mathrm{H},\\,\\mathrm{T}\\}) &= 1.\n\\end{align*}\\] また、天気の場合は例えば以下のようになる。 \\[\\begin{align*}\nP(\\varnothing)&=0,& P(\\{晴\\})&=0.7,& P(\\{雨\\})&=0.2,& P(\\{雪\\})&=0.1\\\\\nP(\\{晴,雨\\})&=0.9,& P(\\{雨,雪\\})&=0.3,& P(\\{雪,晴\\})&=0.8,&P(\\{晴,雨,雪\\})&=1.\n\\end{align*}\\]\nこのように集合 \\(\\Omega\\) の部分集合に確率を与えることを考える。 \\(\\Omega\\) の要素一つずつに確率を与えれば十分であるようにも思えるが、\\(\\Omega\\) が連続的な場合には \\(\\Omega\\) の一つの要素の確率は 0 になってしまうことが多い。 例えば明日の正午の気温が \\(10\\pi \\,{}^\\circ\\mathrm{C}\\) になる確率は 0 であろう。 そのため、\\(\\Omega\\) の要素ではなく部分集合に確率を与えることにする。 そのために測度論が適しているわけである。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "prob-space.html#有限集合上の確率空間",
    "href": "prob-space.html#有限集合上の確率空間",
    "title": "3  確率空間",
    "section": "3.2 有限集合上の確率空間",
    "text": "3.2 有限集合上の確率空間\n確率を考える集合を \\(\\Omega\\) とする。 この \\(\\Omega\\) のことを標本空間という。 また、\\(\\Omega\\) の部分集合のことを事象という。 そして、事象に確率を与える関数 \\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) を確率測度という。 確率測度は以下の条件を満たす。\n\n\\(P(\\Omega)=1\\).\n\\(\\forall A,\\,B\\subseteq\\Omega,\\quad A\\cap B = \\varnothing \\implies P(A\\cup B) = P(A) + P(B)\\).\n\n一つ目の条件は全体の確率が1であるという意味の条件である。 二つ目の条件は排反な二つの事象の和集合の確率はそれぞれの事象の確率の和であるという意味の条件である。 この二つ目の条件を有限加法性という。 例えば \\[\nP(\\{\\text{\"晴\"}, \\text{\"雨\"}\\}) = P(\\{\\text{\"晴\"}\\}) + P(\\{\\text{\"雨\"}\\})\n\\] という等式は「晴れもしくは雨になる確率 \\(=\\) 晴れになる確率 \\(+\\) 雨になる確率」という意味の等式になる。 よって有限加法性が自然な条件であることが分かるだろう。 また、これらのことから、\\(P\\) は各要素 \\(\\omega\\in\\Omega\\) に対する確率 \\(P(\\{\\omega\\})\\) から一意に定まることが分かる。 この標本空間と確率測度のペア \\((\\Omega,\\, P)\\) を確率空間という。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "prob-space.html#可算無限集合上の確率",
    "href": "prob-space.html#可算無限集合上の確率",
    "title": "3  確率空間",
    "section": "3.3 可算無限集合上の確率",
    "text": "3.3 可算無限集合上の確率\n標本空間 \\(\\Omega\\) が可算無限集合のときも、同様に確率測度を定義することもできるが、ここではより強い以下の条件を考える。\n\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n\\subseteq \\Omega)_{n\\ge 0},\\quad \\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge 0}A_n\\right) = \\sum_{n\\ge 0} P(A_n)\\).\n\nここで二つ目の条件における \\({}_{n\\ge 0}\\) という添字において \\(n\\) は非負整数全体をわたる。 今後もこの記法を用いる。 この二つ目の条件を完全加法性もしくは \\(\\sigma\\)-加法性という。 右辺の無限和において \\(P(A_n)\\ge 0\\) なので、無限和 \\(\\sum_{n\\ge 0} P(A_n)\\) が存在するときこれは絶対収束する。 よって、この無限和は事象列の並び順に依存しないことが分かる。 完全加法性ではなく有限加法性だけを使って確率論を構築する試みもあるが、確率測度の連続性などの性質が失なわれるため 標準的な確率論では完全加法性を課す。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "prob-space.html#すべての部分集合を可測にはできない",
    "href": "prob-space.html#すべての部分集合を可測にはできない",
    "title": "3  確率空間",
    "section": "3.4 すべての部分集合を可測にはできない",
    "text": "3.4 すべての部分集合を可測にはできない\nより一般に \\(\\Omega\\) が非可算無限集合の場合を考えよう。例えば \\(\\Omega = [0, 1)\\) の場合が考えられる。 このとき、すべての \\(A\\subseteq\\Omega\\) に確率を与えることができるのだろうか？ そうすると、ごく自然な性質を持つような確率測度が存在しないことが、選択公理を認めると示される。\n\n定理 3.1 (非可測集合の存在) \\(\\Omega=[0,1)\\) とする。 また、集合の平行移動を \\[\nA+x\\coloneqq\\{a+x-\\lfloor a+x\\rfloor\\mid a\\in A\\}\n\\] と定義する。 このとき、 \\[\n\\forall x\\in\\Omega,\\, A\\subseteq\\Omega,\\quad P(A+x) = P(A)\\qquad\\textsf{(平行移動不変性)}\n\\] を満たす確率測度 \\(P\\colon 2^{[0,1)}\\to \\mathbb{R}_{\\ge 0}\\) は存在しない。\n\n\n証明. \\(\\Omega\\) 上の同値関係を \\(x\\sim y \\stackrel{\\mathrm{def}}{\\iff} x-y\\in\\mathbb{Q}\\) と定義する。 選択公理より、この同値関係の同値類から一つずつ要素を含む集合 \\(V\\) が存在する(Vitali集合)。 任意の \\(x\\in[0, 1)\\) について、ある \\(z\\in V\\) が唯一存在して \\(x\\sim z\\) である。 よって、任意の \\(x\\in[0, 1)\\) について、ある \\(z\\in V\\) と \\(q\\in\\mathbb{Q}\\cap[0,1)\\) が唯一存在して \\(x = z+q-\\lfloor z+q\\rfloor\\) であることから \\[\\begin{align*}\n[0, 1) &= \\bigcup_{q\\in\\mathbb{Q}\\cap[0,1)} (V + q)\n\\end{align*}\\] であり、右辺は互いに排反である。 よって条件を満たす \\(P\\) が存在すると仮定すると、 \\[\\begin{align*}\n1 = P([0, 1)) &= P\\left(\\bigcup_{q\\in\\mathbb{Q}\\cap[0,1)} (V+q)\\right)\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V+q\\right)\\qquad \\textsf{(完全加法性)}\\\\\n&= \\sum_{q\\in\\mathbb{Q}\\cap[0,1)} P\\left(V\\right)\\qquad \\textsf{(平行移動不変性)}\n\\end{align*}\\] ここで \\(P(V)\\) をどのように定めても、それを無限回足して 1 にすることはできない。 よって \\(P\\) は存在しない。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "prob-space.html#確率論の公理",
    "href": "prob-space.html#確率論の公理",
    "title": "3  確率空間",
    "section": "3.5 確率論の公理",
    "text": "3.5 確率論の公理\n定理 3.1 より、\n\n選択公理\n確率測度の完全加法性\n\\([0, 1)\\) 上の平行移動不変な確率測度\n\\(\\Omega\\) のすべての部分集合に確率を与える\n\nのどれかを諦めないといけない。 標準的な確率論では4を諦める。 以下に確率空間の厳密な定義を述べる。\n\n定義 3.1 (完全加法族) \\(\\Omega\\) を集合とする。 \\(\\Omega\\) 上の集合族 \\(\\mathcal{F}\\subseteq 2^\\Omega\\) が以下を満たすとする。\n\n\\(\\Omega\\in\\mathcal{F}\\).\n\\(\\forall A\\in\\mathcal{F},\\quad A^\\mathrm{c} = \\Omega\\setminus A\\in\\mathcal{F}\\).\n\\(\\forall (A_n\\in\\mathcal{F})_{n\\ge 0},\\quad \\bigcup_{n\\ge 0} A_n\\in\\mathcal{F}\\).\n\nこのとき、\\(\\mathcal{F}\\) を \\(\\Omega\\) 上の完全加法族もしくは \\(\\sigma\\)-加法族という。\n\n\n定義 3.2 (確率空間) \\(\\Omega\\) を集合とし、 \\(\\mathcal{F}\\subseteq 2^\\Omega\\) を \\(\\Omega\\) 上の完全加法族とする。\nまた、\\(P\\colon\\mathcal{F}\\to\\mathbb{R}_{\\ge 0}\\) が以下を満たすとする。\n\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n\\in \\mathcal{F})_{n\\ge 0},\\quad \\forall i\\ne j,\\, A_i\\cap A_j=\\varnothing\\implies P\\left(\\bigcup_{n\\ge 0}A_n\\right) = \\sum_{n\\ge 0} P(A_n)\\).\n\nこのとき、\\((\\Omega,\\, \\mathcal{F},\\, P)\\) を確率空間という。 また、\\(\\Omega\\) を標本空間、\\(\\mathcal{F}\\) を事象集合、\\(P\\) を確率測度という。\n\nこのように事象集合 \\(\\mathcal{F}\\) の元についてのみ確率が与えられる。\n\n\n\n\n\n\nノート\n\n\n\nペア \\((\\Omega,\\, \\mathcal{F})\\) を可測空間という。 確率空間 \\((\\Omega,\\, \\mathcal{F},\\, P)\\) から \\(P(\\Omega)=1\\) の条件を除いたものが一般の測度空間である。\n\n\n定理 3.1 の証明では選択公理を用いたが、実際に選択公理を認めないと 定理 3.1 が成立しないことが分かっている。 以降、\\(\\Omega\\) が非可算無限集合である場合も含めて、\\(\\mathcal{F} = 2^\\Omega\\) だと思うことにする。 これは正しくない場合もあるのだが、選択公理を使わない限り矛盾は導かれないので、問題になることはほとんどない。 よって、以降は \\((\\Omega,\\, P)\\) を確率空間とする。\n\\(\\Omega = [0, 1)\\) で任意の \\(0\\le a &lt; b\\le 1\\) について \\(P([a, b)) = b-a\\) であるような確率空間はとても基本的なものである。 今後この性質を満たす確率空間が存在すると仮定して話を進める。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "prob-space.html#確率の性質",
    "href": "prob-space.html#確率の性質",
    "title": "3  確率空間",
    "section": "3.6 確率の性質",
    "text": "3.6 確率の性質\n\n補題 3.1 (確率のいくつかの性質) 確率空間 \\((\\Omega,\\, P)\\) と任意の \\(A,\\,B\\subseteq \\Omega\\) について以下が成り立つ。\n\n\\(P(A^\\mathrm{c}) = 1 - P(A)\\).\n\\(B\\subseteq A\\implies P(B)\\le P(A)\\)\n\\(P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\\).\n\\(P(A\\cup B) \\le P(A) + P(B)\\qquad\\) (ブールの不等式、union bound).\n\n\n\n証明. \n\n\\[\n1 = P(\\Omega) = P(A \\cup A^\\mathrm{c}) = P(A) + P(A^\\mathrm{c}).\n\\]\n\\[\nP(A) = P(B\\cup (A\\setminus B)) = P(B) + P(A\\setminus B) \\ge P(B).\n\\]\n\\[\\begin{align*}\nP(A\\cup B) &= P(A \\cup (B\\setminus A)) = P(A) + P(B\\setminus A)\\\\\nP(B) &= P((B\\setminus A) \\cup (A\\cap B)) = P(B\\setminus A) + P(A\\cap B)\n\\end{align*}\\] より、 \\(P(B\\setminus A)\\) を消去することで得られる。\n3 より自明\n\n\n\n補題 3.2 (ユニオンバウンド) 確率空間 \\((\\Omega,\\, P)\\) と \\((A_n\\subseteq\\Omega)_{n\\ge 0}\\) について、 \\[\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) \\le \\sum_{n\\ge 0} P(A_n).\n\\]\n\n\n証明. \\(B_0 \\coloneqq A_0\\), \\(B_n \\coloneqq A_n \\setminus \\bigcup_{k=0}^{n-1} A_k\\) とおくと、\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) &= P\\left(\\bigcup_{n\\ge 0} B_n\\right)\\\\\n&= \\sum_{n\\ge 0} P\\left(B_n\\right)\\\\\n&\\le \\sum_{n\\ge 0} P\\left(A_n\\right).\n\\end{align*}\\]\n\n\n定理 3.2 (確率測度の連続性) 確率空間 \\((\\Omega,\\, P)\\) と事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について \\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\] また、事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) について \\[\\begin{align*}\nP\\left(\\bigcap_{n\\ge 0} A_n\\right) = \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\]\n\n\n証明. 事象列 \\(A_0\\subseteq A_1\\subseteq \\dotsb \\subseteq \\Omega\\) について考える。 \\(B_0\\coloneqq A_0\\), \\(n\\ge 1\\)について\\(B_n\\coloneqq A_n\\setminus A_{n-1}\\)とおく。 このとき、\\(i\\ne j\\)について \\(B_i\\cap B_j=\\varnothing\\)。 また \\(k\\ge 0\\) について、\\(\\bigcup_{n=0}^k B_n = \\bigcup_{n=0}^kA_n = A_k\\) が成り立つ.\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A_n\\right)&= P\\left(\\bigcup_{n\\ge 0} B_n\\right) =\\sum_{n\\ge 0} P(B_n)\\\\\n&=\\lim_{k\\to\\infty} \\sum_{n=0}^k P(B_n)\n=\\lim_{k\\to\\infty} P\\left(\\bigcup_{n=0}^k B_n\\right)\n=\\lim_{k\\to\\infty} P(A_k).\n\\end{align*}\\]\n事象列 \\(\\Omega\\supseteq A_0\\supseteq A_1\\supseteq \\dotsb\\) について考える。 このとき、 \\(A'_n \\coloneqq A_n^\\mathrm{c}\\) とおくと、\\(A'_0\\subseteq A'_1\\subseteq \\dotsb \\subseteq \\Omega\\) を満たす。 よって、\n\\[\\begin{align*}\nP\\left(\\bigcup_{n\\ge 0} A'_n\\right) &= \\lim_{n\\to\\infty} P(A'_n)\n\\end{align*}\\]\nである。ド・モルガンの公式より、\n\\[\\begin{align*}\nP\\left(\\left(\\bigcap_{n\\ge 0} A_n\\right)^\\mathrm{c}\\right) &= \\lim_{n\\to\\infty} P(A^\\mathrm{c}_n)\\\\\n\\iff 1-P\\left(\\bigcap_{n\\ge 0} A_n\\right) &= \\lim_{n\\to\\infty} \\bigl( 1-P(A_n)\\bigr)\\\\\n\\iff P\\left(\\bigcap_{n\\ge 0} A_n\\right) &= \\lim_{n\\to\\infty} P(A_n).\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>確率空間</span>"
    ]
  },
  {
    "objectID": "rv.html",
    "href": "rv.html",
    "title": "4  確率変数と確率分布",
    "section": "",
    "text": "4.1 確率変数\n確率空間の上の様々な部分集合の確率を調べたい。 そのためには確率変数を導入すると便利である。\n任意の関数 \\(f\\colon \\mathbb{R}\\to\\mathbb{R}\\) について \\(f\\circ X\\) は確率変数である。 このとき、\\(\\Pr(f\\circ X \\in A)\\) と書く代わりに \\(\\Pr(f(X)\\in A)\\) と書く。\n共通の確率空間 \\((\\Omega,\\, P)\\) 上の確率変数 \\(X,\\,Y\\) についてその和 \\(X + Y\\) や積 \\(XY\\) も確率変数である。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "rv.html#確率変数",
    "href": "rv.html#確率変数",
    "title": "4  確率変数と確率分布",
    "section": "",
    "text": "定義 4.1 (確率変数) 確率空間 \\((\\Omega,\\, P)\\) について、 関数 \\(X\\colon \\Omega\\to\\mathbb{R}\\) を確率変数という。\nまた、任意の \\(A\\subseteq\\mathbb{R}\\) について \\[\n\\Pr(X\\in A) \\coloneqq P(\\{\\omega\\in\\Omega\\mid X(\\omega)\\in A\\})\n\\] と定義する。 さらに、任意の \\(a\\in\\mathbb{R}\\) について \\[\n\\Pr(X\\ge a) \\coloneqq P(X\\in \\{x\\in\\mathbb{R}\\mid x\\ge a\\}) = P(\\{\\omega\\in\\Omega\\mid X(\\omega)\\ge a\\})\n\\] と定義する。 同様に \\(\\Pr(X &gt; a),\\, \\Pr(X \\le a),\\, \\Pr(X &lt; a),\\, \\Pr(X = a)\\) なども定義される。\n\n\n\n\n\n\n\nノート\n\n\n\n本当の確率論では確率変数は「確率空間から位相空間への写像で開集合の逆像が可測集合になるような関数」として定義される。 また、文献によっては確率変数は「確率空間から可測空間への写像で可測集合の逆像が可測集合になるような関数」として定義されることもある。 開集合族が生成する完全加法族をボレル集合族と呼ぶが、この方法で位相空間から可測空間を作ることができる。 そうすると前者の定義は「確率空間から位相空間への写像でボレル集合の逆像が可測集合になるような関数」と等価なので、後者の定義に含まれる。 後者の定義の中の可測空間が位相空間由来のものに限定したのが前者の定義であると言える。\n\n\n\n\n\n\n\n\n\nノート\n\n\n\n本当の確率論の言葉で述べると任意のボレル関数(開集合(ボレル集合としても等価)の逆像がボレル集合となる関数) \\(f\\) について \\(f\\circ X\\) は確率変数である。\n\n\n\n\n例 4.1 (コイン投げ) コインを2回独立に投げる場合の確率空間 \\((\\Omega,\\,P)\\) を以下で定義する。\n\n\\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\).\n\\(P(A) = \\frac{|A|}{4}\\).\n\n確率変数 \\(X_1\\) と \\(X_2\\) を \\[\\begin{align*}\nX_1(\\mathrm{HH}) &= 1&\nX_1(\\mathrm{HT}) &= 1&\nX_1(\\mathrm{TH}) &= 0&\nX_1(\\mathrm{TT}) &= 0\\\\\nX_2(\\mathrm{HH}) &= 1&\nX_2(\\mathrm{HT}) &= 0&\nX_2(\\mathrm{TH}) &= 1&\nX_2(\\mathrm{TT}) &= 0\n\\end{align*}\\] とすると、\\(k\\in\\{1,2\\}\\) について、\\(X_k\\) は \\(k\\) 回目のコイン投げが表だったときに1、裏だったときに0になる。 また、\\(X=X_1+X_2\\) は表が出た回数を表す確率変数となる。 表が一回以上出る確率は以下のように表せる。 \\[\\begin{align*}\n\\Pr(X\\ge 1) &= P(\\{\\omega\\in\\Omega\\mid X(\\omega)\\ge 1\\}) = P(\\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH}\\}) = \\frac{3}{4}.\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "rv.html#確率分布",
    "href": "rv.html#確率分布",
    "title": "4  確率変数と確率分布",
    "section": "4.2 確率分布",
    "text": "4.2 確率分布\n\n定義 4.2 (累積分布関数) 確率変数 \\(X\\) について累積分布関数 \\(F_X\\colon\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) は以下で定義される。\n\\[\nF_X(x) \\coloneqq \\Pr(X\\le x)\\qquad\\forall x\\in\\mathbb{R}.\n\\]\n\n累積分布関数は定義より単調非減少関数であることが分かる。 累積分布関数は連続とは限らないが右連続であることは以下のように確認できる。\n\\[\\begin{align*}\n\\lim_{n\\to\\infty} \\Pr\\left(X \\le x + \\frac1n\\right) &=\n\\lim_{n\\to\\infty} P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\bigcap_{n=0}^\\infty \\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x + \\frac1n\\right\\}\\right)\\\\\n&= P\\left(\\left\\{\\omega\\in\\Omega\\mid X(\\omega) \\le x\\right\\}\\right)\\\\\n&= \\Pr\\left(X\\le x\\right).\n\\end{align*}\\]\n累積分布関数 \\(F_X\\colon\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) は以下の性質を持つ。\n\n\\(F_X\\) は単調非減少。\n\\(F_X\\) は右連続。\n\\(\\lim_{x\\to\\infty}F_X(x) = 1\\).\n\\(\\lim_{x\\to-\\infty}F_X(x) = 0\\).\n\n確率変数 \\(X\\) の像が高々可算集合のとき、\\(X\\) を離散型確率変数という。 離散型確率変数でない確率変数を連続型確率変数という。\n\\(X\\) が離散型確率変数のとき、\\(A\\) を \\(X\\) の像の部分集合とすると\n\\[\\begin{align*}\n\\Pr(X\\in A) &= P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)\\in A\\}\\right)\\\\\n&= P\\left(\\bigcup_{x\\in A} \\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega)=x\\}\\right)\\\\\n&= \\sum_{x\\in A} \\Pr\\left(X=x\\right)\n\\end{align*}\\]\nであるので、\n\\[\nf_X(x) \\coloneqq \\Pr(X=x) \\qquad \\forall x\\in\\mathbb{R}\n\\]\nという関数を用いて \\[\n\\Pr(X\\in A) = \\sum_{x\\in A} f_X(x)\n\\] と表せる。 この \\(f_X(x)\\) を \\(X\\) の確率質量関数という。\n\\(X\\) が連続型確率変数のとき、\n\\[\\begin{align*}\n\\Pr(X\\in A) &= \\int_{A} f_X(x) \\mathrm{d}x\\qquad\\forall A\\subseteq\\mathbb{R}\n\\end{align*}\\]\nを満たす \\(f_X\\colon\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が存在するとき、この \\(f_X(x)\\) を \\(X\\) の確率密度関数という。 しかし、確率密度関数は常に存在するとは限らない。\n\n例 4.2 \\(\\Omega = [0, 1)\\)とし、\\(P\\colon 2^\\Omega\\to\\mathbb{R}_{\\ge 0}\\) を \\(P([a, b)) = b-a\\) を満たす確率測度とする。 確率空間 \\((\\Omega,\\, P)\\) 上の確率変数 \\(X\\colon [0,1)\\to\\mathbb{R}\\) を \\[\nX(\\omega) =\n\\begin{cases}\n2\\omega& \\text{if }\\omega &lt; \\frac12\\\\\n\\frac12& \\text{otherwise.}\n\\end{cases}\n\\] と定義する。\nこの時 \\(X\\) の像は \\([0,1)\\) であるので \\(X\\) は連続型確率変数である。\nまた、\\(\\Pr(X=\\frac12) = P([\\frac12, 1)\\cup\\{\\frac14\\}) = \\frac12\\) である。 よって \\(X\\) の確率密度関数は存在しない。\n\n連続確率変数 \\(X\\) が確率密度関数を持つとき、\n\\[\nF_X(x) = \\int_{-\\infty}^x f_X(z) \\mathrm{d}z\n\\]\nという関係が成り立つ。 よって累積分布関数が微分可能なときは\n\\[\nf_X(x) = \\frac{\\mathrm{d}F_X}{\\mathrm{d}x}\n\\]\nとおいても構わない。確率密度関数はその積分値にのみ意味を持つ。そのため確率密度関数は一意には定まらない。\n例 4.2 の確率変数 \\(X\\) の累積分布関数は以下のようになる。\n\n\nコード\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# xの範囲を定義（-1から2までを細かく分けて計算）\nx = np.linspace(-0.5, 1.5, 1000)\n\n# 区間ごとの関数定義\ny = np.piecewise(\n    x,\n    [x &lt; 0,\n     (0 &lt;= x) & (x &lt; 0.5),\n     (0.5 &lt;= x) & (x &lt; 1),\n     x &gt;= 1],\n    [0,\n     lambda x: x / 2,\n     lambda x: x / 2 + 0.5,\n     1]\n)\n\n# グラフの描画\nplt.figure(figsize=(8, 5))\nplt.plot(x, y, label='$F_X(x)$', color='blue')\nplt.title('CDF of $X$')\nplt.xlabel('$x$')\nplt.ylabel('$F_X(x)$')\nplt.grid(True)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\n\n# x = 1/2 の左極限（穴あき）\nx_left = 0.5 - 1e-5  # 少しだけ左\ny_left = x_left / 2\nplt.plot(0.5, y_left, 'o', color='white', markeredgecolor='blue', markersize=8)\n\n# x = 1/2 の値（右からの定義値）\ny_right = 0.5 / 2 + 0.5\nplt.plot(0.5, y_right, 'o', color='blue', markersize=6)\n\nplt.show()\n\n\n\n\n\n\n\n\n図 4.1: \\(X\\)の累積分布関数",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "rv.html#離散確率分布の例",
    "href": "rv.html#離散確率分布の例",
    "title": "4  確率変数と確率分布",
    "section": "4.3 離散確率分布の例",
    "text": "4.3 離散確率分布の例\n\n4.3.1 様々な離散確率分布\n\n二項分布 \\(\\mathrm{Binom}(n,p)\\): 表が出る確率が \\(p\\) のコインを \\(n\\) 回独立に投げたとき、表が出る回数の分布 \\[\\Pr(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}.\\]\n幾何分布: 表が出るまでに投げるコインの回数の分布 \\[\\Pr(X=k) = (1-p)^{k-1}p.\\]\n超幾何分布: 袋の中に \\(N\\) 個のボールがあって、そのうち \\(K\\) 個が当たりとし、 \\(n\\) 個引いたときの当たりの個数の分布 \\[\\Pr(X=k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}.\\]\nポアソン分布: \\[\n\\Pr(X=k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda}.\n\\]\n\n\n\n4.3.2 二項分布\n二項分布の確率質量関数は\n\\[\nf_X(k) = \\binom{n}{k} p^k(1-p)^{n-k}\n\\]\n\nコード\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import binom\n\n# パラメータの設定\nn = 12       # 試行回数\np = 0.6      # 成功確率\n\n# 取りうる値の範囲\nx = np.arange(0, n+1)\n\n# 二項分布のPMFの計算\npmf = binom.pmf(x, n, p)\ncdf = binom.cdf(x, n, p)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.bar(x, pmf, tick_label=x)\nplt.title(f'PMF of binomial distribution with n={n}, p={p}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X=k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.step(x, cdf, where='post')\nplt.xticks(x)\nplt.title(f'CDF of binomial distribution with n={n}, p={p}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X\\\\leq k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.2: 二項分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.3: 二項分布の累積分布関数\n\n\n\n\n\n\n\n\n4.3.3 幾何分布\n\\[\nf_X(k) = (1-p)^{k-1}p,\\qquad\\forall k\\ge 1\n\\]\n\nコード\nimport numpy as np\nfrom scipy.stats import geom\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\nn = 12       # 試行回数\np = 0.6      # 成功確率\n\n# 取りうる値の範囲\nk = np.arange(1, n+1)\nkk = np.arange(0, n+1)\n\n# 幾何分布のPMFの計算\npmf = geom.pmf(k, p)\ncdf = geom.cdf(kk, p)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.bar(k, pmf, tick_label=k)\nplt.title(f'PMF of geometric distribution with p={p}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X=k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.step(kk, cdf, where='post')\nplt.xticks(kk)\nplt.title(f'CDF of geometric distribution with p={p}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X\\\\leq k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.4: 幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.5: 幾何分布の累積分布関数\n\n\n\n\n\n\n\n\n4.3.4 超幾何分布\n\\[\nf_X(k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}},\\qquad\\forall k\\in \\{0,\\dotsc,\\min\\{K, n\\}\\}\n\\]\n\nコード\nimport numpy as np\nfrom scipy.stats import hypergeom\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\nN = 40\nn = 16\nK = 12\n\n# 取りうる値の範囲\nk = np.arange(0, K+1)\n\n# 超幾何分布のPMFの計算\npmf = hypergeom.pmf(k, N, K, n)\ncdf = hypergeom.cdf(k, N, K, n)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.bar(k, pmf, tick_label=k)\nplt.title(f'PMF of hypergeometric distribution with K={K}, N={N}, n = {n}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X=k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.step(k, cdf, where='post')\nplt.xticks(k)\nplt.title(f'CDF of hypergeometric distribution with K={K}, N={N}, n = {n}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X\\\\leq k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.6: 超幾何分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.7: 超幾何分布の累積分布関数\n\n\n\n\n\n\n\n\n4.3.5 ポアソン分布\n\\[\nf_X(k) = \\frac{\\lambda^k}{k!}\\mathrm{e}^{-\\lambda},\\qquad \\forall k\\ge 0\n\\]\n\nコード\nimport numpy as np\nfrom scipy.stats import poisson\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\nlam = 5\n\n# 取りうる値の範囲\nk = np.arange(0, 3*lam)\n\n# ポアソン分布のPMFの計算\npmf = poisson.pmf(k, lam)\ncdf = poisson.cdf(k, lam)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.bar(k, pmf, tick_label=k)\nplt.title(f'PMF of Poisson distribution with $\\\\lambda$={lam}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X=k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.step(k, cdf, where='post')\nplt.xticks(k)\nplt.title(f'CDF of Poisson distribution with $\\\\lambda$={lam}')\nplt.xlabel('$k$')\nplt.ylabel('$\\\\Pr(X\\\\leq k)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.8: ポアソン分布の確率質量関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.9: ポアソン分布の累積分布関数\n\n\n\n\n\n\n\n\n4.3.6 確率空間は何か？\n確率変数が従う確率分布のみに注目した議論をする場合、確率空間を陽に考えないことがしばしばある。\n\n二項分布: \\(n\\) 回のコイン投げ、もしくは無限回のコイン投げ。\n幾何分布: 無限回のコイン投げ。\n超幾何分布: \\(K\\) 個の当たりと \\(N-K\\) 個のはずれのボールの \\(\\binom{N}{K}\\) 通りの並び順。\nポアソン分布: ？",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "rv.html#連続確率分布の例",
    "href": "rv.html#連続確率分布の例",
    "title": "4  確率変数と確率分布",
    "section": "4.4 連続確率分布の例",
    "text": "4.4 連続確率分布の例\n\n一様分布\n正規分布\n指数分布\n\n\n4.4.1 一様分布\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n\\frac1{b-a}& \\text{if } x\\in[a,b]\\\\\n0&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; a\\\\\n\\frac{x-a}{b}&\\text{if } x \\in[a,b]\\\\\n1&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\n\nコード\nimport numpy as np\nfrom scipy.stats import uniform\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\n\n# 取りうる値の範囲\n#x = np.linspace(uniform.ppf(0.01), uniform.ppf(0.99), 100)\nx = np.linspace(-0.1, +1.1, 1000)\n\n# 一様分布のPMFの計算\npdf = uniform.pdf(x)\ncdf = uniform.cdf(x)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.plot(x, pdf)\nplt.title(f'PDF of Uniform distribution on $[0,1]$')\nplt.xlabel('$x$')\nplt.ylabel('$f_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.plot(x, cdf)\nplt.title(f'CDF of Uniform distribution on $[0,1]$')\nplt.xlabel('$x$')\nplt.ylabel('$F_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.10: 一様分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.11: 一様分布の累積分布関数\n\n\n\n\n\n\n\n\n4.4.2 正規分布 (ガウス分布)\n\\[\\begin{align*}\nf_X(x) &= \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},&\nF_X(x) &= \\int_{-\\infty}^x \\frac1{\\sqrt{2\\pi\\sigma^2}}\\mathrm{e}^{-\\frac{(z-\\mu)^2}{2\\sigma^2}}\\mathrm{d}z\n\\end{align*}\\]\n特に \\(\\mu=0\\), \\(\\sigma=1\\) のとき標準正規分布という。\n\nコード\nimport numpy as np\nfrom scipy.stats import norm\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\n\n# 取りうる値の範囲\nx = np.linspace(norm.ppf(0.001), norm.ppf(0.999), 100)\n\n# 一様分布のPMFの計算\npdf = norm.pdf(x)\ncdf = norm.cdf(x)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.plot(x, pdf)\nplt.title(f'PDF of normal distribution with $\\\\mu = 0$ and $\\\\sigma = 1$')\nplt.xlabel('$x$')\nplt.ylabel('$f_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.plot(x, cdf)\nplt.title(f'CDF of normal distribution with $\\\\mu = 0$ and $\\\\sigma = 1$')\nplt.xlabel('$x$')\nplt.ylabel('$F_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.12: 標準正規分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.13: 標準正規分布の累積分布関数\n\n\n\n\n\n\n\n\n4.4.3 指数分布\n\\[\\begin{align*}\nf_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n\\lambda\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases},&\nF_X(x) &= \\begin{cases}\n0&\\text{if } x &lt; 0\\\\\n1-\\mathrm{e}^{-\\lambda x}&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\]\n\nコード\nimport numpy as np\nfrom scipy.stats import expon\nimport matplotlib.pyplot as plt\n\n# パラメータの設定\n\n# 取りうる値の範囲\nx = np.linspace(expon.ppf(0.001), expon.ppf(0.999), 100)\n\n# PMFの計算\npdf = expon.pdf(x)\ncdf = expon.cdf(x)\n\n# プロット\nplt.figure(figsize=(4, 2))\nplt.plot(x, pdf)\nplt.title(f'PDF of exponential distribution with $\\\\lambda = 1$')\nplt.xlabel('$x$')\nplt.ylabel('$f_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\nplt.figure(figsize=(4, 2))\nplt.plot(x, cdf)\nplt.title(f'CDF of exponential distribution with $\\\\lambda = 1$')\nplt.xlabel('$x$')\nplt.ylabel('$F_X(x)$')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n図 4.14: 指数分布の確率密度関数\n\n\n\n\n\n\n\n\n\n\n\n図 4.15: 指数分布の累積分布関数",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "rv.html#確率密度関数",
    "href": "rv.html#確率密度関数",
    "title": "4  確率変数と確率分布",
    "section": "4.5 確率密度関数",
    "text": "4.5 確率密度関数\n\n補題 4.1 確率変数 \\(X\\) について、 \\[\\begin{align*}\nf_{X+a}(x) &= f_X(x-a)\\qquad\\forall a\\in\\mathbb{R}\\\\\nf_{aX}(x) &= \\frac1{|a|} f_X(x/a)\\qquad\\forall a\\in\\mathbb{R}_{\\ne 0}\n\\end{align*}\\] はそれぞれ \\(X+a\\) と \\(aX\\) の確率密度関数になる。\n\n\n証明. 関数 \\(f_Z\\colon \\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) が\n\\[\n\\Pr(Z\\le x) = \\int_{-\\infty}^x f_Z(z)\\mathrm{d} z\n\\]\nを満たすとき、\\(f_Z\\) は確率変数 \\(Z\\) の確率密度関数となる。\n任意の \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X+a\\le x) &= \\Pr(X\\le x-a)\\\\\n&= \\int_{-\\infty}^{x-a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} f_{X}(z'-a)\\mathrm{d}z'\\qquad (z'=z+a).\n\\end{align*}\\] 任意の \\(a&gt;0\\) について、 \\[\\begin{align*}\n\\Pr(aX\\le x) &= \\Pr(X\\le x/a)\\\\\n&= \\int_{-\\infty}^{x/a} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{-\\infty}^{x} \\frac1{a} f_{X}(z'/a)\\mathrm{d}z'\\qquad (z'=az).\n\\end{align*}\\] 任意の \\(a&lt;0\\) について、 \\[\\begin{align*}\n\\Pr(aX\\le x) &= \\Pr(X\\ge x/a)\\\\\n&= \\int_{x/a}^{\\infty} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{x}^{-\\infty} \\frac1{a} f_{X}(z'/a)\\mathrm{d}z'\\qquad (z'=az)\\\\\n&= -\\int_{-\\infty}^{x} \\frac1{a} f_{X}(z'/a)\\mathrm{d}z'.\n\\end{align*}\\]\n\n\n補題 4.2 \\(J\\subseteq\\mathbb{R}\\) を有界とは限らない区間とし、\\(g\\colon J\\to\\mathbb{R}\\) を \\(J\\) の内点で微分可能で \\(g'(x)&gt;0\\) と する。 確率変数 \\(X\\) が \\(\\Pr(X\\in J) = 1\\) を満たし確率密度関数を持つとき、 \\[\\begin{align*}\nf_{g(X)}(x) &=\n\\begin{cases}                                                                                                         \\frac1{g'(g^{-1}(x))} f_X(g^{-1}(x))&\\text{if } x\\in\\mathrm{Image}(g)\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] は \\(g(X)\\) の確率密度関数になる。\n\n\n証明. \\(\\Pr(g(X)\\in\\mathrm{Image}(g)) = 1\\) なので、\\(x\\notin\\mathrm{Image}(g)\\) について \\(f_{g(X)}(x) = 0\\) とおいてよい。\n任意の \\(x\\in\\mathrm{Image}(g)\\) について \\[\\begin{align*}\n\\Pr(g(X)\\le x) &= \\Pr(X\\le g^{-1}(x))\\\\\n&= \\int_{-\\infty}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf J}^{g^{-1}(x)} f_{X}(z)\\mathrm{d}z\\\\\n&= \\int_{\\inf \\mathrm{Image}(g)}^{x} f_{X}(g^{-1}(z')) \\frac1{g'(g^{-1}(z'))}\\mathrm{d}z'\\qquad (z'=g(z))\\\\\n&= \\int_{-\\infty}^{x} f_{g(X)}(z')\\mathrm{d}z'.\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>確率変数と確率分布</span>"
    ]
  },
  {
    "objectID": "multivariate.html",
    "href": "multivariate.html",
    "title": "5  複数の確率変数",
    "section": "",
    "text": "5.1 事象の条件付き確率と独立性\n二つの事象 \\(A,B\\subseteq\\Omega\\) を考える文脈では \\(P(A\\cap B)\\) を同時確率、\\(P(A),\\,P(B)\\) を周辺確率という。\n事象 \\(A\\) と \\(B\\) が独立であり、\\(P(B)&gt;0\\) であるとき、\\(P(A\\mid B)=P(A)\\) である。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#事象の条件付き確率と独立性",
    "href": "multivariate.html#事象の条件付き確率と独立性",
    "title": "5  複数の確率変数",
    "section": "",
    "text": "定義 5.1 (条件付き確率) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\(P(B)&gt; 0\\) のとき、\\(B\\) における \\(A\\) の条件付き確率 は以下で定義される。 \\[\\begin{align*}\nP(A\\mid B) &\\coloneqq \\frac{P(A\\cap B)}{P(B)}.\n\\end{align*}\\]\n\n\n\n定義 5.2 (事象の独立性) 確率空間 \\((\\Omega,\\,P)\\) の事象 \\(A,B\\subseteq\\Omega\\) について \\[\\begin{align*}\nP(A\\cap B) &= P(A) P(B)\n\\end{align*}\\] を満たすとき、事象 \\(A\\) と \\(B\\) は独立であるという。\n\n\n例 5.1 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 このとき、\\(A=\\{\\mathrm{HH},\\mathrm{HT}\\},\\,B=\\{\\mathrm{HH},\\mathrm{TH}\\}\\) とおくと、 \\[\\begin{align*}\nP(A\\cap B) &= \\frac14,&P(A)&=P(B)=\\frac12\n\\end{align*}\\] より \\(P(A\\cap B) = P(A)P(B)\\) を満たすことが分かる。 よって事象 \\(A,\\,B\\) は独立である。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#確率変数の条件付き確率と独立性",
    "href": "multivariate.html#確率変数の条件付き確率と独立性",
    "title": "5  複数の確率変数",
    "section": "5.2 確率変数の条件付き確率と独立性",
    "text": "5.2 確率変数の条件付き確率と独立性\n事象は確率変数を通じて表すことが多い。そのため確率変数を用いた条件付き確率も定義する。\n\n定義 5.3 (確率変数) 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) について同時確率を \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\cap\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\quad\\forall A,B\\subseteq\\mathbb{R}\n\\end{align*}\\] と定義する。確率変数が三つ以上の場合も同様に定義する。 また \\(\\Pr(X_2\\in B)&gt;0\\) のとき、条件付き確率は以下で定義する。 \\[\\begin{align*}\n\\Pr(X_1\\in A\\mid X_2\\in B) &\\coloneqq P(\\{\\omega\\in\\Omega\\mid X_1(\\omega)\\in A\\}\\mid\\{\\omega\\in\\Omega\\mid X_2(\\omega)\\in B\\}\\})\\\\\n&=\\frac{\\Pr(X_1\\in A, X_2\\in B)}{\\Pr(X_2\\in B)}\\qquad\\forall A,B\\subseteq\\mathbb{R}.\n\\end{align*}\\] 任意の \\(A,B\\subseteq\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\] を満たすとき、確率変数 \\(X_1\\) と \\(X_2\\) は独立であるという。\n\n\n補題 5.1 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2\\) が独立であるとする。 このとき任意の関数 \\(f_1,\\,f_2\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\\(f_1(X_1),\\,f_2(X_2)\\) は独立である。\n\n\n証明. \\[\\begin{align*}\n\\Pr(f_1(X_1)\\in A,\\,f_2(X_2)\\in B) &=\n\\Pr(X_1\\in f_1^{-1}(A),\\,X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(X_1\\in f_1^{-1}(A))\\Pr(X_2\\in f_2^{-1}(B))\\\\\n&=\\Pr(f_1(X_1)\\in A)\\Pr(f_2(X_2)\\in B).\n\\end{align*}\\]\n\n二つ以上の確率変数の累積分布関数を \\[\\begin{align*}\nF_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n) &\\coloneqq\\Pr(X_1\\le x_1,\\dotsc,X_n\\le x_n)\n\\end{align*}\\] と定義する。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#離散型確率変数と確率質量関数",
    "href": "multivariate.html#離散型確率変数と確率質量関数",
    "title": "5  複数の確率変数",
    "section": "5.3 離散型確率変数と確率質量関数",
    "text": "5.3 離散型確率変数と確率質量関数\n\n定義 5.4 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率質量関数を \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &\\coloneqq \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n\\end{align*}\\] と定義する。\n\n同時確率質量関数からそれぞれの確率変数の確率質量関数が得られる。 \\[\\begin{align*}\nf_{X_1}(x_1) &= \\sum_{x_2} f_{X_1,\\, X_2}(x_1, x_2)\\\\\nf_{X_2}(x_2) &= \\sum_{x_1} f_{X_1,\\, X_2}(x_1, x_2)\n\\end{align*}\\] それぞれの確率変数の確率質量関数を周辺質量関数と呼ぶ。 同時確率質量関数から周辺質量関数を計算する操作のことを周辺化という。\n\n定義 5.5 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1\\), \\(X_2\\) について、条件付き確率質量関数を \\[\\begin{align*}\nf_{X_1\\mid X_2}(x_1\\mid x_2) &\\coloneqq \\Pr(X_1=x_1\\mid X_2=x_2)\n\\end{align*}\\] と定義する。\n\n条件付き確率の定義より \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1\\mid X_2}(x_1\\mid x_2) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。\n\n補題 5.2 確率空間 \\((\\Omega,\\,P)\\) 上の離散型確率変数 \\(X_1, X_2\\) について、 \\(X_1\\) と \\(X_2\\) が独立 \\(\\iff\\) \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n&\\forall x_1\\in\\mathrm{Image}(X_1),x_2\\in\\mathrm{Image}(X_2).\n\\end{align*}\\]\n\n\n証明. \\(\\Longrightarrow\\) は自明。 \\(\\Longleftarrow\\) を示す。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\,X_2\\in B)  &= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1,\\,X_2=x_2)\\\\\n&= \\sum_{x_1\\in A}\\sum_{x_2\\in B} \\Pr(X_1=x_1)\\Pr(X_2=x_2)\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B)\n\\end{align*}\\]\n\n\n例 5.2 (二回のコイン投げ) 標本空間を \\(\\Omega = \\{\\mathrm{HH},\\mathrm{HT},\\mathrm{TH},\\mathrm{TT}\\}\\) とし、確率測度を \\(P(A) = \\frac{|A|}4\\quad\\forall A\\subseteq\\Omega\\) とする。 \\[\\begin{align*}\nX_1(\\mathrm{HH})&=X_1(\\mathrm{HT}) = 1,&\nX_1(\\mathrm{TH})&=X_1(\\mathrm{TT}) = 0\\\\\nX_2(\\mathrm{HH})&=X_2(\\mathrm{TH}) = 1,&\nX_2(\\mathrm{HT})&=X_2(\\mathrm{TT}) = 0\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,\\,x_2) &= \\frac14\\qquad\\forall x_1,x_2\\in\\{0,1\\}\\\\\nf_{X_1}(x_1)=f_{X_2}(x_2)&=\\frac12\\qquad\\forall x_1,x_2\\in\\{0,1\\}\n\\end{align*}\\] より \\(f_{X_1,\\,X_2}(x_1,\\,x_2) = f_{X_1}(x_1)f_{X_2}(x_2)\\) を満たすことが分かる。 よって確率変数 \\(X_1,\\,X_2\\) は独立である。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#連続型確率変数と確率密度関数",
    "href": "multivariate.html#連続型確率変数と確率密度関数",
    "title": "5  複数の確率変数",
    "section": "5.4 連続型確率変数と確率密度関数",
    "text": "5.4 連続型確率変数と確率密度関数\n確率空間 \\((\\Omega,\\,P)\\) 上の連続型確率変数 \\(X_1\\), \\(X_2\\) について、同時確率密度関数を \\[\\begin{align*}\n%\\Pr(\\begin{bmatrix}X_1,\\,X_2\\end{bmatrix}\\in A) &= \\int_A f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\\mathrm{d}x_2\n\\Pr(X_1\\in A,\\,X_2\\in B) &= \\int_A\\left(\\int_B f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\right)\\mathrm{d}x_1\n\\end{align*}\\] を満たすものと定義する。 \\(X_1\\) と \\(X_2\\) が確率密度関数を持つ場合でも \\(X_1\\) と \\(X_2\\) の同時確率密度関数が存在するとは限らない。 例えば \\(X_1=X_2\\) の場合がその例である。 逆に \\(X_1\\) と \\(X_2\\) が同時確率密度関数を持つとき、それぞれの確率密度関数は \\[\\begin{align*}\nf_{X_1}(x_1) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_2\\\\\nf_{X_2}(x_2) &= \\int_{-\\infty}^\\infty f_{X_1,\\,X_2}(x_1,x_2)\\mathrm{d}x_1\n\\end{align*}\\] で得られる。この操作を確率密度関数の周辺化という。 同時確率密度関数を持つ確率変数 \\(X_1\\), \\(X_2\\) が独立であるとき、 \\[\\begin{align*}\nf_{X_1,\\,X_2}(x_1,x_2) &= f_{X_1}(x_1) f_{X_2}(x_2)\n\\end{align*}\\] が成り立つ。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#三つ以上の独立確率変数",
    "href": "multivariate.html#三つ以上の独立確率変数",
    "title": "5  複数の確率変数",
    "section": "5.5 三つ以上の独立確率変数",
    "text": "5.5 三つ以上の独立確率変数\n三つ以上の確率変数についても同時確率質量関数、同時確率密度関数を同様に定義する。 独立性についても同様に定義する。\n\n定義 5.6 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が独立 \\(\\defiff\\) \\[\\begin{align*}\n\\Pr(X_1\\in A_1,\\dotsc, X_n\\in A_n) &= \\prod_{k=1}^n \\Pr(X_k\\in A_k)\\qquad\\forall A_1,\\dotsc,A_n\\subseteq\\mathbb{R}.\n\\end{align*}\\]\n\n\n定義 5.7 確率空間 \\((\\Omega,\\,P)\\) 上の確率変数 \\(X_1, X_2,\\dotsc, X_n\\) が互いに独立 \\(\\defiff\\) 任意の \\(1\\le i&lt; j\\le n\\) について、\\(X_i\\) と \\(X_j\\) が独立。\n\n確率変数 \\(X_1,\\dotsc,X_n\\) が独立であるとき、それらは互いに独立であることは以下から分かる。 \\[\\begin{align*}\n\\Pr(X_1\\in A,\\, X_2\\in B) &= \\Pr(X_1\\in A,\\, X_2\\in B,\\, X_3\\in\\mathbb{R},\\dotsc, X_n\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B) \\prod_{k=3}^n \\Pr(X_k\\in\\mathbb{R})\\\\\n&= \\Pr(X_1\\in A)\\Pr(X_2\\in B).\n\\end{align*}\\]\n一方で確率変数 \\(X_1,\\dotsc,X_n\\) が互いに独立であっても、それらが独立であるとは限らない。 例えば、離散型確率変数 \\(X_1,\\dotsc,X_n\\) を \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\begin{cases}\n\\frac1{2^{n-1}}&\\text{if } \\sum_{k=1}^n x_k \\text{ is even}\\\\\n0&\\text{otherwise}\n\\end{cases}&\n\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] と定義する。 このとき、確率変数 \\(X_n\\) を周辺化すると \\[\\begin{align*}\nf_{X_1,\\dotsc,X_{n-1}}(x_1,\\dotsc,x_{n-1})&=\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},0)+ f_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_{n-1},1)\\\\\n&=\\frac1{2^{n-1}}\n\\end{align*}\\] となる。つまり、\\(X_1,\\dotsc,X_{n-1}\\) は \\(\\{0,1\\}^{n-1}\\) 上の一様分布に従う。 この確率分布は \\(X_1,\\dotsc,X_n\\) について対称なので、どの確率変数を周辺化しても一様分布に従う。 一様分布は独立なので、\\(n\\ge 3\\) のとき、どの二つの確率変数も独立である。\n一方で、\\(n\\ge 2\\) のとき、これらの確率変数の周辺確率は一様である。つまり、 \\[\\begin{align*}\nf_{X_k}(0) &= f_{X_k}(1) = \\frac12\\qquad\\forall k=1,2,\\dotsc,n.\n\\end{align*}\\] しかし、 \\[\\begin{align*}\nf_{X_1,\\dotsc,X_n}(x_1,\\dotsc,x_n)&=\\prod_{k=1}^n f_{X_k}(x_k)\\qquad\\forall x_1,\\dotsc,x_n\\in\\{0,1\\}\n\\end{align*}\\] は成り立たないので独立ではない。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#独立な離散型確率変数の和",
    "href": "multivariate.html#独立な離散型確率変数の和",
    "title": "5  複数の確率変数",
    "section": "5.6 独立な離散型確率変数の和",
    "text": "5.6 独立な離散型確率変数の和\n離散型確率変数 \\(X_1\\) と \\(X_2\\) が独立であるとする。 このとき、\\(X_1+X_2\\) の確率質量関数は \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_z f_{X_1}(z)f_{X_2}(x-z)\n\\end{align*}\\] で与えられる。 これを確率質量関数の畳み込みという。\n\n例 5.3 二項分布の \\(N=1\\) の場合をベルヌーイ分布 \\(\\mathrm{Ber}(p)\\) と呼ぶ。 つまり、\\(X\\sim\\mathrm{Ber}(p)\\defiff\\) \\[\\begin{align*}\n\\Pr(X=0) &= 1-p,& \\Pr(X=1) &= p\n\\end{align*}\\] である。 確率変数 \\(X_1,X_2\\) が独立で \\(\\mathrm{Ber}(p)\\) に従うとする。 このとき、\\(X_1+X_2\\) は \\(\\mathrm{Binom}(2, p)\\) に従う。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = 0) &= \\Pr(X_1=0,\\,X_2=0)\\\\\n&= \\Pr(X_1=0)\\Pr(X_2=0) = (1-p)^2\\\\\n\\Pr(X_1+X_2 = 1) &= \\Pr(X_1=0,\\,X_2=1) + \\Pr(X_1=1,\\,X_2=0)\\\\\n&=  \\Pr(X_1=0)\\Pr(X_2=1) + \\Pr(X_1=1)\\Pr(X_2=0)\\\\\n&= 2p(1-p)\\\\\n\\Pr(X_1+X_2 = 2) &= \\Pr(X_1=1,\\,X_2=1)\\\\\n&= \\Pr(X_1=1)\\Pr(X_2=1) = p^2\n\\end{align*}\\] と計算できる。 よって \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\binom{2}{k} p^k(1-p)^{2-k}\n\\end{align*}\\] が成り立ち \\(X_1+X_2\\sim\\mathrm{Binom}(2, p)\\) であることが分かる。 一般に、独立確率変数 \\(X_1,\\,X_2\\) について \\(X_1\\sim\\mathrm{Binom}(n, p)\\), \\(X_2\\sim\\mathrm{Binom}(m, p)\\) のとき、\\(X_1+X_2\\sim\\mathrm{Binom}(n+m,p)\\) である。 \\[\\begin{align*}\n\\Pr(X_1+X_2 = k) &= \\sum_{\\ell\\ge 0} \\Pr(X_1 = \\ell) \\Pr(X_2 = k-\\ell)\\\\\n&= \\sum_{\\ell\\ge 0} \\binom{n}{\\ell} p^\\ell(1-p)^{n-\\ell} \\binom{m}{k-\\ell} p^{k-\\ell}(1-p)^{m-k+\\ell}\\\\\n&= \\left(\\sum_{\\ell\\ge 0} \\binom{n}{\\ell} \\binom{m}{k-\\ell}\\right) p^k(1-p)^{n+m-k}\\\\\n&= \\binom{n+m}{k} p^k(1-p)^{n+m-k}.\n\\end{align*}\\]\nよって、\\(X_1,\\dotsc,X_n\\) が独立で \\(\\mathrm{Ber}(p)\\) に従うとき、\\(X_1+\\dotsb+X_n\\) は \\(\\mathrm{Binom}(n, p)\\) に従う。\n\n\n例 5.4 確率変数 \\(X_1\\), \\(X_2\\) が独立で \\(X_1\\sim\\mathrm{Poisson}(\\lambda_1)\\), \\(X_2\\sim\\mathrm{Poisson}(\\lambda_2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\sum_{z= 0}^x f_{X_1}(z) f_{X_2}(x-z)\\\\\n&= \\sum_{z= 0}^x \\frac{\\lambda_1^z}{z!}\\mathrm{e}^{-\\lambda_1}\\frac{\\lambda_2^{x-z}}{(x-z)!}\\mathrm{e}^{-\\lambda_2}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}\\sum_{z=0}^x\\binom{x}{z} \\lambda_1^z\\lambda_2^{x-z}\\\\\n&= \\frac1{x!}\\mathrm{e}^{-(\\lambda_1+\\lambda_2)}(\\lambda_1+\\lambda_2)^x\n\\end{align*}\\] が成り立つ。よって \\(X_1+X_2\\sim\\mathrm{Poisson}(\\lambda_1+\\lambda_2)\\) である。 独立なポアソン分布の和はポアソン分布に従う。\n\nこれらの例のように、確率分布の族(集合)が畳み込みに閉じているとき、確率分布の族は再生性を持つという。 二項分布の場合はパラメータ \\(p\\) を固定したときに再生性を持つ。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "multivariate.html#独立な連続型確率変数の和",
    "href": "multivariate.html#独立な連続型確率変数の和",
    "title": "5  複数の確率変数",
    "section": "5.7 独立な連続型確率変数の和",
    "text": "5.7 独立な連続型確率変数の和\n連続確率変数 \\(X_1\\) と \\(X_2\\) が独立で密度関数を持つとき、 \\[\\begin{align*}\n\\Pr(X_1+X_2\\in A) &= \\int\\int_{y+z\\in A} f_{X_1}(y)f_{X_2}(z)\\mathrm{d}y\\mathrm{d}z\\\\\n&= \\int\\int_{x\\in A} f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\mathrm{d}x \\qquad(x=y+z)\\\\\n&= \\int_{A} \\left(\\int_{-\\infty}^\\infty f_{X_1}(y)f_{X_2}(x-y)\\mathrm{d}y\\right)\\mathrm{d}x \\qquad(x=y+z)\\\\\n\\end{align*}\\] と表せるので、\\(X_1+X_2\\) は確率密度関数を持ち \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\n\\end{align*}\\] とすることができる。 確率変数 \\(X_1,\\,X_2\\) が独立で \\(X_1\\sim N(\\mu_1,\\,\\sigma_1^2)\\), \\(X_2\\sim N(\\mu_2,\\,\\sigma_2^2)\\) とする。 このとき、 \\[\\begin{align*}\nf_{X_1+X_2}(x) &= \\int_{-\\infty}^\\infty f_{X_1}(z)f_{X_2}(x-z)\\mathrm{d} z\\\\\n&= \\int_{-\\infty}^\\infty \\frac1{\\sqrt{2\\pi\\sigma_1^2}} \\mathrm{e}^{-\\frac{(z-\\mu_1)^2}{2\\sigma_1^2}}\\frac1{\\sqrt{2\\pi\\sigma_2^2}} \\mathrm{e}^{-\\frac{(x-z-\\mu_2)^2}{2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{\\sigma_2^2(z-\\mu_1)^2+\\sigma_1^2(x-z-\\mu_2)^2}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{2\\pi\\sqrt{\\sigma_1^2\\sigma_2^2}}\\int_{-\\infty}^\\infty  \\mathrm{e}^{-\\frac{(\\sigma_1^2+\\sigma_2^2)\\left(z-\\frac{\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2)}{\\sigma_1^2+\\sigma_2^2}\\right)^2 + \\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\mathrm{d} z\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{\\sigma_2^2\\mu_1^2 + \\sigma_1^2(x-\\mu_2)^2 - \\frac{(\\sigma_2^2\\mu_1+\\sigma_1^2(x-\\mu_2))^2}{\\sigma_1^2+\\sigma_2^2}}{2\\sigma_1^2\\sigma_2^2}}\\\\\n&= \\frac1{\\sqrt{2\\pi(\\sigma_1^2+\\sigma_2^2)}}\\mathrm{e}^{-\\frac{(x-(\\mu_1+\\mu_2))^2}{2(\\sigma_1^2+\\sigma_2^2)}}\\\\\n\\end{align*}\\] が成り立つので \\(X_1+X_2\\sim N(\\mu_1+\\mu_2,\\,\\sigma_1^2+\\sigma_2^2)\\) であることが分かる。 よって正規分布は再生性を持つ。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>複数の確率変数</span>"
    ]
  },
  {
    "objectID": "moments.html",
    "href": "moments.html",
    "title": "6  期待値、分散、モーメント",
    "section": "",
    "text": "6.1 期待値\n連続型確率変数の期待値に関する様々な証明はルベーグ積分の知識を必要とするので本書では扱わない。 以下、証明はすべて離散確率変数の場合に限って与える。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>期待値、分散、モーメント</span>"
    ]
  },
  {
    "objectID": "moments.html#期待値",
    "href": "moments.html#期待値",
    "title": "6  期待値、分散、モーメント",
    "section": "",
    "text": "定義 6.1 (期待値) 離散型確率変数 \\(X\\) の期待値は\n\\[\\begin{align*}\n\\expt{X}\n% &= \\sum_{\\omega \\in \\Omega} X(\\omega) P(\\{\\omega\\})\\\\\n%&= \\sum_{x\\in \\mathrm{Image}(X)} x P(\\{\\omega\\mid X(\\omega)=x\\})\\\\\n&\\coloneqq \\sum_{x\\in \\mathrm{Image}(X)} x \\Pr(X=x)\\\\\n&= \\sum_{x\\in \\mathrm{Image}(X)} x f_X(x)\n\\end{align*}\\]\nと定義される。ここで、右辺の和が絶対収束しない場合は(適当な順番で和を取って収束したとしても)期待値は定義されない。\n連続型確率変数 \\(X\\) が確率密度関数 \\(f_X\\) を持つとき、その期待値は\n\\[\n\\expt{X}\\coloneqq \\int_{-\\infty}^\\infty x f_X(x) \\mathrm{d}x\n\\]\nと定義される。ただし、広義積分で上記の積分が存在する場合でも \\[\n\\int_{-\\infty}^\\infty |x| f_X(x) \\mathrm{d}x\n\\] が存在しない場合は期待値は定義されない。\n\n\n\n補題 6.1 確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\n\\expt{X+Y}&=\\expt{X}+\\expt{Y}\n\\end{align*}\\] である。 また、\\(X\\) と \\(Y\\) が独立のとき、 \\[\\begin{align*}\n\\expt{XY}&=\\expt{X}\\,\\expt{Y}\n\\end{align*}\\] である。\n\n\n証明. \\[\\begin{align*}\n\\expt{X+Y} &= \\sum_{z} z f_{X+Y}(z)\\\\\n&= \\sum_{z} z \\sum_x f_{X,\\,Y}(x, z-x)\\\\\n&= \\sum_{x,\\,y} (x+y) f_{X,\\,Y}(x, y)\\qquad (y=z-x)\\\\\n&= \\sum_{x,\\,y} xf_{X,\\,Y}(x,y) + \\sum_{x,\\,y} yf_{X,\\,Y}(x,y)\\\\\n&= \\sum_{x} xf_{X}(x) + \\sum_{y} yf_{Y}(y)\\\\\n&= \\expt{X} + \\expt{Y}.\n\\end{align*}\\] \\(X\\) と \\(Y\\) が独立のとき、 \\[\\begin{align*}\n\\expt{XY} &= \\sum_{z} z f_{XY}(z)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X,\\,Y}(x,z/x)\\\\\n&= \\sum_{z} z \\sum_{x\\ne 0}f_{X}(x)f_Y(z/x)\\\\\n&= \\sum_{x\\ne 0,\\, y} xy f_{X}(x)f_Y(y)\\qquad(y=z/x)\\\\\n&= \\sum_{x,\\, y} xy f_{X}(x)f_Y(y)\\\\\n&= \\left(\\sum_{x} xf_{X}(x)\\right)\\left(\\sum_y yf_Y(y)\\right)\\\\\n&= \\expt{X}\\,\\expt{Y}\n\\end{align*}\\]\n\n\n補題 6.2 (Law of the unconscious statistician (LOTUS)) 任意の関数 \\(g\\colon\\mathbb{R}\\to\\mathbb{R}\\) について、\n\n\\(X\\) が離散型確率変数のとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\sum_{x} g(x) f_X(x).\n\\end{align*}\\]\n\\(X\\) が連続型確率変数で確率密度関数を持つとき、 \\[\\begin{align*}\n\\expt{g(X)} &= \\int_{-\\infty}^\\infty g(x) f_X(x) \\mathrm{d}x.\n\\end{align*}\\]\n\n\n\n証明. \\(X\\) を離散型確率変数とする。 \\[\\begin{align*}\n\\expt{g(X)}\n%&= \\sum_{x} x f_{g(X)}(x)\\\\\n&= \\sum_{x} x \\Pr(g(X) = x)\\\\\n&= \\sum_{x} x P(\\{\\omega\\in\\Omega\\mid g(X(\\omega)) = x\\})\\\\\n&= \\sum_{x} x P\\left(\\bigcup_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x}\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{x}\\sum_{y\\in\\mathrm{Image}(X)\\colon\\, g(y) = x} x P\\left(\\{\\omega\\in\\Omega\\mid X(\\omega) = y\\}\\right)\\\\\n&= \\sum_{y\\in\\mathrm{Image}(X)} g(y) f_X(y).\n\\end{align*}\\] \n\n\n命題 6.1 (期待値の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\expt{X+a} &= \\expt{X}+a\\\\\n\\expt{aX} &= a\\expt{X}.\n\\end{align*}\\]\n\n\n定理 6.1 (マルコフの不等式) 任意の非負確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(X\\ge a)\\le\\frac{\\expt{X}}{a}.\n\\]\n\n\n証明. \\[\\begin{align*}\n\\expt{X} &= \\sum_{x\\in \\mathrm{Image}(X)} f_X(x) x\\\\\n&= \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x + \\sum_{\\mathrm{Image}(X)\\colon\\, x &lt; a} f_X(x) x\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) x\\qquad\\qquad (\\Pr(X\\ge 0)=1)\\\\\n&\\ge \\sum_{\\mathrm{Image}(X)\\colon\\, x\\ge a} f_X(x) a\\\\\n&= \\Pr(X\\ge a) a.\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>期待値、分散、モーメント</span>"
    ]
  },
  {
    "objectID": "moments.html#分散",
    "href": "moments.html#分散",
    "title": "6  期待値、分散、モーメント",
    "section": "6.2 分散",
    "text": "6.2 分散\n\n定義 6.2 (分散) 確率変数 \\(X\\) が期待値を持つとき、その分散を\n\\[\n\\var{X}\\coloneqq  \\expt{(X-\\expt{X})^2}\n\\]\nと定義する。 また、分散の平方根を標準偏差という。\n\n確率変数 \\(X\\) が分散を持つとき、\n\\[\\begin{align*}\n\\var{X} &= \\expt{(X-\\expt{X})^2}\\\\\n&= \\expt{X^2-2X\\expt{X}+\\expt{X}^2}\\\\\n&= \\expt{X^2}-2\\expt{X}\\expt{X}+\\expt{X}^2\\\\\n&= \\expt{X^2}-\\expt{X}^2\n\\end{align*}\\]\nである。 分散は定義より非負の値を取る。\n\n命題 6.2 (分散の性質) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\var{X+a} &= \\var{X}\\\\\n\\var{aX} &= a^2\\var{X}.\n\\end{align*}\\]\n\n分散は直感的には期待値からのはずれ具合を表す値である。\n\n定理 6.2 (チェビシェフの不等式) 任意の確率変数 \\(X\\) と \\(a&gt;0\\) について \\[\n\\Pr(|X-\\expt{X}|\\ge a)\\le\\frac{\\var{X}}{a^2}.\n\\]\n\n\n証明. \\[\\begin{align*}\n\\Pr(|X-\\expt{X}|\\ge a)&= \\Pr((X-\\expt{X})^2\\ge a^2)\\\\\n&\\le\n\\frac{\\expt{(X-\\expt{X})^2}}{a^2} = \\frac{\\var{X}}{a^2}.\n\\end{align*}\\]\n\n\n補題 6.3 (互いに独立な確率変数の和) 確率変数 \\(X_1,\\,X_2,\\dotsc,X_n\\) が互いに独立のとき\n\\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\var{X_1} +\\dotsb + \\var{X_n}.\n\\end{align*}\\]\n\n\n証明. \\[\\begin{align*}\n\\var{X_1+\\dotsb+X_n} &= \\expt{\\left((X_1+\\dotsb+X_n) - \\expt{X_1+\\dotsb+X_n}\\right)^2}\\\\\n&= \\expt{\\left((X_1- \\expt{X_1}) + \\dotsb + (X_n-\\expt{X_n})\\right)^2}\\\\\n&= \\expt{\\sum_i (X_i- \\expt{X_i})^2  + 2\\sum_{i &lt; j}\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{\\left(X_i-\\expt{X_i}\\right)\\left(X_j-\\expt{X_j}\\right)}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2} +  2\\sum_{i &lt; j}\\expt{X_i-\\expt{X_i}}\\expt{X_j-\\expt{X_j}}\\\\\n&= \\sum_i \\expt{(X_i- \\expt{X_i})^2}\n=\\sum_i \\var{X_i}.\n\\end{align*}\\]\n\n\n例 6.1 互いに独立な確率変数 \\(X_1,\\dotsc,X_n\\) のそれぞれが確率変数 \\(X\\) と同分布であるとし、 \\[\\begin{align*}\nY&\\coloneqq \\frac1{n} (X_1+\\dotsb+X_n)\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\n\\expt{Y} &= \\expt{X}\\\\\n\\var{Y} &= \\frac1{n}\\var{X}\n\\end{align*}\\] である。互いに独立な確率変数の平均を取ると期待値は変わらず、分散は小さくなる。\n\n\n例 6.2 独立確率変数 \\(X_1,\\dotsc,X_n\\sim\\mathrm{Ber}(1/2)\\) について \\[\\begin{align*}\nY_S &\\coloneqq \\sum_{i\\in S} X_i \\mod 2\\qquad\\forall S\\subseteq\\{1,2,\\dotsc,n\\}\n\\end{align*}\\] と定義すると、これらは互いに独立である。 また、\\(S\\ne\\varnothing\\) について \\(Y_S\\sim\\mathrm{Ber}(1/2)\\) である。 任意の関数 \\(g\\colon\\,\\{0,1\\}\\to\\mathbb{R}\\) について、 \\[\\begin{align*}\nY&\\coloneqq \\frac1{2^n-1} \\sum_{S\\subseteq\\{1,\\dotsc,n\\}\\colon\\, S\\ne\\varnothing} g(Y_S)\n\\end{align*}\\] と定義すると、\\(X\\sim\\mathrm{Ber}(1/2)\\) について、 \\[\\begin{align*}\n\\expt{Y} &= \\expt{g(X)}\\\\\n\\var{Y} &= \\frac1{2^n-1}\\var{g(X)}.\n\\end{align*}\\]",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>期待値、分散、モーメント</span>"
    ]
  },
  {
    "objectID": "moments.html#共分散",
    "href": "moments.html#共分散",
    "title": "6  期待値、分散、モーメント",
    "section": "6.3 共分散",
    "text": "6.3 共分散\n\n定義 6.3 (共分散) 確率変数 \\(X,Y\\) が期待値を持つとき、その共分散を\n\\[\\begin{align*}\n\\cov{X}{Y} &\\coloneqq \\expt{(X-\\expt{X})(Y-\\expt{Y})}\\\\\n&= \\expt{XY}-\\expt{X}\\,\\expt{Y}\n\\end{align*}\\]\nと定義する。 共分散がゼロである確率変数のペアを無相関であるという。\n\n定義より、\\(\\cov{X}{X}=\\var{X}\\) であることが分かる。\n\n命題 6.3 独立確率変数 \\(X,Y\\) は無相関である。\n\n逆に無相関であっても独立とは限らない。\n\n例 6.3 確率変数 \\(X\\) を \\[\\begin{align*}\nf_X(0)= f_X(+1)= f_X(-1)= \\frac13\n\\end{align*}\\] を満たすものとし、\\(Y=X^2\\) とする。 このとき、 \\[\\begin{align*}\n\\cov{X}{Y} &= \\expt{XY} - \\expt{X}\\expt{Y}\\\\\n&= \\expt{X^3} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X} - \\expt{X}\\expt{X^2}\\\\\n&= \\expt{X}(1-\\expt{X^2})\\\\\n&= 0\n\\end{align*}\\] なので、\\(X\\) と \\(Y\\) は無相関である。 一方で \\[\\begin{align*}\nf_{Y}(0) &= \\frac13&\nf_{Y}(1) &= \\frac23\\\\\nf_{X,\\,Y}(0, 0) &= \\frac13&\nf_{X,\\,Y}(1, 1) &= \\frac13&\nf_{X,\\,Y}(-1, 1) &= \\frac13&\n\\end{align*}\\] なので \\(X\\) と \\(Y\\) は独立ではない。\n\n共分散は正の値も負の値も取り得る。 大雑把に言うと、\n\n\\(X\\) と \\(Y\\) の共分散が正 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) も大きい\n\\(X\\) と \\(Y\\) の共分散が負 \\(\\iff\\) \\(X\\) が大きいとき \\(Y\\) は小さい\n\nという意味になる。\n\n補題 6.4 任意の確率変数 \\(X_1,\\dotsc,X_n\\) について \\[\\begin{align*}\n\\var{\\sum_i X_i} &= \\sum_i \\var{X_i} + 2\\sum_{i &lt; j} \\cov{X_i}{X_j}.\n\\end{align*}\\]\n\n\n証明. 補題 6.3 の証明参照。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>期待値、分散、モーメント</span>"
    ]
  },
  {
    "objectID": "moments.html#モーメントとモーメント母関数",
    "href": "moments.html#モーメントとモーメント母関数",
    "title": "6  期待値、分散、モーメント",
    "section": "6.4 モーメントとモーメント母関数",
    "text": "6.4 モーメントとモーメント母関数\n\n定義 6.4 (モーメント) 確率変数 \\(X\\) と正の整数 \\(n\\ge 1\\) について、\n\\[\n\\mu_n(X)\\coloneqq \\expt{X^n}\n\\]\nを \\(X\\) の \\(n\\) 次モーメントという。\n\n\n定義 6.5 (モーメント母関数(積率母関数)) 確率変数 \\(X\\) について、\n\\[\nM_X(t) \\coloneqq \\expt{\\mathrm{e}^{tX}}\\qquad t\\in\\mathbb{R}\n\\]\nを \\(X\\) のモーメント母関数という。 すべての \\(t\\in\\mathbb{R}\\) で \\(M_X(t)\\) が存在しない場合もある。 また、\n\\[\nK_X(t) \\coloneqq \\log M_X(t)\n\\] を \\(X\\) のキュムラント母関数という。\n\n\n今後は以下の補題を認めることにする。証明にはルベーグ積分の知識が必要である。\n\n定理 6.3 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\nM_X(t) &=\\sum_{n\\ge 0}\\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon)\\\\\n\\mu_n(X) &= \\left.\\frac{\\mathrm{d}^n M_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}.\n\\end{align*}\\]\n\n\n証明. 前半の証明を与える。 離散型確率変数 \\(X\\) について、 \\[\\begin{align*}\nM_X(t) &= \\expt{\\mathrm{e}^{tX}}\\\\\n&= \\sum_x \\mathrm{e}^{tx} f_X(x)\\\\\n&= \\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\n\\end{align*}\\] である。 ここで、任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について \\[\\begin{align*}\n&\\sum_x \\sum_{n\\ge0}\\left|\\frac{(tx)^n}{n!} f_X(x)\\right|\\\\\n&= \\sum_x \\sum_{n\\ge0}\\frac{|tx|^n}{n!} f_X(x)\\\\\n&= \\sum_x \\mathrm{e}^{|tx|} f_X(x)\\\\\n&\\le \\sum_x (\\mathrm{e}^{tx}+\\mathrm{e}^{-tx}) f_X(x)\\\\\n&= \\expt{\\mathrm{e}^{tX}} + \\expt{\\mathrm{e}^{-tX}}\\\\\n&= M_X(t) + M_X(-t) &lt; \\infty\n\\end{align*}\\] よって、無限和 \\[\\begin{align*}\n\\sum_x \\sum_{n\\ge0}\\frac{(tx)^n}{n!} f_X(x)\n\\end{align*}\\] は任意の \\(t\\in(-\\epsilon,\\epsilon)\\) について絶対収束する。 そのため、和の順序を変えても収束値は変化しない。 よって、 \\[\\begin{align*}\nM_X(t) &= \\expt{\\mathrm{e}^{tX}}\\\\\n&= \\sum_x \\left(\\sum_{n\\ge0}\\frac{(tx)^n}{n!}\\right) f_X(x)\\\\\n&= \\sum_{n\\ge 0} \\sum_{x}\\frac{(tx)^n}{n!}f_X(x)\\\\\n&= \\sum_{n\\ge 0} \\frac{\\sum_xx^n f_X(x)}{n!}t^n\\\\\n&= \\sum_{n\\ge 0} \\frac{\\expt{X^n}}{n!}t^n\\qquad\\forall t\\in(-\\epsilon,\\epsilon).\n\\end{align*}\\] \n\n\n系 6.1 確率変数 \\(X\\) について、ある \\(\\epsilon &gt;0\\) が存在し、モーメント母関数 \\(M_X(t)\\) が \\(t\\in(-\\epsilon,\\epsilon)\\) で存在するとき、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\expt{X}\\\\\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &=  \\var{X}.\n\\end{align*}\\]\n\n\n証明. \\[\\begin{align*}\n\\left.\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d} t}\\right|_{t=0} &= \\left.\\frac{M'_X(t)}{M_X(t)}\\right|_{t=0}=\\expt{X}\\\\\n\\left.\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d} t^2}\\right|_{t=0} &= \\left.\\frac{M''_X(t)M_X(t) - M'_X(t)^2}{M_X(t)^2}\\right|_{t=0} = M''_X(0) - M'_X(0)^2 = \\var{X}.\n\\end{align*}\\]\n\nまた、重要度は低くなるが、\n\\[\\begin{align*}\n\\left.\\frac{\\mathrm{d}^3 K_X(t)}{\\mathrm{d} t^3}\\right|_{t=0} &= \\expt{(X - \\expt{X})^3}\\\\\n\\left.\\frac{\\mathrm{d}^4 K_X(t)}{\\mathrm{d} t^4}\\right|_{t=0} &= \\expt{(X - \\expt{X})^4} - 3\\var{X}^2\n\\end{align*}\\]\nが成り立つ。 一般に \\[\\begin{align*}\n\\kappa_n(X) &\\coloneqq \\left.\\frac{\\mathrm{d}^n K_X(t)}{\\mathrm{d} t^n}\\right|_{t=0}\n\\end{align*}\\] を \\(X\\) の \\(n\\) 次キュムラント と呼ぶ。\n\n定理 6.4 確率変数 \\(X\\) と \\(Y\\) のモーメント母関数が0を含む開区間 \\((-\\epsilon,\\,\\epsilon)\\) で存在し、それらが等しいとき、\\(X\\) の分布と \\(Y\\) の分布は等しい。\n\n\n証明. \\(\\mathrm{Image}(X)\\) と \\(\\mathrm{Image}(Y)\\) が有限の場合に限って証明を与える (この場合はモーメント母関数は \\(\\mathbb{R}\\) 全体で存在するのだが)。 \\[\\begin{align*}\n\\{x_0,\\dotsc,x_{N-1}\\} &\\coloneqq \\mathrm{Image}(X) \\cup \\mathrm{Image}(Y)\n\\end{align*}\\] とする。 \\[\\begin{align*}\nM_X(t) &= \\sum_{k=0}^{N-1} f_X(x_k) \\mathrm{e}^{tx_k}\\\\\nM_Y(t) &= \\sum_{k=0}^{N-1} f_Y(x_k) \\mathrm{e}^{tx_k}\n\\end{align*}\\] なので、 \\[\\begin{align*}\n0 = M_X(t) - M_Y(t) &= \\sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \\mathrm{e}^{tx_k}\\qquad\\forall t\\in(-\\epsilon,\\epsilon)\n\\end{align*}\\] 各 \\(k\\in\\{0,1,\\dotsc,N-1\\}\\) について、\\(t_k\\coloneqq \\epsilon\\frac{k}{N}\\) とおくと、 \\[\\begin{align}\n\\sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \\mathrm{e}^{t_\\ell x_k}&=0\\qquad\\forall \\ell\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align}\\] である。 ここで、\\(N\\times N\\) 実行列 \\(V\\) を \\[\\begin{align*}\nV_{\\ell k} &= \\mathrm{e}^{t_\\ell x_k}\n= \\mathrm{e}^{\\frac{\\epsilon x_k}{N} \\ell}\\qquad\\forall k,\\ell\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] とおく。 この行列 \\(V\\) は Vandermonde行列の転置であり正則なので、 \\[\\begin{align*}\n&\\sum_{k=0}^{N-1} V_{\\ell k} g_k=0\\qquad\\forall \\ell\\in\\{0,1,\\dotsc,N-1\\}\\\\\n\\implies& g_k = 0 \\qquad\\forall k\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] よって、 \\[\\begin{align*}\nf_X(x_k) &= f_Y(x_k) \\qquad\\forall k\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] である。\n\n定理 6.4 より、モーメント母関数には確率変数の分布のすべての情報が含まれていると言える。 ただし、モーメント母関数は原点まわりで存在しないこともあるので、分布の情報をすべて含む関数としては特性関数 \\[\\begin{align*}\n\\varphi_X(t) &\\coloneqq \\expt{\\mathrm{e}^{itX}}\\qquad\\forall t\\in\\mathbb{R}\n\\end{align*}\\] の方が優秀である。 特性関数は常に存在する。 一方でモーメント母関数は確率の集中を示す文脈では中心的な役割を果たす。",
    "crumbs": [
      "確率論",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>期待値、分散、モーメント</span>"
    ]
  },
  {
    "objectID": "bayes.html",
    "href": "bayes.html",
    "title": "7  ベイズ推定",
    "section": "",
    "text": "7.1 最大事後確率推定\n統計的推論とは現実の推定問題を確率論に基づきモデル化し、誤り確率を最小化するように推論する方法論である。 統計的推論には大きく分けて二種類の流派がある。\n例えば統計的推論は以下のような問題に適用されている。\nデータが取り得る値の集合を \\(\\mathcal{X}\\) とし、分布のパラメータの取り得る値の集合を \\(\\Theta\\) とする。 簡単のため、\\(\\mathcal{X}\\) と \\(\\Theta\\) は高々可算集合とする。 データ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。 このとき、\\(x\\) と \\(\\theta\\) が何かしらの確率分布に従っていると仮定する。 パラメータ \\(\\theta\\) に対する \\(x\\) の確率質量関数を \\(p(x\\mid \\theta)\\) と表す。 また、パラメータ \\(\\theta\\) の確率質量関数を \\(\\pi(\\theta)\\) と表す。 つまり、パラメータ \\(\\theta\\in\\Theta\\) とデータ \\(x\\in\\mathcal{X}\\) が選ばれる確率は \\[\\begin{align*}\n\\pi(\\theta) p(x\\mid\\theta)\n\\end{align*}\\] である。 また、 \\[\\begin{align*}\np(x) &= \\sum_{\\theta\\in\\Theta}\\pi(\\theta)p(x\\mid\\theta),&\np(\\theta\\mid x)&\\coloneqq \\frac{\\pi(\\theta)p(x\\mid\\theta)}{p(x)}\n\\end{align*}\\] と定義する。 ベイズ推定の文脈では\nと呼ぶ。\n得られたデータ \\(x\\in\\mathcal{X}\\) からパラメータ \\(\\theta\\in\\Theta\\) を推定する関数 \\(\\widehat{\\theta}\\colon \\mathcal{X}\\to\\Theta\\) を推定量 (estimator)もしくは推定関数という。 推定量 \\(\\widehat{\\theta}\\) の誤り確率を \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta})&\\coloneqq\n\\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) \\,\\mathbb{I}\\{\\widehat{\\theta}(x)\\ne\\theta\\}\n\\end{align*}\\] と定義する。 このとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta})\n&= \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) \\,\\mathbb{I}\\{\\widehat{\\theta}(x)\\ne\\theta\\}\\\\\n&= \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta) (1-\\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\})\\\\\n&= 1- \\sum_{\\theta\\in\\Theta} \\pi(\\theta) \\sum_{x\\in\\mathcal{X}} p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\sum_{\\theta\\in\\Theta} \\pi(\\theta)  p(x\\mid\\theta)\\, \\mathbb{I}\\{\\widehat{\\theta}(x)=\\theta\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}}\\pi\\left(\\widehat{\\theta}(x)\\right)  p\\left(x\\mid\\widehat{\\theta}(x)\\right)\\\\\n&\\ge 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\Theta} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] と下から抑えることができ、 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{MAP}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}p\\left(\\theta\\mid x\\right)  p\\left(x\\right)\\\\\n&= \\arg\\max_{\\theta\\in\\Theta}\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n\\end{align*}\\] という推定量により等号が達成される。 この推定量を最大事後確率(maximum a posteriori; MAP)推定量と呼ぶ。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ベイズ推定</span>"
    ]
  },
  {
    "objectID": "bayes.html#最大事後確率推定",
    "href": "bayes.html#最大事後確率推定",
    "title": "7  ベイズ推定",
    "section": "",
    "text": "\\(\\pi(\\theta)\\colon\\) 事前確率\n\\(p(x\\mid \\theta)\\colon\\) 尤度\n\\(p(\\theta\\mid x)\\colon\\) 事後確率",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ベイズ推定</span>"
    ]
  },
  {
    "objectID": "bayes.html#最尤推定",
    "href": "bayes.html#最尤推定",
    "title": "7  ベイズ推定",
    "section": "7.2 最尤推定",
    "text": "7.2 最尤推定\nMAP推定は誤り確率を最小化する推定方法であるが、事前確率 \\(\\pi(\\theta)\\) を仮定しないと用いることができない。 一方で尤度を最大化する推定量 \\[\\begin{align*}\n\\widehat{\\theta}_{\\mathrm{ML}}(x) &\\coloneqq\n  \\arg\\max_{\\theta\\in\\Theta}p\\left(x\\mid\\theta\\right)\n\\end{align*}\\] を最尤推定(maximam a priori; ML)量という。 \\(\\Theta\\) が有限集合で、事前確率が一様分布 \\(\\pi(\\theta)=\\frac1{|\\Theta|}\\) のとき、最尤推定は最大事後確率推定と一致する。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ベイズ推定</span>"
    ]
  },
  {
    "objectID": "bayes.html#全変動距離",
    "href": "bayes.html#全変動距離",
    "title": "7  ベイズ推定",
    "section": "7.3 全変動距離",
    "text": "7.3 全変動距離\n特にパラメータが二値である場合を考える。この章では \\(\\Theta=\\{0,1\\}\\) とする。 また、 \\[\\begin{align*}\np^{(0)}(x) &\\coloneqq p(x\\mid 0)&\np^{(1)}(x) &\\coloneqq p(x\\mid 1)\n\\end{align*}\\] とする。 このとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max_{\\theta\\in\\{0,1\\}} \\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n\\end{align*}\\] である。 ここで、 \\[\\begin{align*}\n\\begin{split}\n\\max\\{a,b\\} - \\min\\{a,b\\} &= |\\,a-b\\,|\\\\\n\\max\\{a,b\\} + \\min\\{a,b\\} &= a+b\n\\end{split}\n\\qquad\\forall a,b\\in\\mathbb{R}\n\\end{align*}\\] であるので、 \\[\\begin{align*}\n\\max\\{a,b\\} &= \\frac12(a+b+|\\,a-b\\,|)\\qquad\\forall a,b\\in\\mathbb{R}.\n\\end{align*}\\] よって、 \\[\\begin{align*}\n%\\max_{\\theta\\in\\{0,1\\}} \\{\\pi\\left(\\theta\\right)  p\\left(x\\mid\\theta\\right)\\}\n\\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\n&= \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\n\\end{align*}\\] よって、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})\n&= 1- \\sum_{x\\in\\mathcal{X}} \\max \\left\\{\\pi(0)  p^{(0)}\\left(x\\right),\\,\\pi(1)  p^{(1)}\\left(x\\right)\\right\\}\\\\\n&= 1- \\sum_{x\\in\\mathcal{X}} \\frac12\\left(p(x) +\n\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= 1-  \\frac12\\left(1 +\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n&= \\frac12\\left(1 -\n\\sum_{x\\in\\mathcal{X}}\\left|\\,\\pi\\left(0\\right)  p^{(0)}\\left(x\\right) - \\pi\\left(1\\right)  p^{(1)}\\left(x\\right) \\,\\right|\\right)\\\\\n\\end{align*}\\]\n\n定義 7.1 (全変動距離) 高々可算集合 \\(\\mathcal{X}\\) 上の関数 \\(f\\) について、 \\[\\begin{align*}\n\\|f\\|_1 &\\coloneqq \\sum_{x\\in\\mathcal{X}} \\left|\\, f(x)\\,\\right|\n\\end{align*}\\] と定義する。 また、\\(\\mathcal{X}\\) 上の確率質量関数 \\(p^{(0)}\\), \\(p^{(1)}\\) について、 \\[\\begin{align*}\nd_{\\mathrm{TV}}(p^{(0)},\\, p^{(1)}) &\\coloneqq \\frac12\\left\\|\\, p^{(0)}-p^{(1)}\\,\\right\\|_1\n\\end{align*}\\] を \\(p^{(0)}\\) と \\(p^{(1)}\\) の全変動距離という。\n\nこれらの記法を用いると、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-\\left\\|\\pi(0)p^{(0)} - \\pi(1)p^{(1)}\\right\\|_1\\right)\n\\end{align*}\\] と表せる。また、\\(\\pi(0)=\\pi(1)=1/2\\) のとき、 \\[\\begin{align*}\nP_{\\mathrm{err}}(\\widehat{\\theta}_\\mathrm{MAP})&=\\frac12\\left(1-d_{\\mathrm{TV}}(p^{(0)},\\,p^{(1)})\\right)\n\\end{align*}\\] である。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ベイズ推定</span>"
    ]
  },
  {
    "objectID": "bayes.html#損失関数",
    "href": "bayes.html#損失関数",
    "title": "7  ベイズ推定",
    "section": "7.4 損失関数",
    "text": "7.4 損失関数\nパラメータが取り得る値の集合が実数の部分集合 \\(\\Theta\\subseteq\\mathbb{R}\\) であると仮定する。 真のパラメータとその推定値の間の「誤差」を表す関数 \\(L\\colon\\Theta\\times\\mathbb{R}\\to\\mathbb{R}_{\\ge 0}\\) を損失関数と呼ぶ。 また、期待損失 \\(R\\colon\\Theta\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\nR(\\theta,\\,\\widehat{\\theta}) &\\coloneqq \\expt{L(\\theta,\\,\\widehat{\\theta}(X))\\mid\\theta}\\\\\n&=\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\n\\end{align*}\\] と定義する。 また、ベイズリスク \\(\\rho\\colon \\mathcal{P}(\\Theta)\\times(\\mathcal{X}\\to\\mathbb{R})\\to\\mathbb{R}_{\\ge 0}\\) を \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\sum_{\\theta\\in\\Theta}\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\n\\end{align*}\\] と定義する。 \\(\\Theta\\subseteq\\mathbb{R}\\) が非可算無限集合の場合は \\(\\pi(\\theta)\\) を確率密度関数とし、 \\[\\begin{align*}\n\\rho(\\pi, \\widehat{\\theta})&\\coloneqq  \\expt{L(\\theta,\\,\\widehat{\\theta}(X))}\\\\\n&=\\int\\sum_{x\\in\\mathcal{X}} L(\\theta,\\,\\widehat{\\theta}(x)) p(x\\mid\\theta)\\pi(\\theta)\\mathrm{d}\\theta\n\\end{align*}\\] と定義する。 このとき、 \\(p(x\\mid\\theta)\\) は条件付き確率というより、\\(\\theta\\in\\Theta\\) というパラメータを持った確率質量関数(\\(\\theta\\in\\Theta\\) から定まる確率質量関数)と理解すれば十分である。\n例えば \\(\\Theta\\) が高々可算集合で、 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= \\mathbb{I}\\{\\theta\\ne \\theta'\\}\\qquad\\forall\\theta,\\theta'\\in\\Theta\n\\end{align*}\\] と定義すると、ベイズリスク \\(\\rho(\\pi, \\widehat{\\theta})\\) は推定量 \\(\\widehat{\\theta}\\) の誤り確率 \\(P_\\mathrm{err}(\\widehat{\\theta})\\) である。\nその他の重要な損失関数の例として二乗誤差がある。 \\[\\begin{align*}\nL(\\theta,\\,\\theta') &= (\\theta-\\theta')^2.\n\\end{align*}\\]\n損失関数 \\(L\\) を定めたときに、ベイズリスクを最小化する推定量 \\[\\begin{align*}\n\\widehat{\\theta} &= \\arg\\min_{\\widehat{\\theta}} \\rho(\\pi, \\widehat{\\theta})\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(x\\mid\\theta)\\pi(\\theta)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)p(x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\iff \\widehat{\\theta}(x) &= \\arg\\min_{\\theta'\\in\\Theta} \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\\\\\n\\end{align*}\\] ここで、 \\[\\begin{align*}\n\\expt{L(\\theta,\\,\\theta')\\mid x}&=  \\sum_{\\theta\\in\\Theta} L(\\theta,\\,\\theta') p(\\theta\\mid x)\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を損失関数の事後平均という。 各 \\(x\\in\\mathcal{X}\\) について、\\(\\theta'=\\widehat{\\theta}(x)\\) が損失関数の事後平均を最小化するとき、ベイズリスクを最小化する。\n損失関数が \\(L(\\theta,\\,\\theta')\\) が各 \\(\\theta\\in\\Theta\\) を固定したときに \\(\\theta'\\) について凸関数であるとき、事後平均 \\(\\expt{L(\\theta,\\,\\theta')\\mid x}\\) も \\(\\theta'\\) について凸関数となる(凸関数の非負倍は凸関数であり、凸関数の和は凸関数なので)。 さらに、\\(L(\\theta,\\,\\theta')\\) が \\(\\theta'\\) について微分可能なとき、 \\[\\begin{align*}\n\\frac{\\partial \\expt{L(\\theta,\\,\\theta')\\mid x}}{\\partial\\, \\theta'}&=  \\sum_{\\theta\\in\\Theta} \\frac{\\partial L(\\theta,\\,\\theta')}{\\partial\\, \\theta'} p(\\theta\\mid x)=0\\qquad\\forall x\\in\\mathcal{X}\n\\end{align*}\\] を満たす \\(\\theta'\\) を \\(\\widehat{\\theta}(x)\\) として選択するのが最適である。 二乗誤差 \\(L(\\theta,\\,\\theta')=(\\theta-\\theta')^2\\) のとき、この条件は \\[\\begin{align*}\n0&=\\sum_{\\theta} 2(\\theta'-\\theta) p(\\theta\\mid x)\n=2\\left(\\theta' - \\sum_{\\theta}\\theta p(\\theta\\mid x)\\right)\n\\end{align*}\\] となり、 \\[\\begin{align*}\n\\widehat{\\theta}(x) &= \\sum_\\theta \\theta p(\\theta\\mid x)\n\\end{align*}\\] とするのが最適であることが分かる。この右辺の値をパラメータ \\(\\theta\\) の事後平均という。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>ベイズ推定</span>"
    ]
  },
  {
    "objectID": "testings.html",
    "href": "testings.html",
    "title": "8  仮説検定",
    "section": "",
    "text": "8.1 事前分布を仮定しない推定問題\nベイズ推定では推定したいパラメータ \\(\\theta\\in\\Theta\\) の事前分布 \\(\\pi(\\theta)\\) を既知として仮定した。 しかし、現実の問題ではこの事前分布を適切に仮定する方法がない場合もある。 例えば\nといった問題について事前分布をどのように仮定するのが適切か不明瞭である。 そのような状況でデータ \\(x\\in\\mathcal{X}\\) から パラメータ \\(\\theta\\in\\Theta\\) を推定する問題を考える。 尤度 \\(p(x\\mid\\theta)\\) は既知とする。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "testings.html#事前分布を仮定しない推定問題",
    "href": "testings.html#事前分布を仮定しない推定問題",
    "title": "8  仮説検定",
    "section": "",
    "text": "開発中の薬に効果があるかないか\nある患者が病気かどうか\nサイコロに偏りがあるかどうか",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "testings.html#伝統的な仮説検定",
    "href": "testings.html#伝統的な仮説検定",
    "title": "8  仮説検定",
    "section": "8.2 伝統的な仮説検定",
    "text": "8.2 伝統的な仮説検定\nパラメータの集合を二つの部分集合 \\(\\Theta_0\\) と \\(\\Theta_1\\) に分割する。 つまり、\\(\\Theta_0\\cup \\Theta_1 = \\Theta\\), \\(\\Theta_0\\cap \\Theta_1=\\varnothing\\) である。 そしてパラメータが \\(\\Theta_0\\) に属するか \\(\\Theta_1\\) に属するかを知りたいとする。 このとき二つの命題 \\[\\begin{align*}\nH_0\\colon \\theta\\in\\Theta_0\\\\\nH_1\\colon \\theta\\in\\Theta_1\n\\end{align*}\\] を仮説という。 その二つの仮説のうちの通常成り立っていると考える方を \\(H_0\\) とし(対応するパラメータ集合は \\(\\Theta_0\\)) 帰無仮説と呼ぶ。 また、そうでない方を \\(H_1\\) とし(対応するパラメータ集合は \\(\\Theta_1\\)) 対立仮説と呼ぶ。 帰無仮説の例として\n\n開発中の薬に効果はない\nある患者が病気ではない\nサイコロに偏りはない\n\nなどがある。 それらに対応する対立仮説はそれぞれ\n\n開発中の薬に効果がある\nある患者が病気である\nサイコロに偏りがある\n\nとなる。 仮説検定の考え方では帰無仮説を棄却するかしないかを決める。 帰無仮説を棄却した場合、対立仮説を正しいと考え、帰無仮説を棄却しなかった場合は何も言えないと結論づける。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "testings.html#単純仮説",
    "href": "testings.html#単純仮説",
    "title": "8  仮説検定",
    "section": "8.3 単純仮説",
    "text": "8.3 単純仮説\n仮説 \\(\\Theta_0\\) と \\(\\Theta_1\\) がそれぞれ一元集合であるとき、\\(H_0\\) と \\(H_1\\) を単純仮説という。 \\(\\Theta_0=\\{\\theta_0\\}\\), \\(\\Theta_1=\\{\\theta_1\\}\\) として、 \\(p_0(x)\\coloneqq p(x\\mid \\theta_0)\\) と \\(p_1(x)\\coloneqq p(x\\mid \\theta_1)\\) とする。 データから仮説を推定する関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) を検定関数という。 各 \\(x\\in\\mathcal{X}\\) について、\\(E(x)\\) は帰無仮説を棄却する確率とする。 この検定関数について二種類の誤り確率を \\[\\begin{align*}\n\\alpha_E &\\coloneqq \\expt{E(X)\\mid \\theta_0}=\\sum_x E(x) p(x\\mid \\theta_0)\\\\\n\\beta_E &\\coloneqq 1-\\expt{E(X)\\mid \\theta_1}=1-\\sum_x E(x) p(x\\mid \\theta_1)\\\\\n\\end{align*}\\] と定義する。 このとき、\\(\\alpha_E\\) は帰無仮説が正しいときに帰無仮説を棄却する確率であり、第一種誤り確率もしくは有意水準という。 また、\\(\\beta_E\\) は対立仮説が正しいときに帰無仮説を棄却しない確率であり、第二種誤り確率という。 第一種誤り確率だけを小さくしたければ \\(E(x) = 0\\) とすればよいし、第二種誤り確率だけを小さくしたければ \\(E(x)=1\\) とすればよい。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "testings.html#最強力検定",
    "href": "testings.html#最強力検定",
    "title": "8  仮説検定",
    "section": "8.4 最強力検定",
    "text": "8.4 最強力検定\n\n定義 8.1 検定関数 \\(E\\colon\\mathcal{X}\\to[0,1]\\) が有意水準 \\(\\alpha\\in[0,1]\\) の最強力検定 \\(\\defiff\\) \\(\\alpha_E=\\alpha\\) であり、任意の \\(F\\colon\\mathcal{X}\\to[0,1]\\) について、\\(\\alpha_F\\le\\alpha\\) ならば \\(\\beta_F\\ge\\beta\\) が成り立つ。\n\n実現可能な誤り確率 \\((\\alpha,\\,\\beta)\\) の集合 \\[\\begin{align*}\nC &= \\left\\{(\\alpha_E,\\,\\beta_E)\\mid E\\colon\\mathcal{X}\\to[0,1]\\right\\}\n\\end{align*}\\] について考える。 自明に \\((1,0)\\) と \\((0,1)\\) は実現可能である。\nこの集合 \\(C\\) は凸集合である。 \\[\\begin{align*}\n\\alpha_{pE + (1-p)F} &= p\\alpha_E + (1-p)\\alpha_F\\\\\n\\beta_{pE + (1-p)F} &= p\\beta_E + (1-p)\\beta_F\n\\end{align*}\\] であることから、 \\[\\begin{align*}\n\\begin{pmatrix}\n\\alpha_{pE + (1-p)F},& \\beta_{pE + (1-p)F}\n\\end{pmatrix}\n&= p \\begin{pmatrix}\\alpha_E,&\\beta_E\\end{pmatrix} + (1-p) \\begin{pmatrix}\\alpha_F,&\\beta_F\\end{pmatrix}\n\\end{align*}\\] が確認できる。 また、検定結果を反転させた検定関数 \\(1-E(x)\\) を考えると、 \\[\\begin{align*}\n\\begin{pmatrix}\n\\alpha_{1-E},& \\beta_{1-E}\n\\end{pmatrix}&=\n\\begin{pmatrix}\n1,&1\n\\end{pmatrix} -\n\\begin{pmatrix}\n\\alpha_{E},& \\beta_{E}\n\\end{pmatrix}\n\\end{align*}\\] である。\nまとめると、実現可能な \\((\\alpha,\\,\\beta)\\) の集合 \\(C\\) は\n\n\\((1,0),\\,(0,1)\\in C\\)\n\\(C\\) は 凸集合\n\\((\\alpha,\\,\\beta)\\in C\\iff (1-\\alpha,\\,1-\\beta)\\in C\\)\n\nを満たす。\n\n\nコード\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 区間 [0,1] でプロット\nx = np.linspace(0, 1, 400)\ny1 = 1-np.sqrt(1-(1-x)**2)\ny2 = np.sqrt(1-x**2)\n\nplt.figure()\n\n# 2 本の曲線\nplt.plot(x, y1)\nplt.plot(x, y2)\n\n# 間の領域を塗る\nplt.fill_between(x, y1, y2, where=(y2 &gt;= y1), alpha=0.3)\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"$\\\\alpha$\")\nplt.ylabel(\"$\\\\beta$\")\nplt.tight_layout()\n\nax = plt.gca()\nax.set_aspect(\"equal\", adjustable=\"box\")\n\n\n\n\n\n\n\n\n図 8.1: 実現可能な \\((\\alpha,\\,\\beta)\\) の集合の例\n\n\n\n\n\n各 \\(\\alpha\\in[0,1]\\) について、\\(\\beta\\) を最小化するのが最強力検定であるので、この図の下のカーブが最強力検定で実現される \\((\\alpha,\\,\\beta)\\) となる。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "testings.html#尤度比検定",
    "href": "testings.html#尤度比検定",
    "title": "8  仮説検定",
    "section": "8.5 尤度比検定",
    "text": "8.5 尤度比検定\nベイズ推定の枠組みではMAP推定量が誤り確率を最小化する推定量であった。 このMAP推定量は \\[\\begin{align*}\nE_\\mathrm{MAP}(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}\\ge \\frac{\\pi(\\theta_1)}{\\pi(\\theta_0)}\\\\\n1&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] と表すことができる。\n一般的に \\(\\eta &gt; 0,\\,\\kappa\\in[0,1]\\) について \\[\\begin{align*}\nE(x) &=\\begin{cases}\n0&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&gt; \\eta\\\\\n1&\\text{if } \\frac{p(x\\mid\\theta_0)}{p(x\\mid\\theta_1)}&lt; \\eta\\\\\n\\kappa&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] という形の検定関数を尤度比検定という。\n\n補題 8.1 (ネイマン・ピアソンの補題) 任意の尤度比検定は最強力検定である(逆も成り立つ)。\n\n\n証明. 尤度比検定 \\(E\\) における尤度比の閾値を \\(\\eta&gt; 0\\) とする。 任意の \\(F\\colon \\mathcal{X}\\to[0,1]\\) について \\[\\begin{align*}\n&(F(x) - E(x)) (p_0(x) - \\eta p_1(x))\\ge 0\\qquad \\forall x\\in\\mathcal{X}\\\\\n\\iff&F(x)p_0(x) - E(x)p_0(x) - \\eta F(x) p_1(x) + \\eta E(x) p_1(x)\\ge 0\\qquad \\forall x\\in\\mathcal{X}\\\\\n\\implies&\\alpha_F - \\alpha_E - \\eta (1-\\beta_F)  + \\eta (1-\\beta_E)\\ge 0\\\\\n\\iff&(\\alpha_F - \\alpha_E) + \\eta(\\beta_F-\\beta_E)\\ge 0.\n\\end{align*}\\] よって \\(\\alpha_F\\le\\alpha_E\\) ならば \\(\\beta_F\\ge\\beta_E\\) である。\n\nデータ \\(\\mathcal{X}\\) が連続な場合は確率質量関数の代わりに確率密度関数を考える。\n\n例 8.1 コインを持っており、表が出る確率は \\(p_0\\) か \\(p_1\\) のどちらかである。 コインを独立に \\(N\\) 回投げて表が出る確率が \\(p_0\\) か \\(p_1\\) かを推定したい。 \\(\\mathcal{X}=\\{0,1\\}^N\\) とし、0 は裏、1 は表に対応するものとする。 このとき尤度は \\[\\begin{align*}\np(\\mathbf{x}\\mid p_k) &= \\prod_{i=1}^N p_k^{x_i} (1-p_k)^{1-x_i}\\qquad\\text{for } k\\in\\{0,1\\}\n\\end{align*}\\] である。 このとき尤度比は \\[\\begin{align*}\n\\frac{p(\\mathbf{x}\\mid p_0)}{p(\\mathbf{x}\\mid p_1)} &= \\frac{\\prod_i p_0^{x_i}(1-p_0)^{1-x_i}}{\\prod_i p_1^{x_i}(1-p_1)^{1-x_i}}\\\\\n&= \\left(\\frac{p_0}{p_1}\\right)^{\\sum_i x_i}\\left(\\frac{1-p_0}{1-p_1}\\right)^{N-\\sum_i x_i}\n\\end{align*}\\] である。 よって尤度比は表が出た回数 \\(T(\\mathbf{x})=\\sum_i x_i\\) から定まる。 なので \\(p_1&gt; p_0\\) とすると、表が出た回数が多いときに \\(E(\\mathbf{x}) = 1\\) とすることになる。",
    "crumbs": [
      "統計学",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>仮説検定</span>"
    ]
  },
  {
    "objectID": "large_numbers.html",
    "href": "large_numbers.html",
    "title": "9  大数の法則と集中不等式",
    "section": "",
    "text": "9.1 大数の弱法則\n表が出る確率が \\(1/2\\) のコインを100回独立に投げたときに表が出る回数は大体50回くらいになるだろう。 それを一般的な形で述べたものが大数の法則である。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#大数の弱法則",
    "href": "large_numbers.html#大数の弱法則",
    "title": "9  大数の法則と集中不等式",
    "section": "",
    "text": "定理 9.1 (大数の弱法則(分散有限を仮定)) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 このとき、任意の \\(\\epsilon&gt;0\\) について \\[\\begin{align*}\n\\lim_{N\\to\\infty}\\Pr\\left(\\left|\\frac1N\\sum_{k=1}^N X_k-\\expt{X}\\right|\\ge\\epsilon\\right) &= 0\n\\end{align*}\\] が成り立つ。\n\n\n証明. \\[\\begin{align*}\n\\Pr\\left(\\left|\\frac1n\\sum_{k=1}^N X_k-\\expt{X}\\right|\\ge\\epsilon\\right)\n&=  \\Pr\\left(\\left(\\frac1N\\sum_{k=1}^N X_k-\\expt{X}\\right)^2\\ge\\epsilon^2\\right) \\\\\n&=  \\Pr\\left(\\left(\\sum_{k=1}^N X_k-N\\expt{X}\\right)^2\\ge\\epsilon^2N^2\\right) \\\\\n&\\le \\frac{N\\var{X}}{\\epsilon^2N^2}\n= \\frac{\\var{X}}{\\epsilon^2N}\\longrightarrow 0.\n\\end{align*}\\]",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#チェルノフ上界",
    "href": "large_numbers.html#チェルノフ上界",
    "title": "9  大数の法則と集中不等式",
    "section": "9.2 チェルノフ上界",
    "text": "9.2 チェルノフ上界\n上記の大数の弱法則の証明では確率が0に収束するスピートは \\(O(1/N)\\) であった。 より詳しく確率が0にいくスピードを解析しよう。\n\n補題 9.1 (チェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(X\\le a\\right) &\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}=\\mathrm{e}^{K_X(t)-at}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\n証明. \\(t=0\\) のときは不等式の右辺は1となるので、不等式は自明に成り立つ。 任意の \\(t&gt;0\\) について、 \\[\\begin{align*}\n\\Pr\\left(X\\ge a\\right) &= \\Pr\\left(\\mathrm{e}^{tX}\\ge \\mathrm{e}^{ta}\\right)\\\\\n&\\le \\frac{M_X(t)}{\\mathrm{e}^{at}}\\qquad(\\text{マルコフの不等式}).\n\\end{align*}\\] が成り立つ。 もう一つの不等式も同様に示すことができる。\n\nマルコフの不等式は非負の確率変数にしか適用できないが、チェルノフ上界は任意の確率変数に適用できる。\n\n補題 9.2 (確率変数の和に対するチェルノフ上界) 任意の確率変数 \\(X\\) と \\(a\\in\\mathbb{R}\\) について、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\ge a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\ge 0\\\\\n\\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\le a\\right) &\\le \\mathrm{e}^{-(at-K_X(t))N}\\qquad\\forall t\\le 0.\n\\end{align*}\\]\n\n\n証明. \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\ge a\\right) &= \\Pr\\left(\\sum_{k=1}^N X_k\\ge aN\\right)\\\\\n&\\le \\mathrm{e}^{K_{\\sum_k X_k}(t) - atN}\\qquad\\text{(チェルノフ上界)}\\\\\n&= \\mathrm{e}^{(K_X(t) - at)N}\\qquad\\left(K_{\\sum_k X_k}(t) = \\sum_k K_{X_k}(t) = N K_X(t)\\right).\n\\end{align*}\\]\n\nこのようにチェルノフ上界を使うと \\(N\\) について指数関数の上界が得られる。 係数 \\(at-K_X(t)\\) が正であれば、確率は指数関数的に小さいことになる。 ここで、最適な \\(t\\) を選ぶことで、この係数 \\(at-K_X(t)\\) を最大化することを考える。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#キュムラント母関数の性質",
    "href": "large_numbers.html#キュムラント母関数の性質",
    "title": "9  大数の法則と集中不等式",
    "section": "9.3 キュムラント母関数の性質",
    "text": "9.3 キュムラント母関数の性質\nキュムラント母関数 \\[\\begin{align*}\nK_X(t) &= \\log M_X(t) = \\log\\expt{\\mathrm{e}^{tX}}\n\\end{align*}\\] の性質を改めて考えよう。 発散する場合は \\(+\\infty\\) に値を取るとみなして \\(K_X\\colon \\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) と考えることにする。\nまず、\\(K_X(0)=0\\) である。\nある \\(t&gt;0\\) について、 \\(M_X(t)&lt;+\\infty\\) と仮定すると、任意の \\(s\\in(0,t)\\) について \\[\\begin{align*}\nM_X(s) &= \\expt{\\mathrm{e}^{sX}}\\\\\n&= \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X\\ge 0\\}}}\n+ \\expt{\\mathrm{e}^{sX} \\mathbb{1}_{\\{X&lt; 0\\}}}\\\\\n&\\le \\expt{\\mathrm{e}^{tX} \\mathbb{1}_{\\{X\\ge 0\\}}} + 1\\\\\n&\\le M_X(t) + 1 &lt; +\\infty\n\\end{align*}\\] である。 同様に、ある \\(t&lt;0\\) について、 \\(M_X(t)&lt;+\\infty\\) と仮定すると、任意の \\(s\\in(t,0)\\) について \\(M_X(s)&lt;+\\infty\\) である。 よって、\\(M_X(t)\\) や \\(K_X(t)\\) が有限となる範囲は0を含む区間となる。 ここでいう区間とは一般的に空集合、もしくは \\(a&lt; b\\) について、 \\[\\begin{align*}\n[a,\\,a]\\quad\n(a,\\,b)\\quad\n[a,\\,b)\\quad\n(a,\\,b]\\quad\n[a,\\,b]\\quad\n(a,\\,+\\infty)\\quad\n[a,\\,+\\infty)\\quad\n(-\\infty,\\, b)\\quad\n(-\\infty,\\, b]\\quad\n(-\\infty,\\,+\\infty)\n\\end{align*}\\] のいずれかの形の集合を指す。 この区間を \\[\\begin{align*}\n\\mathrm{dom}(K_X) &\\coloneqq\\left\\{t\\in\\mathbb{R}\\mid K_X(t)&lt;+\\infty\\right\\}\n\\end{align*}\\] と表す。 区間は1次元の凸集合と一言で理解できる。\n証明はしないが、キュムラント母関数 \\(K_X(t)\\) は \\(\\mathrm{dom}(K_X)\\) の内点で何回でも微分可能であり、無限和や積分を取る前に微分しても構わない。\n\\[\\begin{align*}\n\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d}t} &= \\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\\\\n\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d}t^2} &= \\frac{\\expt{X^2\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tX}}-\\expt{X\\mathrm{e}^{tX}}^2}{\\expt{\\mathrm{e}^{tX}}^2}\\\\\n&= \\frac{\\expt{X^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}-\\left(\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\\\\n&= \\frac{\\expt{\\left(X-\\frac{\\expt{X\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\right)^2\\mathrm{e}^{tX}}}{\\expt{\\mathrm{e}^{tX}}}\\ge 0\n\\end{align*}\\] ここで確率変数 \\(Z_t\\) を導入し、確率質量関数 \\[\\begin{align*}\nf_{Z_t}(x) &= \\frac{f_X(x)\\mathrm{e}^{tx}}{\\sum_x f_X(x)\\mathrm{e}^{tx}}\n\\end{align*}\\] を持つものとすると、 \\[\\begin{align*}\n\\frac{\\mathrm{d} K_X(t)}{\\mathrm{d}t} &= \\expt{Z_t}\\\\\n\\frac{\\mathrm{d}^2 K_X(t)}{\\mathrm{d}t^2} &= \\var{Z_t}\n\\end{align*}\\] であることが分かる。 また、\\(X\\)が決定的(\\(\\Pr(X=\\expt{X})=1\\))でない限り、\\(K_X\\) は \\(\\mathrm{dom}(K_X)\\) で狭義凸である。\nよって \\(X\\) のキュムラント母関数 \\(K_X(t)\\) が原点付近で存在すると仮定すると、\\(K_X(t)\\) は\n\n0を含む区間で定義され、\n原点を通り、\n凸関数で、\n原点の傾きは \\(\\expt{X}\\)\n\nであることが分かる。\n\n\n\n\n\n\nノート\n\n\n\n関数 \\(f\\colon\\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) が下半連続であるとは、 任意の \\(\\alpha\\in\\mathbb{R}\\) について \\(\\{t\\in\\mathbb{R}\\mid f(t)\\le\\alpha\\}\\) が閉集合であることをいう。 キュムラント母関数は下半連続の凸関数である。\n\n\nまた、キュムラント母関数の簡単な性質として以下が成り立つ。 任意の独立確率変数 \\(X\\) と \\(Y\\) と \\(a\\in\\mathbb{R}\\) について \\[\\begin{align*}\nK_{X+a}(t) &= \\log\\expt{\\mathrm{e}^{t(X+a)}} = \\log\\left(\\expt{\\mathrm{e}^{tX}}\\cdot \\mathrm{e}^{ta}\\right) = K_X(t) + at\\\\%\\quad\\text{for } t\\in\\mathrm{dom}(K_X)\\\\\nK_{aX}(t) &= \\log\\expt{\\mathrm{e}^{t(aX)}} = K_X(at)\\\\%\\qquad\\text{if } at\\in\\mathrm{dom}(K_X)\\\\\nK_{X+Y}(t) &= \\log\\expt{\\mathrm{e}^{t(X+Y)}} =\\log\\left(\\expt{\\mathrm{e}^{tX}}\\expt{\\mathrm{e}^{tY}}\\right) = K_X(t) + K_Y(t).\n%&\\hspace{17em}\\text{for } t\\in\\mathrm{dom}(K_X)\\cap\\mathrm{dom}(K_Y)\n\\end{align*}\\]",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#キュムラント母関数の例",
    "href": "large_numbers.html#キュムラント母関数の例",
    "title": "9  大数の法則と集中不等式",
    "section": "9.4 キュムラント母関数の例",
    "text": "9.4 キュムラント母関数の例",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#ルジャンドル変換",
    "href": "large_numbers.html#ルジャンドル変換",
    "title": "9  大数の法則と集中不等式",
    "section": "9.5 ルジャンドル変換",
    "text": "9.5 ルジャンドル変換\nチェルノフ上界に現れる係数 \\(at-K_X(t)\\) の最大化はルジャンドル変換を用いて \\(K_X^*(a)\\) と表せる。 ルジャンドル変換を定義する際は \\(+\\infty\\) という値を許して \\((-\\infty,\\,+\\infty]\\) を値域として考えると都合がよい。 このように \\(+\\infty\\) を値として許した場合にも凸性を通常の関数と同じように定義する。 一般に区間上で定義された凸関数を実数全体に拡張し、元の定義域の外で \\(+\\infty\\) を取ることにするとやはり凸関数になる。 また、\\(f\\colon\\mathbb{R}\\to(-\\infty,\\,+\\infty]\\) の有効領域を \\[\\begin{align*}\n\\mathrm{dom}(f) &\\coloneqq\\left\\{x\\in\\mathbb{R}\\mid f(x)&lt;+\\infty\\right\\}\n\\end{align*}\\] と定義する。 凸関数の有効領域は区間になる。\n\n定義 9.1 (ルジャンドル変換)  \n\n恒等的に \\(+\\infty\\) ではない凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) を以下で定義する。 \\[\\begin{align*}\nf^*(a) &\\coloneqq \\sup_{t\\in \\mathbb{R}}\\left\\{at-f(t)\\right\\}.\n\\end{align*}\\]\n\nルジャンドル変換において \\(f\\) は凸関数なので、\\(at-f(t)\\) は凹関数(上に凸の関数)になる。 簡単のため \\(f\\) が \\(\\mathrm{dom}(f)\\) の内点で微分可能であると仮定しよう(キュムラント母関数はこの仮定は満たす)。 このとき、\n\n\\(at-f(t)\\) の微分が 0 になる点、つまり \\(f'(t_a) = a\\) を満たす \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在するとき、\\(t_a\\) で \\(at-f(t)\\) は最大化される。\nそのような \\(t_a\\in \\mathrm{dom}(f)^\\circ\\) が存在しないときは、\\(\\mathrm{dom}(f)\\) の端への極限で \\(\\sup\\) が達成される。\n\n凸関数は \\(\\mathrm{dom}(f)\\) の上では接線の集合で表すことができる。 接線 \\(ax+b\\) は傾き \\(a\\) と切片 \\(b\\) のペアで表すことができる。 傾き \\(a\\) を持つ \\(f\\) の接線は \\[\\begin{align*}\na(x-t_a) + f(t_a) &= ax - (at_a - f(t_a)) = ax - f^*(a)\n\\end{align*}\\] この傾き \\(a\\) から接線 \\(ax+b\\) の切片の \\(-1\\)倍である \\(-b\\) への関数が \\(f^*\\) である。\n例えば \\(f\\) が0で微分可能であるとき \\[\\begin{align*}\nf^*(f'(0)) &= 0\n\\end{align*}\\] である。\nまた、ルジャンドル変換 \\(f^*\\) は凸関数である。\n\n補題 9.3 凸関数 \\(f\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) のルジャンドル変換 \\(f^*\\colon \\mathbb{R}\\to (-\\infty,\\,+\\infty]\\) は凸関数である。\n\n\n証明. 任意の \\(a_1,a_2\\in \\mathbb{R}\\) と \\(\\lambda\\in[0,1]\\) について \\[\\begin{align*}\nf^*(\\lambda a_1+ (1-\\lambda)a_2) &= \\sup_{t\\in \\mathbb{R}}\\left\\{(\\lambda a_1+(1-\\lambda)a_2)t - f(t)\\right\\}\\\\\n&= \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))+(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\sup_{t\\in \\mathbb{R}}\\left\\{\\lambda (a_1t - f(t))\\right\\}+\\sup_{t\\in \\mathbb{R}}\\left\\{(1-\\lambda)(a_2t - f(t))\\right\\}\\\\\n&\\le \\lambda f^*(a_1) + (1-\\lambda) f^*(a_2).\n\\end{align*}\\]\n\nルジャンドル変換を凸でない関数 \\(f\\) についても同様に定義した場合でも、ルジャンドル変換 \\(f^*\\) は同様に凸関数となる。\n\n\n\n\n\n\nノート\n\n\n\nまたルジャンドル変換 \\(f^*\\) は下半連続である。 ルジャンドル変換は凸で下半連続な関数を凸で下半連続な関数に写す。 また、凸で下半連続な関数 \\(f\\) について \\(f=f^{**}\\) である。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "large_numbers.html#クラメールの定理",
    "href": "large_numbers.html#クラメールの定理",
    "title": "9  大数の法則と集中不等式",
    "section": "9.6 クラメールの定理",
    "text": "9.6 クラメールの定理\n\n補題 9.4 (イェンセンの不等式) 任意の凸関数 \\(f\\colon\\mathbb{R}\\to\\mathbb{R}\\) と確率変数 \\(X\\) について\n\\[\\begin{align*}\n\\expt{f(X)} &\\ge f(\\expt{X}).\n\\end{align*}\\]\n\n\n証明 (\\(X\\) の像が有限のときの証明). 確率変数 \\(X\\) は \\(k=1,2,\\dotsc,m\\) について確率 \\(p_k\\) で値 \\(a_k\\) をとると仮定する。 \\(m\\) についての帰納法で示す。\\(m=1\\) のときは明らかに成り立つ。 \\(X\\) の像のサイズが \\(m\\) 未満のときにイェンセンの不等式が成り立つと仮定すると、 \\[\\begin{align*}\n\\expt{f(X)} &= \\sum_{k=1}^m p_k f(a_k)\n= \\left(\\sum_{k=1}^{m-1}p_k\\right)\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell} f(a_k) + p_m f(a_m)\\\\\n&\\ge \\left(\\sum_{k=1}^{m-1}p_k\\right) f\\left(\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell}a_k\\right) + p_m f(a_m)\\quad\\text{(帰納法の仮定)}\\\\\n&\\ge  f\\left(\\left(\\sum_{k=1}^{m-1}p_k\\right)\\sum_{k=1}^{m-1} \\frac{p_k}{\\sum_{\\ell=1}^{m-1}p_\\ell}a_k + p_ma_m\\right)\\quad\\text{($f$の凸性)}\\\\\n&= f\\left(\\sum_{k=1}^m p_ka_k\\right) = f(\\expt{X}).\n\\end{align*}\\]\n\n補題 9.2 の右辺を \\(t\\) について最小化することを考えよう。\n\n補題 9.5 レート関数 \\(I_X\\colon \\mathbb{R} \\to[0,\\,+\\infty]\\)を \\[\\begin{align*}\nI_X(a) &:= K_X^*(a) = \\sup_{t \\in\\mathbb{R}}\\left\\{at - K_X(t)\\right\\}\n\\end{align*}\\] と定義する。 このとき、\n\n\\(\\mathrm{dom}(K_X)=\\{0\\}\\) のとき、\\(I_X(a) = 0\\).\nある \\(\\epsilon&gt;0\\) が存在して \\(K_X(\\epsilon)&lt;+\\infty\\) のとき、\\(\\mathbb{E}[X]&lt;+\\infty\\) であり、 \\[\\begin{align*}\n\\sup_{t\\ge0}\\left\\{at-K_X(t)\\right\\}&=\\begin{cases}\nI_X(a)&\\text{if } a &gt; \\expt{X}\\\\\n0&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\nある \\(\\epsilon&gt;0\\) が存在して \\(K_X(-\\epsilon)&lt;+\\infty\\) のとき、\\(\\mathbb{E}[X]&gt;-\\infty\\) であり、 \\[\\begin{align*}\n\\sup_{t\\le0}\\left\\{at-K_X(t)\\right\\}&=\\begin{cases}\nI_X(a)&\\text{if } a &lt; \\expt{X}\\\\\n0&\\text{otherwise.}\n\\end{cases}\n\\end{align*}\\]\n\n\n\n証明. 1 は自明。 2 を示す。 ある \\(\\epsilon&gt;0\\) について、\\(K_X(\\epsilon)&lt;+\\infty\\) と仮定する。 一般に、 \\[\\begin{align*}\n\\mathrm{e}^{tx} &\\ge tx + 1\\qquad\\forall t,x\\in\\mathbb{R}\n\\end{align*}\\] より、\\(M_X(t)\\ge t\\expt{X}+1\\) である。 よって、 \\[\\begin{align*}\n\\expt{X}&\\le \\frac{M_X(\\epsilon)-1}{\\epsilon}&lt;+\\infty\n\\end{align*}\\] である。 また、イェンセンの不等式より、 \\[\\begin{align*}\nK_X(t) &= \\log \\expt{\\mathrm{e}^{tX}} \\ge \\expt{\\log\\mathrm{e}^{tX}} = t\\expt{X}\\qquad\\forall t\\in\\mathbb{R}\n\\end{align*}\\] である。 よって、 \\[\\begin{align*}\nI_X(\\expt{X}) &= \\sup_{t\\in\\mathbb{R}} \\left\\{t\\expt{X} - K_X(t)\\right\\} = 0\n\\end{align*}\\] である。 任意の \\(a &gt; \\expt{X}\\) と \\(t&lt;0\\) について、 \\[\\begin{align*}\nta - K_X(t) &\\le t\\expt{X} - K_X(t) \\le 0\n\\end{align*}\\] であるので、任意の \\(a &gt; \\expt{X}\\) について \\[\\begin{align*}\nI_X(a) &:= \\sup_{t \\in\\mathbb{R}}\\left\\{at - K_X(t)\\right\\}\n= \\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\}\n\\end{align*}\\] また、\\(\\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\}\\) は \\(a\\) について単調なので、 任意の \\(a &lt; \\expt{X}\\) について \\[\\begin{align*}\n\\sup_{t\\ge 0}\\left\\{at - K_X(t)\\right\\} &= 0\n\\end{align*}\\] である。\n3 は 2 と同様に示せる。\n\n\nよってチェルノフ上界を最適化することで確率の指数的な上界を得る。\n\n定理 9.2 (最適化されたチェルノフ上界) 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 このとき、 \\[\\begin{align*}\n\\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\ge a\\right) &\\le \\mathrm{e}^{-I_X(a)N}\\qquad\\forall a&gt;\\expt{X}\\\\\n\\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\le a\\right) &\\le \\mathrm{e}^{-I_X(a)N}\\qquad\\forall a&lt;\\expt{X}.\n\\end{align*}\\]\n\nこの指数は漸近的に最適である。証明は少し難しいので紹介しない。\n\n定理 9.3 (クラメールの定理) 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 このとき、 \\[\\begin{align*}\n\\lim_{N\\to\\infty}\\frac1N\\log \\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\ge a\\right) &= -I_X(a)\\qquad\\forall a&gt;\\expt{X}\\\\\n\\lim_{N\\to\\infty}\\frac1N\\log \\Pr\\left(\\frac1N\\sum_{k=1}^N X_k\\le a\\right) &= -I_X(a)\\qquad\\forall a&lt;\\expt{X}.\n\\end{align*}\\]",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>大数の法則と集中不等式</span>"
    ]
  },
  {
    "objectID": "clt.html",
    "href": "clt.html",
    "title": "10  正規分布と中心極限定理",
    "section": "",
    "text": "10.1 確率変数の収束\nこの確率収束を使うと大数の弱法則は以下のように表せる。\n一方でより弱い収束の定義に法則収束という概念がある。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "clt.html#確率変数の収束",
    "href": "clt.html#確率変数の収束",
    "title": "10  正規分布と中心極限定理",
    "section": "",
    "text": "定義 10.1 (確率変数の確率収束) 共通の確率空間 \\((\\Omega,\\,P)\\) 上の確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) を考える。 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) が同じ確率空間上の確率変数 \\(X\\) に確率収束する \\(\\defiff\\) \\[\\begin{align*}\n\\lim_{n\\to\\infty} \\Pr\\left(\\left|X_n-X\\right|&gt;\\epsilon\\right)= 0\\qquad\\forall\\epsilon&gt;0\n\\end{align*}\\]\nまた、このとき \\(X_n\\overset{p}{\\longrightarrow} X\\) と表す。\n\n\n\n定理 10.1 (大数の弱法則(分散有限を仮定)) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 このとき、 \\[\\begin{align*}\n\\frac1N\\sum_{k=1}^N X_k\\overset{p}{\\longrightarrow}\\expt{X}\\qquad\\text{as } N\\to\\infty.\n\\end{align*}\\]\n\n\n\n定義 10.2 (確率変数の法則収束) 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) を考える。これらの確率変数は確率空間 \\((\\Omega,\\,P)\\) を共有している必要はない(同時確率を考えるわけではないので)。 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) が確率変数 \\(X\\) に法則収束する \\(\\defiff\\) \\(X\\) の累積分布関数 \\(F_X\\) のすべての連続点 \\(x\\in\\mathbb{R}\\) について \\[\\begin{align*}\n\\lim_{n\\to\\infty} F_{X_n}(x)= F_X(x)\n\\end{align*}\\]\nまた、このとき \\(X_n\\overset{d}{\\to} X\\) と表す。\n\n\n補題 10.1 共通の確率空間 \\((\\Omega,\\,P)\\) 上の確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) と確率変数 \\(X\\) について、 \\[\\begin{align*}\nX_n\\overset{p}{\\longrightarrow} X &\\implies\nX_n\\overset{d}{\\longrightarrow} X.\n\\end{align*}\\]\n\n\n証明. \\(X_n\\overset{p}{\\longrightarrow}X\\) を仮定する。 つまり、 \\[\\begin{align*}\n\\lim_{n\\to\\infty} \\Pr\\left(\\left|X_n-X\\right|&gt;\\epsilon\\right)= 0\\qquad\\forall\\epsilon&gt;0\n\\end{align*}\\] である。このとき、 \\[\\begin{align*}\nF_{X_n}(x)&=\\Pr(X_n\\le x)\\\\\n&\\le\\Pr(X\\le x+\\epsilon\\cup|X_n-X|&gt;\\epsilon)\\\\\n&\\le\\Pr(X\\le x+\\epsilon) + \\Pr(|X_n-X|&gt;\\epsilon)\n\\end{align*}\\] よって、 \\[\\begin{align*}\n\\limsup_{n\\to\\infty} F_{X_n}(x)&\\le F_X(x+\\epsilon)\\qquad\\forall x\\in\\mathbb{R}\\quad\\epsilon&gt;0.\n\\end{align*}\\] 同様に \\(X_n\\) と \\(X\\) を逆にすると、 \\[\\begin{align*}\nF_{X}(x)&=\\Pr(X\\le x)\\\\\n&\\le\\Pr(X_n\\le x+\\epsilon\\cup|X_n-X|&gt;\\epsilon)\\\\\n&\\le\\Pr(X_n\\le x+\\epsilon) + \\Pr(|X_n-X|&gt;\\epsilon)\n\\end{align*}\\] よって、 \\[\\begin{align*}\n\\liminf_{n\\to\\infty} F_{X_n}(x+\\epsilon)&\\ge F_X(x)\\qquad\\forall x\\in\\mathbb{R}\n\\end{align*}\\] つまり \\[\\begin{align*}\n\\liminf_{n\\to\\infty} F_{X_n}(x)&\\ge F_X(x-\\epsilon)\\qquad\\forall x\\in\\mathbb{R}\\quad\\epsilon&gt;0.\n\\end{align*}\\] これらのことから、 \\[\\begin{align*}\nF_X(x-\\epsilon)&\\le \\liminf_{n\\to\\infty} F_{X_n}(x) \\le\\limsup_{n\\to\\infty} F_{X_n}(x) \\le F_X(x+\\epsilon)\n\\qquad\\forall x\\in\\mathbb{R}\\quad\\epsilon&gt;0.\n\\end{align*}\\] よって \\(F_X\\) が \\(x\\) で連続なとき、\\(\\epsilon\\to 0\\) 極限を取ることで、 \\[\\begin{align*}\nF_X(x)&\\le \\liminf_{n\\to\\infty} F_{X_n}(x) \\le\\limsup_{n\\to\\infty} F_{X_n}(x) \\le F_X(x)\n\\end{align*}\\] となり、 \\[\\begin{align*}\n\\lim_{n\\to\\infty} F_{X_n}(x) = F_X(x)\n\\end{align*}\\] である。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "clt.html#中心極限定理",
    "href": "clt.html#中心極限定理",
    "title": "10  正規分布と中心極限定理",
    "section": "10.2 中心極限定理",
    "text": "10.2 中心極限定理\n大数の法則により \\(\\frac1N\\sum_{k=1}^N X_k\\) は期待値周辺に集中することが分かる。 また、クラメールの定理によりその集中のスピードも精密に評価することができる。\n一方で期待値周辺の挙動を \\[\\begin{align*}\n\\frac1{\\sqrt{N}}\\left(\\sum_{k=1}^N X_k-N\\expt{X}\\right)\n\\end{align*}\\] より詳しく見る。\n\n定理 10.2 (中心極限定理) 確率変数 \\(X\\) が分散を持つとする。 確率変数 \\(X_1,\\dotsc,X_N\\) が独立で \\(X\\) と同じ分布に従うとする。 また、確率変数 \\(Z\\) は期待値0分散1の正規分布 \\(N(0,1)\\) に従うものとする。 このとき、 \\[\\begin{align*}\n\\lim_{N\\to\\infty} \\Pr\\left(\\frac1{\\sqrt{N\\var{X}}}\\left(\\sum_{k=1}^N X_k-N\\expt{X}\\right)\\le x\\right)\n&= \\Pr(Z\\le x) \\qquad\\forall x\\in\\mathbb{R}.\n\\end{align*}\\]\n\n確率変数 \\(X_k\\) を期待値0分散1に正規化した確率変数 \\[\\begin{align*}\nY_k &\\coloneqq \\frac{X_k -\\expt{X}}{\\sqrt{\\var{X}}}\n\\end{align*}\\] を使うと、 \\[\\begin{align*}\n\\lim_{N\\to\\infty} F_{\\frac{\\sum_k Y_k}{\\sqrt{N}}}(x)\n&= F_Z(x)\\qquad\\forall x\\in\\mathbb{R}\n\\end{align*}\\]",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "clt.html#特性関数",
    "href": "clt.html#特性関数",
    "title": "10  正規分布と中心極限定理",
    "section": "10.3 特性関数",
    "text": "10.3 特性関数\n\n定義 10.3 確率変数 \\(X\\) について、特性関数 \\(\\varphi_X\\colon\\mathbb{R}\\to\\mathbb{C}\\) を以下で定義する。 \\[\\begin{align*}\n\\varphi_X(t) &\\coloneqq \\expt{\\mathrm{e}^{itX}}.\n\\end{align*}\\]\n\n\n定理 10.3 確率変数 \\(X,\\,Y\\) について \\[\\begin{align*}\n\\varphi_X = \\varphi_Y &\\iff F_X = F_Y.\n\\end{align*}\\]\n\n\n証明 (確率変数の像が有限の場合の証明). \\(\\mathrm{Image}(X)\\) と \\(\\mathrm{Image}(Y)\\) が有限の場合に限って証明を与える。 \\[\\begin{align*}\n\\{x_0,\\dotsc,x_{N-1}\\} &\\coloneqq \\mathrm{Image}(X) \\cup \\mathrm{Image}(Y)\n\\end{align*}\\] とする。 \\[\\begin{align*}\n\\varphi_X(t) &= \\sum_{k=0}^{N-1} f_X(x_k) \\mathrm{e}^{itx_k},&\n\\varphi_Y(t) &= \\sum_{k=0}^{N-1} f_Y(x_k) \\mathrm{e}^{itx_k}\n\\end{align*}\\] なので、 \\[\\begin{align*}\n0 = \\varphi_X(t) - \\varphi_Y(t) &= \\sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \\mathrm{e}^{itx_k}\n\\qquad\\forall t\\in\\mathbb{R}.\n\\end{align*}\\] よって、 \\[\\begin{align}\n\\sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \\mathrm{e}^{i\\ell x_k}&=0\\qquad\\forall \\ell\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align}\\] である。 ここで、\\(N\\times N\\) 実行列 \\(V\\) を \\[\\begin{align*}\nV_{\\ell k} &= \\mathrm{e}^{i\\ell x_k}\n\\qquad\\forall k,\\ell\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] とおく。 この行列 \\(V\\) は Vandermonde行列の転置であり正則なので、 \\[\\begin{align*}\n&\\sum_{k=0}^{N-1} V_{\\ell k} g_k=0\\qquad\\forall \\ell\\in\\{0,1,\\dotsc,N-1\\}\\\\\n\\implies& g_k = 0 \\qquad\\forall k\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] よって、 \\[\\begin{align*}\nf_X(x_k) &= f_Y(x_k) \\qquad\\forall k\\in\\{0,1,\\dotsc,N-1\\}\n\\end{align*}\\] である。",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "clt.html#特性関数の応用",
    "href": "clt.html#特性関数の応用",
    "title": "10  正規分布と中心極限定理",
    "section": "10.4 特性関数の応用",
    "text": "10.4 特性関数の応用\n正規分布の再生性は愚直に確率密度関数の畳み込みを計算しても確認できるが、特性関数と 定理 10.3 を用いると簡単に証明できる。\n\n補題 10.2 (正規分布の再生性) 独立確率変数 \\(X\\sim N(\\mu_0,\\,\\sigma_0^2)\\) と \\(Y\\sim N(\\mu_1,\\,\\sigma_1^2)\\) について \\(X+Y\\sim N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\).\n\n\n証明. \\[\\begin{align*}\n\\varphi_X(t) &= \\mathrm{e}^{i\\mu_0 t - \\frac12\\sigma_0^2 t^2}&\n\\varphi_Y(t) &= \\mathrm{e}^{i\\mu_1 t - \\frac12\\sigma_1^2 t^2}\n\\end{align*}\\] より、 \\[\\begin{align*}\n\\varphi_{X+Y}(t) &= \\varphi_X(t)\\varphi_Y(t) =\n\\mathrm{e}^{i(\\mu_0+\\mu_1) t - \\frac12(\\sigma_0^2+\\sigma_1^2) t^2}\n\\end{align*}\\] であるが、これは \\(N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\) の特性関数である。 よって、定理 10.3 より \\(X+Y\\sim N(\\mu_0+\\mu_1,\\,\\sigma_0^2+\\sigma_1^2)\\).\n\n\n補題 10.3 (ポアソン分布の再生性) 独立確率変数 \\(X\\sim \\mathrm{Poisson}(\\lambda_0)\\) と \\(Y\\sim \\mathrm{Poisson}(\\lambda_1)\\) について \\(X+Y\\sim \\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\).\n\n\n証明. \\[\\begin{align*}\n\\varphi_X(t) &= \\mathrm{e}^{\\lambda_0(\\mathrm{e}^{it}-1)}&\n\\varphi_Y(t) &= \\mathrm{e}^{\\lambda_1(\\mathrm{e}^{it}-1)}&\n\\end{align*}\\] より、 \\[\\begin{align*}\n\\varphi_{X+Y}(t) &= \\varphi_X(t)\\varphi_Y(t) =\n\\mathrm{e}^{(\\lambda_0+\\lambda_1)(\\mathrm{e}^{it}-1)}&\n\\end{align*}\\] であるが、これは \\(\\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\) の特性関数である。 よって、定理 10.3 より \\(X+Y\\sim \\mathrm{Poisson}(\\lambda_0+\\lambda_1)\\).",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "clt.html#中心極限定理の証明",
    "href": "clt.html#中心極限定理の証明",
    "title": "10  正規分布と中心極限定理",
    "section": "10.5 中心極限定理の証明",
    "text": "10.5 中心極限定理の証明\n中心極限定理の証明の概要を紹介する。\n定理 10.3 は特性関数が確率分布と一対一に対応していることを主張していた。\n\n定理 10.4 (レヴィの連続性定理) 確率変数の列 \\((X_n)_{n=1,2,\\dotsc,}\\) を考える。これらの確率変数は確率空間 \\((\\Omega,\\,P)\\) を共有している必要はない(同時確率を考えるわけではないので)。 確率変数列の特性関数列 \\((\\varphi_{X_n})_{n=1,2,\\dotsc}\\) が各点収束すると仮定する。 このとき、\n\\[\\begin{align*}\n\\varphi(t) &\\coloneqq \\lim_{n\\to\\infty} \\varphi_{X_n}(t).\n\\end{align*}\\]\nとおくと、ある確率変数 \\(X\\) が存在し、\\(\\varphi_X(t) = \\varphi(t)\\) であり、\\((X_n)_n\\) は \\(X\\) に法則収束する。\n\n\n定理 10.5 (テイラーの定理) 実関数 \\(f\\colon \\mathbb{R}\\to\\mathbb{R}\\) が \\(a\\in\\mathbb{R}\\) で \\(k\\ge 1\\) 回微分可能なとき、ある関数 \\(h\\colon\\mathbb{R}\\to\\mathbb{R}\\) で \\(\\lim_{x\\to a}h(x) = 0\\) であるものが存在し、 \\[\\begin{align*}\nf(x) &= \\sum_{s=0}^k\\frac{f^{(s)}(a)}{s!}(x-a)^s + h(x)(x-a)^k.\n\\end{align*}\\]\n\n\n証明 (中心極限定理の証明). 定理 10.4 より \\[\\begin{align*}\n\\lim_{N\\to\\infty} \\varphi_{\\frac{\\sum_k Y_k}{\\sqrt{N}}}(t) &= \\varphi_Z(t) = \\mathrm{e}^{-\\frac{t^2}2}\n\\end{align*}\\] を示せば十分である。\n\\[\\begin{align*}\n\\varphi_{\\frac{\\sum_k Y_k}{\\sqrt{N}}}(t)\n&= \\varphi_{\\sum_k Y_k}\\left(\\frac{t}{\\sqrt{N}}\\right)\\\\\n&= \\varphi_{Y}\\left(\\frac{t}{\\sqrt{N}}\\right)^N\\\\\n&= \\left(\\varphi_Y(0) + \\varphi'_Y(0)\\frac{t}{\\sqrt{N}} + \\frac{\\varphi''_Y(0)}2 \\left(\\frac{t}{\\sqrt{N}}\\right)^2 + o\\left(\\frac{1}{N}\\right)\\right)^N\\\\\n&= \\left(1 - \\frac{1}2 \\frac{t^2}{N} + o\\left(\\frac{1}{N}\\right)\\right)^N\\\\\n&\\to \\mathrm{e}^{-\\frac{t^2}2}.\n\\end{align*}\\]",
    "crumbs": [
      "漸近論",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>正規分布と中心極限定理</span>"
    ]
  },
  {
    "objectID": "markov.html",
    "href": "markov.html",
    "title": "12  マルコフ連鎖",
    "section": "",
    "text": "12.1 確率過程とマルコフ連鎖\n共通の確率空間 \\((\\Omega,\\,P)\\) 上の長さ無限の確率変数列 \\(X_0,X_1,X_2,\\dotsc\\) を離散時間確率過程という。 各時刻 \\(t=0,1,2,\\dotsc,\\) について、 \\(X_t\\) を時刻 \\(t\\) における状態と考える。 離散時間確率過程 \\(X_0,X_1,\\dotsc,\\) の各確率変数の像が有限集合 \\(S\\) であり、 任意の \\(t\\in\\mathbb{Z}_{\\ge 0}\\) と \\(x_0,\\dotsc, x_{t+1}\\in S\\) について \\[\\begin{align*}\n\\Pr(X_{t+1} = x_{t+1}\\mid X_{t} = x_t,\\dotsc,\\,X_1=x_1,\\,X_0=x_0)\n&= \\Pr(X_{t+1} = x\\mid X_{t} = x_t)\n\\end{align*}\\] を満たすとき、それを有限状態マルコフ連鎖という。 さらに、 \\[\\begin{align*}\n\\Pr(X_{t+1} = x_{t+1}\\mid X_{t} = x_t)\n\\end{align*}\\] が \\(t\\in\\mathbb{Z}_{\\ge 0}\\) に依存しないとき時間的に均一な有限状態マルコフ連鎖という。 以下では時間的に均一な有限状態マルコフ連鎖を考える。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>マルコフ連鎖</span>"
    ]
  },
  {
    "objectID": "markov.html#確率行列と状態遷移図",
    "href": "markov.html#確率行列と状態遷移図",
    "title": "12  マルコフ連鎖",
    "section": "12.2 確率行列と状態遷移図",
    "text": "12.2 確率行列と状態遷移図\n有限状態マルコフ連鎖の場合、状態 \\(S\\) は実数の有限部分集合と考えるより、単に有限集合と考えた方が自然な場合も多い。 例えば \\(S = \\{ 晴れ、曇り、雨\\}\\) や。 このとき、状態集合を便宜上 \\(S=\\{1,2,\\dotsc,n\\}\\) とおき、 \\[\\begin{align*}\np_{i,j} &= \\Pr(X_{t+1} = j\\mid X_{t} = i)\\qquad \\forall i,\\,j\\in S\n\\end{align*}\\] とする。 この \\(p_{i,j}\\) を \\((i,j)\\) 成分に持つ \\(n\\times n\\) 行列 \\(T\\) を遷移行列という。 遷移行列は非負行列であり、行和が1である。 一般に、この二つの条件を満たす正方行列を確率行列という。 確率行列は遷移行列とみなすことができる。\n一方で、初期確率からなる行ベクトル \\(\\pi\\in\\mathbb{R}^{|S|}\\) を初期状態ベクトルという。 つまり、行ベクトル \\(\\pi\\) の \\(i\\in S\\) 成分を \\(\\pi_i\\) とすると、 \\[\\begin{align*}\n\\pi_i &= \\Pr(X_0=i)\\qquad i\\in S\n\\end{align*}\\] である。\n初期状態ベクトル \\(\\pi\\) と確率行列 \\(T\\) からマルコフ連鎖は定義される。\n\n例 12.1 (天気のマルコフ連鎖) 状態集合 \\(S=\\{晴れ、曇り、雨\\}\\) 上のマルコフ連鎖を考える。 \\[\\begin{align*}\n\\Pr(X_0 = 晴れ) &= 1/3\\\\\n\\Pr(X_0 = 曇り) &= 1/2\\\\\n\\Pr(X_0 = 雨) &= 1/6\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=晴れ) &= 1/2\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=晴れ) &= 1/3\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=晴れ) &= 1/6\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=曇り) &= 1/4\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=曇り) &= 1/2\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=曇り) &= 1/4\\\\\n\\Pr(X_{t+1} = 晴れ\\mid X_t=雨) &= 1/3\\\\\n\\Pr(X_{t+1} = 曇り\\mid X_t=雨) &= 1/3\\\\\n\\Pr(X_{t+1} = 雨\\mid X_t=雨) &= 1/3\\\\\n\\end{align*}\\] と初期確率と遷移確率が与えられているとする。 このとき、 \\[\\begin{align*}\n晴れ&\\longleftrightarrow 1&\n曇り&\\longleftrightarrow 2&\n雨&\\longleftrightarrow 3&\n\\end{align*}\\] と対応させると、初期状態ベクトル \\(\\pi\\) と遷移行列 \\(T\\) は \\[\\begin{align*}\n\\pi&=\n\\begin{bmatrix}\n1/3&1/2&1/6\n\\end{bmatrix}&\nT&=\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\] である。\n\n確率の遷移確率を有向グラフで表したものを状態遷移図という。 上記の天気のマルコフ連鎖の状態遷移図は以下の通りである。 状態遷移図において遷移確率が0の有向辺は通常は描かない。\n\n\n\n\n\n\n\nMarkov\n\n\n\n1\n\n晴れ\n\n\n\n1-&gt;1\n\n\n1/2\n\n\n\n2\n\n曇り\n\n\n\n1-&gt;2\n\n\n1/3\n\n\n\n3\n\n雨\n\n\n\n1-&gt;3\n\n\n1/6\n\n\n\n2-&gt;1\n\n\n1/4\n\n\n\n2-&gt;2\n\n\n1/2\n\n\n\n2-&gt;3\n\n\n1/4\n\n\n\n3-&gt;1\n\n\n1/3\n\n\n\n3-&gt;2\n\n\n1/3\n\n\n\n3-&gt;3\n\n\n1/3",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>マルコフ連鎖</span>"
    ]
  },
  {
    "objectID": "markov.html#時刻-t-の確率分布",
    "href": "markov.html#時刻-t-の確率分布",
    "title": "12  マルコフ連鎖",
    "section": "12.3 時刻 \\(t\\) の確率分布",
    "text": "12.3 時刻 \\(t\\) の確率分布\n初期状態ベクトル \\(\\pi\\) と遷移行列 \\(T\\) が与えられているとき、\\(X_1\\) の確率は \\[\\begin{align*}\n\\Pr(X_1=j) &= \\sum_{i\\in S} \\Pr(X_0=i) \\Pr(X_1=j\\mid X_0=i)\\\\\n&=\\sum_{i\\in S} \\pi_i\\, p_{i, j}\\\\\n&=(\\pi T)_j\n\\end{align*}\\] と表せる。よって、 \\[\\begin{align*}\n\\Pr(X_t=j) &= (\\pi T^t)_j\n\\end{align*}\\] である。\n任意の遷移行列 \\(T\\) とすべて1の列ベクトル \\(\\mathrm{1}\\in\\mathbb{R}^{|S|}\\) について、 \\[\\begin{align*}\nT \\mathrm{1} = \\mathrm{1}\n\\end{align*}\\] である。  よって \\(I-T\\) は正則ではないので固有値1を持ち、対応する左固有ベクトル \\(\\mu\\) を持つ。 つまり、 \\[\\begin{align*}\n\\mu T = \\mu\n\\end{align*}\\] を満たす非零行ベクトル \\(\\mu\\) が存在する。 非負で成分の和が1の行ベクトル \\(\\mu\\) で \\(\\mu T = \\mu\\) を満たすものを定常確率ベクトルもしくは定常分布という。 現時点では定常確率ベクトルの存在は明らかではないが、任意の遷移行列 \\(T\\) について定常確率ベクトルが存在する。\n\n\n\n\n\n\nノート\n\n\n\n以下の不動点定理を認めると、定常確率ベクトルの存在が直ちに証明できる。\nブラウワーの不動点定理: ユークリッド空間のコンパクト凸集合 \\(K\\) からそれ自身への連続関数は不動点を持つ。\n\\(K\\) を非負で成分の和が1のベクトルの集合とおけばよい。\\(T\\) を右から掛けるという写像は連続写像なのでブラウワーの不動点定理が適用できる。\n\n\n\n例 12.2 (天気のマルコフ連鎖の定常確率ベクトル) \\[\\begin{align*}\nT&=\n\\begin{bmatrix}\n1/2&1/3&1/6\\\\\n1/4&1/2&1/4\\\\\n1/3&1/3&1/3\n\\end{bmatrix}\n\\end{align*}\\] のとき、 \\[\\begin{align*}\nI-T&=\n\\begin{bmatrix}\n1/2&-1/3&-1/6\\\\\n-1/4&1/2&-1/4\\\\\n-1/3&-1/3&2/3\n\\end{bmatrix}\n\\end{align*}\\] の左カーネルとして \\[\\begin{align*}\n\\mu&=\n\\begin{bmatrix}\n9/25&2/5&6/25\n\\end{bmatrix}\n\\end{align*}\\] が取れる。これは非負で成分の和が1なので、定常確率ベクトルである。 \\(I-T\\) のランクは2であり、これが唯一の定常確率ベクトルである。\n一方で、この例においては \\(T\\) を対角化することはできない。\n\n\n\n定義 12.1 (スペクトル半径) 正方行列 \\(A\\in\\mathbb{C}^{n\\times n}\\) について、その固有値の絶対値の最大値をスペクトル半径といい \\(\\rho(A)\\) で表す。\n\n\n\n\n\n\n\n注意\n\n\n\nスペクトルノルムはスペクトル半径と似た概念であるが異なるものである。 正方行列とは限らない行列 \\(A\\in\\mathbb{C}^{n\\times m}\\) のスペクトルノルムは \\[\\begin{align*}\n\\|A\\|_2&\\coloneqq \\max_{x\\in\\mathbb{C}^m \\setminus\\{0\\}} \\frac{\\|Ax\\|_2}{\\|x\\|_2}\n\\end{align*}\\] と定義される。 ここで、右辺の \\(\\|\\cdot\\|_2\\) は複素ユークリッド空間上の \\(L_2\\) ノルムを表す。ここで、 \\[\\begin{align*}\n\\|A\\|_2&=\n\\max_{x\\in\\mathbb{C}^m \\setminus\\{0\\}} \\left\\|A\\frac{x}{\\|x\\|_2}\\right\\|_2\\\\\n&=\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} \\left\\|Ax\\right\\|_2\\\\\n&=\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} \\sqrt{\\left\\|Ax\\right\\|_2^2}\\\\\n&=\\sqrt{\\max_{x\\in\\mathbb{C}^m\\colon\\, \\|x\\|_2=1} x^*A^*Ax}\\\\\n&=\\sqrt{\\lambda_{\\max}(A^*A)}\\\\\n&=\\sigma_{\\max}(A)\n\\end{align*}\\] である。\\(\\lambda_{\\max}\\) と \\(\\sigma_{\\max}\\) は最大固有値と最大特異値を表す。\n直感的な意味としては\n\nスペクトルノルム\\(\\colon\\) 線形写像 \\(A\\) が \\(L_2\\) ノルムをどれだけ大きくするか？\nスペクトル半径 \\(\\colon\\) 線形写像 \\(A\\) が向きを変えずに \\(L_2\\) ノルムをどれだけ大きくするか？\n\nということになる。 これらの意味から \\(\\|A\\|_2\\ge\\rho(A)\\) であることが分かる。 実際 \\(\\|A\\|_2\\) の定義の中で \\(x\\) として \\(A\\) の絶対値最大固有値に対応する固有ベクトルを選べばこの不等式が得られる。\n正方行列 \\(A\\in\\mathbb{C}^{n\\times n}\\) が正規行列のとき、スペクトル分解定理よりユニタリ行列 \\(U\\) と対角行列 \\(D\\) を用いて \\(A = UDU^*\\) と表せる。 このとき、\\(A^*A=UD^*DU^*\\) であることから、簡単な計算により \\(\\|A\\|_2=\\rho(A)\\) であることが分かる。\nしかし一般的には(対角化可能であっても)スペクトル半径とスペクトルノルムは異なる。 例えば、 \\[\\begin{align*}\nA&=\\begin{bmatrix}\n1&0\\\\\n1&0\n\\end{bmatrix}\n\\end{align*}\\] とすると、 \\(A\\) の固有値は 0 と 1 なので\\(\\rho(A)=1\\) である。 一方で、 \\[\\begin{align*}\nA^*A&=\n\\begin{bmatrix}\n2&0\\\\\n0&0\n\\end{bmatrix}\n\\end{align*}\\] より、\\(A^*A\\) の固有値は 0 と 2 である。 よって、\\(A\\) のスペクトルノルムは \\(\\|A\\|_2=\\sqrt{2} &gt; 1 =\\rho(A)\\) である。 ここで、\\(A\\) は確率行列であり、二つの異なる固有値を持つので対角化可能である。\nまた、スペクトル半径はノルムにもならない。 \\[\\begin{align*}\n\\rho\\left(\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}\\right) &= 0\n\\end{align*}\\] であるし、 \\[\\begin{align*}\n1&=\\rho\\left(\\begin{bmatrix}0&1\\\\1&0\\end{bmatrix}\\right) &gt;\n\\rho\\left(\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}\\right) +\n\\rho\\left(\\begin{bmatrix}0&0\\\\1&0\\end{bmatrix}\\right) = 0\n\\end{align*}\\] なので三角不等式も満たさない。\n\n\n\n補題 12.1 任意の確率行列 \\(T\\) について、\\(\\rho(T)=1\\) である。\n\n\n証明. すべての成分が1の列ベクトルは確率行列 \\(T\\) の固有値1に対する右固有ベクトルになるので、\\(\\rho(T)\\ge 1\\) である。\n以下では \\(\\rho(T)\\le 1\\) を示す。 遷移行列 \\(T\\) の固有値 \\(\\lambda\\in\\mathbb{C}\\) に対応する固有ベクトルを \\(v\\) とすると \\[\\begin{align*}\nTv &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の成分で絶対値最大のものを第 \\(i\\) 成分とする。 第 \\(i\\) 成分に注目すると \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j}v_j &= \\lambda v_i\n\\end{align*}\\] が成り立つ。ここで \\[\\begin{align*}\n|\\lambda| |v_i| &= \\left|\\sum_{j\\in S}T_{i,j}v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_j\\right|\\\\\n&\\le \\sum_{j\\in S}T_{i,j}\\left|v_i\\right|\\\\\n&=\\left|v_i\\right|\n\\end{align*}\\] と \\(|v_i|&gt;0\\) より、 \\(|\\lambda|\\le 1\\) である。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>マルコフ連鎖</span>"
    ]
  },
  {
    "objectID": "markov.html#マルコフ連鎖の例-グラフ上のランダムウォーク",
    "href": "markov.html#マルコフ連鎖の例-グラフ上のランダムウォーク",
    "title": "12  マルコフ連鎖",
    "section": "12.4 マルコフ連鎖の例: グラフ上のランダムウォーク",
    "text": "12.4 マルコフ連鎖の例: グラフ上のランダムウォーク\n\n定義 12.2 (グラフ) 有限集合 \\(V\\) と集合 \\(E\\subseteq \\{\\{u,v\\}\\mid u,\\, v\\in V, u\\ne v\\}\\) のペア \\(G=(V,\\,E)\\) を(無向単純)グラフという。 \\(V\\) の元を頂点、\\(E\\) の元を辺と呼ぶ。\n\nグラフ \\(G=(V,\\,E)\\) と \\(v\\in V\\) について、 \\[\\begin{align*}\nN(v)&\\coloneqq\\{u\\in V\\mid \\{u,v\\}\\in E\\}\n\\end{align*}\\] を頂点 \\(v\\) の近傍という。また、 \\[\\begin{align*}\nd_v&\\coloneqq|N(v)|\n\\end{align*}\\] を \\(v\\) の次数という。 次数0の頂点を孤立頂点という。\n\n定義 12.3 (グラフ上のランダムウォーク) 孤立頂点を持たないグラフ \\(G=(V=\\{1,2,\\dotsc,n\\},\\,E)\\) 上のランダムウォークは \\(S=V\\) であり、 任意の初期確率ベクトル \\(\\pi\\) と \\[\\begin{align*}\np_{i,j} &=\n\\begin{cases}\n\\frac1{d_i}&\\text{if } \\{i,j\\}\\in E\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] で定義される。\n\n\n補題 12.2 グラフ上のランダムウォークの遷移行列は対角化可能であり、固有値はすべて実数である。\n\n\n証明. グラフ \\(G\\) の次数行列を \\[\\begin{align*}\nD_{i,j} &= d_i\\delta_{i,j}\n\\end{align*}\\] と定義する。 ここで \\(\\delta_{i,j}\\) はクロネッカーのデルタである。 \\[\\begin{align*}\nQ &= \\sqrt{D} P \\sqrt{D}^{-1}\n\\end{align*}\\] とすると、その \\((i,j)\\) 成分は \\[\\begin{align*}\nQ_{i,j} &= \\sqrt{d_i} p_{i,j} \\frac1{\\sqrt{d_j}}\\\\\n&= \\begin{cases}\n\\sqrt{d_i} \\frac1{d_i} \\frac1{\\sqrt{d_j}} = \\frac1{\\sqrt{d_id_j}}&\\text{if } \\{i,j\\}\\in E\\\\\n0&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] である。よって\\(Q\\) は実対称行列であり、スペクトル分解定理より、直交行列で対角化でき、すべての固有値は実数である。 つまり、ある直交行列 \\(V\\) と実対角行列 \\(\\Lambda\\) が存在して \\[\\begin{align*}\nQ &= V\\Lambda V^T\n\\end{align*}\\] である。 よって、 \\[\\begin{align*}\nP &= \\sqrt{D}^{-1}Q\\sqrt{D} = \\sqrt{D}^{-1}V\\Lambda V^T\\sqrt{D}\n\\end{align*}\\] が成り立ち、\\(P\\) も対角化可能であり、固有値はすべて実数である。\n\n\\(T=U\\Lambda U^{-1}\\) と対角化できるとき、\\(t\\) ステップ後の確率は \\[\\begin{align*}\n\\pi T^t &= \\pi (U \\Lambda U^{-1})^t\\\\\n&= \\pi U \\Lambda^t U^{-1}\n\\end{align*}\\] と表せる。 \\(T\\) の固有値の絶対値は 1 以下であるので、グラフ上のランダムウォークの場合、\\(t\\to\\infty\\) 極限では \\(\\Lambda^t\\) は固有値 \\(\\pm1\\) の部分だけが残る。 特に固有値1が一つだけであり、固有値 \\(-1\\) を持たないとき、初期分布 \\(\\pi\\) によらず、唯一の定常分布 \\(\\mu\\) に収束する。 \\[\\begin{align*}\n\\lim_{t\\to\\infty} \\pi T^t  &= \\mu\n\\end{align*}\\]\n\n補題 12.3 グラフ上のランダムウォークの遷移行列 \\(T\\) に含まれる固有値1の重複度はグラフの連結成分の個数である。\n\n\n証明. まず、「固有値1の重複度 \\(\\ge\\) グラフの連結成分の個数」を証明する。 グラフの連結成分 \\(C\\subseteq V\\) について、列ベクトル \\(\\mathrm{1}_C\\) を成分のインデックスが \\(C\\) に含まれるとき1、そうでないとき 0 と定義する。 このとき、\\(T\\mathrm{1}_C=\\mathrm{1}_C\\) であるので、固有値1の右固有ベクトルとなる。 各連結成分 \\(C\\) について \\(\\mathrm{1}_C\\) は線形独立であるので、「固有値1の重複度 \\(\\ge\\) グラフの連結成分の個数」が示された。\n次に、「固有値1の重複度 \\(\\le\\) グラフの連結成分の個数」を証明する。 \\(v\\) を固有値1に対応する固有ベクトルとすると、 \\[\\begin{align*}\nTv &=  v\n\\end{align*}\\] が成り立つ。 これは \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j} v_j &=  v_i\\qquad\\forall i\\in V\n\\end{align*}\\] を意味する。 グラフの連結成分 \\(C\\subseteq V\\) を固定する。 そして、 \\[\\begin{align*}\ni &\\in \\arg\\max_{j\\in C} v_j\n\\end{align*}\\] とする。 このとき、 \\[\\begin{align*}\nv_i &= \\sum_{j\\in S}T_{i,j} v_j\\\\\n&\\le \\sum_{j\\in S}T_{i,j} v_i\\\\\n&= v_i\n\\end{align*}\\] という不等式が得られるが、この不等式が等号で満たされなければならない。 よって、\\(j\\in N(i)\\) について \\(v_j=v_i\\) であることが必要である。 よって \\(j\\in C\\) について \\(v_j=v_i\\) である必要がある。 したがって、グラフの連結成分を \\(C_1,\\dotsc,C_k\\) とすると \\[\\begin{align*}\nv&\\in\\mathrm{span}(\\mathrm{1}_{C_1},\\dotsc,\\mathrm{1}_{C_k})\n\\end{align*}\\] である。 以上のことから「固有値1の重複度 \\(\\le\\) グラフの連結成分の個数」が示された。\n\n\n補題 12.4 グラフ上のランダムウォークの遷移行列 \\(T\\) に含まれる固有値 \\(-1\\) の重複度はグラフの二部連結成分の個数である。\n\n\n証明. まず、「固有値 \\(-1\\) の重複度 \\(\\ge\\) グラフの二部連結成分の個数」を証明する。 グラフの二部連結成分 \\(L\\cup R\\subseteq V\\) について、列ベクトル \\(\\mathrm{1}_{L,R}\\) を成分のインデックスが \\(L\\) に含まれるとき \\(+1\\)、\\(R\\) に含まれるとき \\(-1\\)、それ以外のとき 0 と定義する。 このとき、\\(T\\mathrm{1}_{L,R}=-\\mathrm{1}_{L,R}\\) であるので、固有値\\(-1\\)の右固有ベクトルとなる。 各二部連結成分 \\(L\\cup R\\) について \\(\\mathrm{1}_{L,R}\\) は線形独立であるので、「固有値 \\(-1\\) の重複度 \\(\\ge\\) グラフの二部連結成分の個数」が示された。\n次に、「固有値 \\(-1\\) の重複度 \\(\\le\\) グラフの二部連結成分の個数」を証明する。 \\(v\\) を固有値 \\(-1\\) に対応する固有ベクトルとすると、 \\[\\begin{align*}\nTv &=  -v\n\\end{align*}\\] が成り立つ。 これは \\[\\begin{align*}\n\\sum_{j\\in S}T_{i,j} v_j &=  -v_i\\qquad\\forall i\\in V\n\\end{align*}\\] を意味する。 グラフの二部連結成分 \\(L\\cup R\\subseteq V\\) を固定する。 そして、 \\[\\begin{align*}\ni &\\in \\arg\\max_{j\\in L\\cup R} |v_j|\n\\end{align*}\\] とする。 このとき、 \\[\\begin{align*}\n-v_i &= \\sum_{j\\in S}T_{i,j} v_j\\\\\n&\\le \\sum_{j\\in S}T_{i,j} |v_i|\\\\\n&= |v_i|\n\\end{align*}\\] という不等式が得られるが、\\(v_i\\le 0\\) のとき、この不等式が等号で満たされなければならない。 よって、\\(v_i\\le 0\\) のとき、\\(j\\in N(i)\\) について \\(v_j=-v_i\\) であることが必要である。 同様に、 \\[\\begin{align*}\n-v_i &= \\sum_{j\\in S}T_{i,j} v_j\\\\\n&\\ge -\\sum_{j\\in S}T_{i,j} |v_i|\\\\\n&= -|v_i|\n\\end{align*}\\] より、\\(v_i\\ge 0\\) のときも、\\(j\\in N(i)\\) について \\(v_j=-v_i\\) であることが必要である。 よって \\(j\\in L\\cup R\\) について \\[\\begin{align*}\nv_j&=\\begin{cases}\nv_i&\\text{if } \\{i,j\\}\\subseteq L\\text{ or } \\{i,j\\}\\subseteq R\\\\\n-v_i&\\text{otherwise}\n\\end{cases}\n\\end{align*}\\] である必要がある。 したがって、グラフの二部連結成分を \\(L_1\\cup R_1,\\dotsc,L_k\\cup R_k\\) とすると \\[\\begin{align*}\nv&\\in\\mathrm{span}(\\mathrm{1}_{L_1,R_1},\\dotsc,\\mathrm{1}_{L_k,R_k})\n\\end{align*}\\] である。 以上のことから「固有値 \\(-1\\) の重複度 \\(\\le\\) グラフの二部連結成分の個数」が示された。\n\nよって、グラフが連結していて二部グラフでない場合は遷移行列は固有値 \\(1\\) を一つだけ持ち、固有値 \\(-1\\) を持たない。 この場合は、初期分布 \\(\\pi\\) によらず、唯一の定常分布に収束する。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>マルコフ連鎖</span>"
    ]
  },
  {
    "objectID": "stationary.html",
    "href": "stationary.html",
    "title": "13  定常分布",
    "section": "",
    "text": "13.1 遷移グラフ\nマルコフ連鎖の推移行列 \\(T\\) について、 \\[\\begin{align*}\n\\mu T &= \\mu\n\\end{align*}\\] を満たす確率ベクトル(非負で成分の和が1) \\(\\mu\\) を定常分布と呼ぶのであった。 定常分布の存在、唯一性、極限分布との一致について考える。 参考文献 (Levin and Peres 2017)。\n有向辺 \\((u,v)\\in E\\) は頂点 \\(u\\) から頂点 \\(v\\) への有向辺と解釈することにする。\nマルコフ連鎖の定常分布や収束に関する議論をする際には遷移確率は 0 か正かということが問題になり、具体的な値は問題にならない。 したがって、定常分布が唯一であるための条件などは遷移グラフの性質として表すことができる。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>定常分布</span>"
    ]
  },
  {
    "objectID": "stationary.html#遷移グラフ",
    "href": "stationary.html#遷移グラフ",
    "title": "13  定常分布",
    "section": "",
    "text": "定義 13.1 (有向グラフ) 有限集合 \\(V\\) と集合 \\(E\\subseteq V\\times V\\) のペア \\(G=(V,\\,E)\\) を有向グラフという。 \\(V\\) の元を頂点、\\(E\\) の元を辺(有向辺)と呼ぶ。\n\n\n\n定義 13.2 (遷移グラフ) 有向グラフ \\(G=(V,\\,E)\\) が状態集合 \\(S\\) 上のマルコフ連鎖の遷移行列 \\(T\\) の遷移グラフ \\(\\defiff\\) \\[\\begin{align*}\nV&= S\\\\\nE&=\\left\\{(u,v)\\in V\\times V\\mid T_{u,v}&gt;0\\right\\}.\n\\end{align*}\\]",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>定常分布</span>"
    ]
  },
  {
    "objectID": "stationary.html#既約性と定常分布",
    "href": "stationary.html#既約性と定常分布",
    "title": "13  定常分布",
    "section": "13.2 既約性と定常分布",
    "text": "13.2 既約性と定常分布\n\n定義 13.3 (有向グラフのウォーク) 有向グラフ \\(G=(V,E)\\) の頂点列 \\[\\begin{align*}\n(v_0,v_1,\\dotsc,v_\\ell)\n\\end{align*}\\] で各 \\(i=0,1,\\dotsc,\\ell-1\\) について \\((v_i,\\,v_{i+1})\\in E\\) を満たすものを(\\(v_0\\) から \\(v_{\\ell}\\) への)ウォークという。 また、\\(\\ell\\) をウォークの長さという。\n\n頂点列 \\((v)\\) は長さ0のウォークであることに気をつけよう。 遷移グラフの定義より、任意の \\(u,v\\in S\\) について \\[\\begin{align*}\n&\\text{遷移グラフ上に $u$ から $v$ への長さ $\\ell$ のウォークが存在する} \\iff (T^\\ell)_{u,v} &gt; 0\\\\\n\\iff&\\Pr(X_\\ell=v\\mid X_0=u) &gt; 0\n\\end{align*}\\] である。\n\n定義 13.4 (順序関係) 推移行列 \\(T\\) を持つマルコフ連鎖の状態 \\(u,v\\in S\\) について \\(u\\le_T v\\) \\(\\defiff\\) その遷移グラフにおいて \\(u\\) から \\(v\\) へのウォークが存在する。 また、\\(u\\le_T v\\) かつ \\(v\\le_T u\\) のとき、\\(u\\sim_T v\\) とする。\n\nこの \\(\\le_T\\) は以下の前順序関係の公理を満たす。\n\n(反射律) \\(\\forall u\\in S,\\, u\\le_T u\\).\n(推移律) \\(\\forall u,v,w\\in S,\\, (u\\le_T v\\,\\land\\, v\\le_T w) \\implies u\\le_T w\\).\n\nまた、\\(\\sim_T\\) は以下の同値関係の公理を満たす。\n\n(反射律) \\(\\forall u\\in S,\\, u\\sim_T u\\).\n(対称律) \\(\\forall u,v\\in S,\\, u\\sim_T v\\implies v\\sim_T u\\).\n(推移律) \\(\\forall u,v,w\\in S,\\, (u\\sim_T v\\,\\land\\, v\\sim_T w) \\implies u\\sim_T w\\).\n\n\n定義 13.5 (マルコフ連鎖の既約性) マルコフ連鎖が既約である \\(\\defiff\\) 任意の \\(u,v\\in S\\) について \\(u\\sim_T v\\). \n\n有向グラフ \\(G\\) の任意の頂点 \\(u, v\\in V\\) について \\(u\\) から \\(v\\) へのウォークが存在するとき、\\(G\\) は強連結であるという。 よってマルコフ連鎖が既約 \\(\\iff\\) 遷移グラフが強連結である。\n\n\n\n\n\n\n\nirreduc_graph\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n\n\n\n5\n\n5\n\n\n\n2-&gt;5\n\n\n\n\n\n3-&gt;1\n\n\n\n\n\n4\n\n4\n\n\n\n3-&gt;4\n\n\n\n\n\n4-&gt;2\n\n\n\n\n\n4-&gt;4\n\n\n\n\n\n5-&gt;1\n\n\n\n\n\n\n 既約なマルコフ連鎖の遷移グラフ。任意の頂点 \\(u, v\\in V\\) について、\\(u\\) から \\(v\\) へのウォークが存在する。 \n\n\n\n\n補題 13.1 既約なマルコフ連鎖について \\(\\mathrm{Ker}(I-T)=\\mathrm{span}(1)\\) である。\n\n\n証明. 列ベクトル \\(v\\in\\mathbb{R}^n\\) を \\[\\begin{align*}\n(I-T)v = 0 &\\iff Tv = v\n\\end{align*}\\] を満たすものとする。 このとき、\\(i\\in\\arg\\max_{k\\in S} v_k\\) とすると \\[\\begin{align*}\nv_i &= \\sum_{j\\in S} T_{i,j} v_j\\\\\n&= \\sum_{j\\in S\\colon\\,(i,j)\\in E} T_{i,j} v_j\\\\\n&\\le \\sum_{j\\in S\\colon\\,(i,j)\\in E} T_{i,j} v_i\\\\\n&= v_i\n\\end{align*}\\] という不等式が得られる。 この不等号は等号でなくてはいけないので、 \\[\\begin{align*}\nv_j &= v_i\\qquad\\text{if } (i, j)\\in E\n\\end{align*}\\] である。 この議論を繰り返すと \\(i\\le_T j\\) である \\(j\\) について \\(v_j=v_i\\) である。 マルコフ連鎖が既約であることから、任意の \\(j\\in S\\) について \\(i\\le j\\) であり、\\(v = v_i 1\\) である。 したがって、\\(\\mathrm{Ker}(I-T)=\\mathrm{span}(1)\\) である。\n\nよって既約なマルコフ連鎖に対して定常分布は高々一つである。 実際には既約なマルコフ連鎖は一つの定常分布を持つ。\n\n\n\n\n\n\nノート証明の方針\n\n\n\n既約なマルコフ連鎖が定常分布を持つことの証明には大きく分類して3通りの方法がある。\n\nブラウワーの不動点定理。\n確率論的な議論(再帰時間)で明示的に定常状態を与える。定常状態は直感的に記述できる。\n線形代数的な議論(マルコフ連鎖木定理)で組合せ的な記述で明示的に定常状態を与える。\n\n以下では3番目の方針に従い、明示的な定常状態は与えず、その存在だけを示す。\n\n\n\n定理 13.1 既約なマルコフ連鎖は唯一の定常分布 \\(\\mu\\in\\mathbb{R}_{&gt;0}^n\\) を持つ。\n\n\n証明. マルコフ連鎖のラプラシアン行列を \\(\\Lambda \\coloneqq I-T\\) と定義する。 ラプラシアン行列の余因子行列を \\(\\mathrm{adj}(\\Lambda)\\) で表す(\\(\\mathrm{adj}(\\Lambda)\\) の \\((i,j)\\) 成分は \\((j,i)\\) 余因子である)。 余因子展開より \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)\\Lambda &= \\Lambda\\,\\mathrm{adj}(\\Lambda) = \\det(\\Lambda)I\n\\end{align*}\\] である。確率行列 \\(T\\) は固有値1を持つので、\\(\\det(\\Lambda)=0\\) である。 よって、 \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)\\Lambda &= \\Lambda\\,\\mathrm{adj}(\\Lambda) = O\n\\end{align*}\\] である。 まず、\\(\\Lambda\\,\\mathrm{adj}(\\Lambda)=O\\) と 補題 13.1 より \\(\\mathrm{adj}(\\Lambda)\\) の各列は \\(1\\) のスカラー倍である。よって、\\(\\mathrm{adj}(\\Lambda)\\) の行はすべて等しい。 次に、\\(\\mathrm{adj}(\\Lambda)\\Lambda=O\\) より、\\(\\mathrm{adj}(\\Lambda)\\) の行 \\(\\mu\\in\\mathbb{R}^n\\) は \\(\\mu\\Lambda=0\\) を満たす。 ここで、\\(\\mathrm{adj}(\\Lambda)\\) の行がすべて等しいことから \\[\\begin{align*}\n\\mu_i &= \\mathrm{adj}(\\Lambda)_{i,i}\\qquad\\forall i\\in S\n\\end{align*}\\] が成り立つ。 よって \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)_{i,i}&&gt;0\\qquad\\forall i\\in S\n\\end{align*}\\] を示せば十分である。 余因子行列の定義より、 \\[\\begin{align*}\n\\mathrm{adj}(\\Lambda)_{i,i}&= \\det(I - T^{(i)})\n\\end{align*}\\] である。 ここで、\\(T^{(i)}\\) は \\(T\\) の \\(i\\) 行目と \\(i\\) 列目を削除して得られる行列である。\n目標である \\(\\det(I-T^{(i)})&gt;0\\) を示すためには \\(\\rho(T^{(i)})&lt;1\\) を示せば十分である。\n\n\n\n\n\n\nノート\\(\\rho(A)&lt;1\\implies \\det(I-A)&gt;0\\) の代数的な証明\n\n\n\n実正方行列 \\(A\\) の固有値の多重集合を \\(\\mathrm{spec}(A)\\) で表すことにする。 実多項式の実数でない根はその複素共役とペアで現れることに注意すると、 \\[\\begin{align*}\n\\det(I-A)&= \\prod_{\\lambda\\in\\mathrm{spec}(A)} (1-\\lambda)\\\\\n&= \\prod_{\\lambda\\in\\mathrm{spec}(A)\\cap\\mathbb{R}} (1-\\lambda)\n\\cdot \\prod_{\\lambda\\in\\mathrm{spec}(A)\\setminus\\mathbb{R}} (1-\\lambda)\\\\\n&= \\prod_{\\lambda\\in\\mathrm{spec}(A)\\cap\\mathbb{R}} (1-\\lambda)\n\\cdot \\prod_{\\lambda\\in\\mathrm{spec}(A)\\setminus\\mathbb{R}} |1-\\lambda|\\\\\n\\end{align*}\\] よって \\(\\rho(A)&lt;1\\) であれば \\(\\det(I-A)&gt;0\\) である。\n\n\n\n\n\n\n\n\nノート\\(\\rho(A)&lt;1\\implies \\det(I-A)&gt;0\\) の解析的な証明\n\n\n\n実正方行列 \\(A\\) の特性多項式を \\[\\begin{align*}\np_A(x) &\\coloneqq \\det(xI - A)\n\\end{align*}\\] と定義する。 これはモニックな多項式であるため \\(x\\to+\\infty\\) で \\(p_A(x)\\to+\\infty\\) である。 よって \\(p_A(x)\\) が実根を持たないもしくは、すべての実根が 1 未満であれば \\(p_A(1)&gt;0\\) である。 特性多項式 \\(p_A\\) の根は \\(A\\) の固有値なので、\\(\\rho(A)&lt;1\\) であれば \\(p_A(1)=\\det(I-A)&gt;0\\) である。\n\n\nよって、\\(\\rho(T^{(i)})&lt;1\\) を示せば \\(\\mathrm{adj}(\\Lambda)_{i,i}=\\det(I-T^{(i)}) &gt; 0\\) がしたがう。\n\n\\(T^{(i)}\\) の絶対値最大の固有値を \\(\\lambda\\) とおき、対応する固有ベクトルを \\(v\\) とする。 このとき \\[\\begin{align*}\nT^{(i)}v &= \\lambda v\n\\end{align*}\\] が成り立つ。 \\(v\\) の絶対値最大の成分のインデックスを \\(j\\in S\\setminus\\{i\\}\\) とおく。 マルコフ連鎖が既約であることから、その遷移グラフ上で \\(j\\) から \\(i\\) へのウォークが存在する。 そのウォークの長さを \\(\\ell\\in\\mathbb{Z}_{\\ge 1}\\) とおく。 このとき、\\(S\\coloneqq T^{(i)\\ell}\\) とおくと、 \\[\\begin{align*}\nS v &= \\lambda^\\ell v\n\\end{align*}\\] である。 ここで、\\(S\\) の \\(j\\) 行目の和は \\[\\begin{align*}\n\\sum_{k\\in S\\setminus\\{i\\}} S_{j,k} &= \\sum_{k\\in S\\setminus\\{i\\}} \\Pr(X_1\\ne i,\\dotsc,X_{\\ell-1} \\ne i,X_\\ell=k\\mid X_0 = j)\\\\\n&= \\Pr(X_1\\ne i,\\dotsc,X_{\\ell} \\ne i\\mid X_0 = j)\\\\\n&\\le \\Pr(X_\\ell\\ne i\\mid X_0 = j) &lt; 1\n\\end{align*}\\] である。 よって、 \\[\\begin{align*}\n|\\lambda^\\ell v_j| &= |(S v)_j|\\\\\n&= \\left|\\sum_{k}S_{j,k} v_k\\right|\\\\\n&\\le \\sum_{k}S_{j,k} \\left|v_k\\right|\\\\\n&\\le \\sum_{k}S_{j,k} |v_j|\\\\\n&&lt; |v_j|\\\\\n\\end{align*}\\] である。\\(|v_j|&gt;0\\) より、\\(|\\lambda|&lt;1\\) である。 したがって、\\(\\rho(T^{(i)}) &lt; 1\\) であることが示された。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>定常分布</span>"
    ]
  },
  {
    "objectID": "stationary.html#一般のマルコフ連鎖の定常分布",
    "href": "stationary.html#一般のマルコフ連鎖の定常分布",
    "title": "13  定常分布",
    "section": "13.3 一般のマルコフ連鎖の定常分布",
    "text": "13.3 一般のマルコフ連鎖の定常分布\n次に既約とは限らない一般のマルコフ連鎖について考える。 マルコフ連鎖の状態集合 \\(S\\) を同値関係 \\(\\sim_T\\) で割った同値類 \\(S/\\sim_T\\) を考える。 そして、その同値類の遷移グラフを考える。\n\n定義 13.6 (同値類の遷移グラフ) 有向グラフ \\(G=(V,\\,E)\\) が状態集合 \\(S\\) 上のマルコフ連鎖の遷移行列 \\(T\\) の遷移グラフ \\(\\defiff\\) \\[\\begin{align*}\nV&= S/\\sim_T\\\\\nE&=\\left\\{(A,B)\\in V\\times V\\mid \\exists a\\in A, b\\in B\\quad T_{a,b}&gt;0,\\,A\\ne B\\right\\}.\n\\end{align*}\\]\n\nマルコフ連鎖の遷移グラフから同値類の遷移グラフは定まる。\n\n定義 13.7 (強連結成分と縮約グラフ) 有向グラフ \\(G=(V,E)\\) について、\\(V\\) 上の同値関係を \\(u\\sim v\\defiff \\text{$u$ と $v$ の間に両方向のパスがある}\\)と定義する。 この同値関係の同値類を \\(G\\) の強連結成分と呼ぶ。\n\\(G\\) の強連結成分を頂点に持つ縮約グラフ \\(G'=(V',E')\\) を \\[\\begin{align*}\nV'&=V/\\sim\\\\\nE'&=\\left\\{(A,B)\\in V'\\times V'\\mid \\exists a\\in A, \\exists b\\in B, (a,b)\\in E, A\\ne B\\right\\}\n\\end{align*}\\] と定義する。\n\n\n\n\n\n\n\n\ntgraph\n\n\n\n1\n\n1\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n\n\n\n7\n\n7\n\n\n\n1-&gt;7\n\n\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n\n\n\n4\n\n4\n\n\n\n2-&gt;4\n\n\n\n\n\n5\n\n5\n\n\n\n2-&gt;5\n\n\n\n\n\n3-&gt;1\n\n\n\n\n\n4-&gt;7\n\n\n\n\n\n6\n\n6\n\n\n\n5-&gt;6\n\n\n\n\n\n6-&gt;5\n\n\n\n\n\n6-&gt;7\n\n\n\n\n\n7-&gt;7\n\n\n\n\n\n\n 有向グラフの例。強連結ではない。 \n\n\n\n\n\n\n\n\n\n\ntgraph_equiv\n\n\n\na\n\n{1, 2, 3}\n\n\n\nb\n\n{4}\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\n{5, 6}\n\n\n\na-&gt;c\n\n\n\n\n\nd\n\n{7}\n\n\n\na-&gt;d\n\n\n\n\n\nb-&gt;d\n\n\n\n\n\nc-&gt;d\n\n\n\n\n\n\n 上の図の有向グラフの縮約グラフ。 \n\n\n\n\n定義 13.8 (有向非巡回グラフ) 有向グラフ \\(G\\) の長さ1以上のウォーク \\((v_0,\\dotsc,v_\\ell)\\) が\n\n\\(v_\\ell=v_0\\).\n\\(v_0,\\dotsc,v_{\\ell-1}\\) がすべて異なる。\n\nを満たすとき、サイクルという。 サイクルを持たない有向グラフを有向非巡回グラフ(directed acyclic graph; DAG)という。\n\n同値類の遷移グラフはDAGである。 \\(S\\) に対する前順序関係 \\(\\le_T\\) を同値類 \\(S/\\sim_T\\) についても同様に定義する。 このとき、\\(\\le_T\\) は\n\n(反対称律) \\(\\forall u,v\\in S/\\sim_T,\\,((u\\le_T v\\land v\\le_T u)\\implies u=v)\\)\n\nを満たし、半順序関係となる。\n\n\n\n\n\n\nノート\n\n\n\n逆に一般の有限半順序集合からDAGを作ることもできる(ハッセ図)。 任意のDAGが半順序集合のハッセ図になる訳ではない。\n\n\nDAGの頂点で出次数(外に出ていく有向辺の個数)が0のものをシンクという。 (有限サイズの)DAGは必ずシンクを一つ以上持つ。 一般のマルコフ連鎖の定常分布について、その同値類の遷移グラフを用いて考察する。 マルコフ連鎖の同値類の遷移グラフにおいてシンクに対応する同値類やそれに含まれる状態を再帰的であるという。\n\n補題 13.2 マルコフ連鎖の定常状態を \\(\\mu\\in\\mathbb{R}^n\\) とすると、再帰的でない状態 \\(s\\in S\\) について \\(\\mu(s)=0\\) である。\n\n\n証明. 定常分布 \\(\\mu\\in\\mathbb{R}^n\\) が再帰的でない状態 \\(s\\in S\\) について\\(\\mu(s)&gt;0\\) であると仮定する。 状態 \\(s\\) に対して再帰的な状態 \\(t\\in S\\) が存在して、\\(s\\le_T t\\) である。 この再帰的な状態 \\(t\\in S\\) が属する同値類を \\(C\\) とおくと、定常分布におけるこの同値類の確率の総和 \\[\\begin{align*}\n\\sum_{s\\in C} \\mu(s)\n\\end{align*}\\] もマルコフ連鎖の遷移によって不変である。 しかし、最初に確率1で\\(s\\)に入る状態からマルコフ連鎖をスタートしたとき、十分長いステップ(例えば状態数 \\(n\\))遷移すると必ず正の確率で同値類 \\(C\\) に遷移してしまう。 よって、再帰的な同値類 \\(C\\) の確率の総和は増加してしまう。 これは矛盾であるので、定常分布 \\(\\mu\\) において再帰的でない状態 \\(s\\in S\\) の確率は0である。\n\nよって、一般のマルコフ連鎖の定常状態を考えるときは、非再帰的な状態を削除してしまって考えてもよい。 このとき、再帰的な同値類 \\(C_1,C_2,\\dotsc,C_k\\) は互いに遷移できないので、独立に考えることができる。 それぞれの再帰的な同値類 \\(C_i\\) について、\\(C_i\\) だけに確率を持つ定常分布 \\(\\mu_i\\) が唯一存在する。 定常分布は凸集合に閉じているので、 \\[\\begin{align*}\n\\sum_{i=1}^k p_i \\mu_i\n\\end{align*}\\] も定常分布となる。 逆に \\(\\mu\\) が定常分布のとき、それを \\(C_i\\) に制限したものも定常ベクトルになる。よって、それは \\(\\mu_i\\) の非負倍に等しい。\n\n\n\n\nLevin, David A, and Yuval Peres. 2017. Markov Chains and Mixing Times. Vol. 107. American Mathematical Soc. https://pages.uoregon.edu/dlevin/MARKOV/.",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>定常分布</span>"
    ]
  },
  {
    "objectID": "ergodic.html",
    "href": "ergodic.html",
    "title": "14  エルゴード性",
    "section": "",
    "text": "14.1 定常分布への収束\nマルコフ連鎖が推移行列 \\(T\\) を持つとする。 ある確率ベクトル \\(\\mu\\in\\mathbb{R}_{\\ge 0}^S\\) が存在して、任意の確率ベクトル \\(\\pi\\in\\mathbb{R}_{\\ge0}^S\\) について、 \\[\\begin{align*}\n\\lim_{t\\to\\infty} \\pi T^t &= \\mu\n\\end{align*}\\] が成り立つ条件について考えよう。 このとき、 \\[\\begin{align*}\n\\mu &= \\lim_{t\\to\\infty} \\pi T^{t}\\\\\n&= \\lim_{t\\to\\infty} \\pi T^{t-1}T\\\\\n&= \\mu T\n\\end{align*}\\] より、収束先である \\(\\mu\\) は定常分布である。 初期分布が定常分布のとき、収束先は初期状態そのものである。 そのため、「初期分布によらない極限分布に収束 \\(\\implies\\) 定常分布は唯一」が成り立つ。 しかし、その逆は成り立たない。 例えば、推移行列が \\[\\begin{align*}\nT&=\n\\begin{bmatrix}\n0&1\\\\1&0\n\\end{bmatrix}\n\\end{align*}\\] のとき、既約なマルコフ連鎖なので定常分布は唯一である。 唯一の定常確率ベクトルは \\(\\begin{bmatrix}1/2&1/2\\end{bmatrix}\\) である。 しかし、初期分布が \\(\\begin{bmatrix}1&0\\end{bmatrix}\\) のとき、 \\(\\begin{bmatrix}1&0\\end{bmatrix}\\) と \\(\\begin{bmatrix}0&1\\end{bmatrix}\\) を交互に遷移するため、分布が収束しないことが分かる。初期分布が \\(\\begin{bmatrix}1/2+\\epsilon&1/2-\\epsilon\\end{bmatrix}\\) のように定常分布に近い場合でも収束しない。 このことは \\(T\\) の固有値が \\(\\pm1\\) であることから理解することができる。\n同様に \\[\\begin{align*}\nT&=\n\\begin{bmatrix}\n0&1&0\\\\0&0&1\\\\1&0&0\n\\end{bmatrix}\n\\end{align*}\\] の場合も既約であり、唯一の定常分布 \\(\\begin{bmatrix}1/3&1/3&1/3\\end{bmatrix}\\) を持つが、定常分布以外の分布からスタートすると収束しない。 この場合は固有値は \\(1, \\mathrm{e}^{\\frac{2\\pi}{3}},\\mathrm{e}^{\\frac{4\\pi}{3}}\\) である。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>エルゴード性</span>"
    ]
  },
  {
    "objectID": "ergodic.html#指数関数的な収束",
    "href": "ergodic.html#指数関数的な収束",
    "title": "14  エルゴード性",
    "section": "14.2 指数関数的な収束",
    "text": "14.2 指数関数的な収束\n行ベクトル \\(v\\in\\mathbb{R}^S\\) について\n\\[\\begin{align*}\n\\|v\\|_1 &\\coloneqq \\sum_{i\\in S} |v_i|\n\\end{align*}\\] と定義する。 確率ベクトル \\(\\pi,\\mu\\in\\mathbb{R}^S\\) について \\[\\begin{align*}\n\\frac12\\|\\pi-\\mu\\|_1\n\\end{align*}\\] は確率分布 \\(\\pi\\) と \\(\\mu\\) の全変動距離となる。\n一般に確率ベクトルとは限らないベクトル \\(\\rho\\in\\mathbb{R}^S\\) と確率行列 \\(T\\) について \\[\\begin{align*}\n\\|\\rho T\\|_1 &= \\sum_{i\\in S} \\left|(\\rho T)_i\\right|\\\\\n&= \\sum_{i\\in S} \\left|\\sum_{j\\in S}\\rho_j T_{j,i}\\right|\\\\\n&\\le \\sum_{i\\in S} \\sum_{j\\in S}\\left|\\rho_j\\right| T_{j,i}\\\\\n&= \\sum_{j\\in S}\\left|\\rho_j\\right| \\sum_{i\\in S} T_{j,i}\\\\\n&= \\sum_{j\\in S}\\left|\\rho_j\\right| = \\|\\rho\\|_1.\n\\end{align*}\\]\n\n定理 14.1 (Doeblin の定理) 推移行列 \\(T\\) を持つマルコフ連鎖について、ある \\(i_0\\in S\\) と \\(\\epsilon&gt;0\\) が存在して、 任意の \\(j\\in S\\) について \\(T_{j, i_0} \\ge \\epsilon\\) と仮定する。 このとき、唯一の定常分布 \\(\\mu\\in\\mathbb{R}^S\\) が存在し、任意の確率ベクトル \\(\\pi\\in\\mathbb{R}^S\\) について \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1\\le (1-\\epsilon)^n\\|\\pi-\\mu\\|_1\\le 2(1-\\epsilon)^n\\qquad \\forall n\\ge 0.\n\\end{align*}\\]\n\n\n証明. \n\n任意の(有限状態)マルコフ連鎖は定常分布を持つので、このマルコフ連鎖は定常分布 \\(\\mu\\in\\mathbb{R}^S\\) を持つ。\n推移行列 \\(T\\) が定理の条件を満たすとする。 まず最初にベクトル \\(\\rho\\in\\mathbb{R}^S\\) について、 \\[\\begin{align*}\n\\sum_{i\\in S} \\rho_i = 0 &\\implies \\|\\rho T\\|_1 \\le (1-\\epsilon)\\|\\rho\\|_1\n\\end{align*}\\] を示す。 任意の \\(\\sum_{i\\in S}\\rho_i = 0\\) を満たす \\(\\rho\\in\\mathbb{R}^S\\) と任意の \\(j\\in S\\) について \\[\\begin{align*}\n|(\\rho T)_j| &= \\left|\\sum_{k\\in S} \\rho_k T_{k,j}\\right|\\\\\n&= \\left|\\sum_{k\\in S} \\rho_{k} (T_{k,j}-\\epsilon\\delta_{j,i_0})\\right|\\\\\n&\\le \\sum_{k\\in S} \\left|\\rho_k\\right| (T_{k,j}-\\epsilon\\delta_{j,i_0})\\\\\n\\end{align*}\\] であるので \\[\\begin{align*}\n\\|\\rho T\\|_1 &= \\sum_{j\\in S} |(\\rho T)_j|\\\\\n&\\le \\sum_{j\\in S}\\sum_{k\\in S} \\left|\\rho_k\\right| (T_{k,j}-\\epsilon\\delta_{j,i_0})\\\\\n&= \\sum_{k\\in S} \\left|\\rho_k\\right|\\sum_{j\\in S} (T_{k,j}-\\epsilon\\delta_{j,i_0})\\\\\n&= \\sum_{k\\in S} \\left|\\rho_k\\right|(1 - \\epsilon)\\\\\n&= (1-\\epsilon)\\|\\rho\\|_1.\n\\end{align*}\\] よって \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1 &= \\|(\\pi-\\mu)T^n\\|_1\\\\\n&\\le (1-\\epsilon)\\|(\\pi-\\mu)T^{n-1}\\|_1\\\\\n&\\le (1-\\epsilon)^n\\|\\pi-\\mu\\|_1\\le 2(1-\\epsilon)^n\\qquad \\forall n\\ge 0.\n\\end{align*}\\]\n\n定理 14.1 の条件は厳しいので、直接は使いづらい。 しかし、簡単な考察によりこの条件を弱めることができる。\n\n補題 14.1 推移行列 \\(T\\) を持つマルコフ連鎖について、ある \\(M\\ge 1\\) と \\(\\epsilon&gt;0\\) が存在して、 \\[\\begin{align*}\n\\max_{j\\in S}\\min_{i\\in S} (T^M)_{i,j}\\ge \\epsilon\n\\end{align*}\\] を満たすと仮定する。 このとき、唯一の定常分布 \\(\\mu\\in\\mathbb{R}^S\\) が存在し、任意の確率ベクトル \\(\\pi\\in\\mathbb{R}^S\\) について \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1\\le (1-\\epsilon)^{\\lfloor n/M\\rfloor}\\|\\pi-\\mu\\|_1\\le 2(1-\\epsilon)^{\\lfloor n/M\\rfloor}\\qquad \\forall n\\ge 0.\n\\end{align*}\\]\n\n\n証明. 推移行列 \\(T\\) が補題の条件を満たすとする。 任意の \\(n\\ge 0\\) について、\\(M\\) で割った商と余りを \\(q\\in\\mathbb{Z}_{\\ge 0}\\) と \\(r\\in\\{0,1,\\dotsc,M-1\\}\\) とし、 \\(n = qM + r\\) を満たすものとする。 このとき、 \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1 &= \\|\\pi T^{qM+r}-\\mu\\|_1\\\\\n&= \\left\\|\\left(\\pi T^{qM}-\\mu\\right)T^r\\right\\|_1\\\\\n&\\le \\left\\|\\pi T^{qM}-\\mu\\right\\|_1\\\\\n&= \\|\\pi (T^{M})^q-\\mu\\|_1\\\\\n&\\le (1-\\epsilon)^{q}\\|\\pi -\\mu\\|_1\\le 2(1-\\epsilon)^{\\lfloor n/M\\rfloor}\\qquad \\forall n\\ge 0.\n\\end{align*}\\]",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>エルゴード性</span>"
    ]
  },
  {
    "objectID": "ergodic.html#周期",
    "href": "ergodic.html#周期",
    "title": "14  エルゴード性",
    "section": "14.3 周期",
    "text": "14.3 周期\n\n定義 14.1 (状態の周期) マルコフ連鎖の状態 \\(i\\in S\\) について \\[\\begin{align*}\nS(i) &\\coloneqq\\left\\{n\\ge 0\\mid (T^n)_{i,i}&gt;0\\right\\}\\\\\nd(i) &\\coloneqq\\mathrm{gcd}\\left(S(i)\\right)\n\\end{align*}\\] と定義する(\\(0\\) と \\(n\\ge0\\) の最大公約数は \\(n\\) とする)。\n\n\n\n\n\n\nノート最大公約数の単位元\n\n\n\n\\(a,b,c\\in\\mathbb{Z}_{\\ge 1}\\) について \\[\\begin{align*}\n\\mathrm{gcd}(\\mathrm{gcd}(a,b), c) =\n\\mathrm{gcd}(a,\\mathrm{gcd}(b,c))\n\\end{align*}\\] より、\\(\\mathrm{gcd}\\) は二項演算として結合法則を満たす。 そのため、\\((\\mathbb{Z}_{\\ge 1},\\,\\mathrm{gcd})\\) は可換な半群となるが、単位元があると便利である。 任意の \\(n\\in\\mathbb{Z}_{\\ge 0}\\) について \\[\\begin{align*}\n\\mathrm{gcd}(0,n)&=n\n\\end{align*}\\] と定義することにする。任意の \\(n\\in\\mathbb{Z}_{\\ge 1}\\) は 0 を割り切るので自然な定義である。 唯一 \\(\\mathrm{gcd}(0, 0) = 0\\) だけ少し違和感を感じるかもしれないが、こうすると色々な観点からとても綺麗な定義になる。 「最大」公約数の「最大」というのを半順序 \\(a\\preceq b \\defiff a \\mid b\\) の意味で「最大」だと思うと 0 は「最大」の数なので自然である。 また、任意の \\(a,b,d\\in\\mathbb{Z}_{\\ge 0}\\) について \\[\\begin{align*}\n\\mathrm{gcd}(a,\\,b) = d&\\iff\n\\left\\{sa + tb \\mid s, t\\in\\mathbb{Z}\\right\\} = d\\cdot \\mathbb{Z}\n\\end{align*}\\] という特徴付けも \\(a\\) や \\(b\\) が 0 の場合も含めて成り立つ。 また、ユークリッドの互除法のアルゴリズムも\n\ndef gcd(a, b):\n  if a == 0:\n    return b\n  else:\n    return gcd(b % a, a)\n\nと端的に書くことができる(ここで b % a は b を a で割った余りという意味)。 このように様々な意味で \\(\\mathrm{gcd}(0,\\,0)=0\\) は自然な定義である。 この定義から \\((\\mathbb{Z}_{\\ge 0},\\, \\mathrm{gcd})\\) は 0 を単位元とする可換なモノイドになる。\n空集合の和は和の単位元である 0だと定義するし 空集合の積は積の単位元である 1と定義する。 それと同様に 空集合の \\(\\mathrm{gcd}\\) は \\(\\mathrm{gcd}\\) の単位元である 0 と自然に定義することができる。\n\n\n\n戻ってこれない状態 \\(i\\in S\\) について、\\(S(i)=\\{0\\}\\) となるため \\(d(i)=0\\) である。 これを \\(d(i)=+\\infty\\) としている文献もある。 しかし、このような状態の周期を考えることがそもそもあまりないので、この違いは気にしないことにする。\n状態 \\(i\\in S\\) について \\(d(i)\\) を \\(i\\) の周期という。 周期が1である状態を非周期的であるという。 非周期的でない状態を周期的であるという。\n\n\n補題 14.2 (周期は不変量) マルコフ連鎖の状態 \\(i, j\\in S\\) について \\[\\begin{align*}\ni\\sim_T j&\\implies d(i) = d(j).\n\\end{align*}\\]\n\n\n証明. 状態 \\(i,j\\in S\\) が \\(i\\sim_T j\\) を満たすと仮定する。 このとき、ある \\(a,b\\in\\mathbb{Z}_{\\ge 0}\\) が存在して、 \\[\\begin{align*}\n(T^{a})_{i,j} &&gt; 0,&\n(T^{b})_{j,i} &&gt; 0\n\\end{align*}\\] が成り立つ。 このとき、\\(a+b\\in S(i)\\) である。 よって、任意の \\(c\\in S(j)\\) について \\[\\begin{align*}\n(T^{a+c+b})_{i,i} &\\ge (T^a)_{i, j} (T^c)_{j, j} (T^b)_{j, i} &gt; 0\n\\end{align*}\\] である。よって、\\(a+b+c\\in S(i)\\) である。 これらのことから、\\(d(i)\\) は \\(a+b\\) と \\(a+b+c\\) の両方を割り切るため、\\(d(i)\\) は \\(c\\) を割り切る。 よって、\\(d(i)\\) は \\(S(j)\\) のすべての要素を割り切るため、\\(S(j)\\) の公約数であり\\(d(j)\\) を割り切る。 同様に \\(d(j)\\) は \\(d(i)\\) を割り切るため、\\(d(i)=d(j)\\) である。\n\n\n補題 14.3 マルコフ連鎖の任意の状態 \\(i\\in S\\) について、ある \\(r_0\\in\\mathbb{Z}_{\\ge 0}\\) が存在して任意の \\(r\\ge r_0\\) について \\[\\begin{align*}\n(T^{d(i)r})_{i,i}&&gt;0.\n\\end{align*}\\]\n\n\n証明. 非負整数の集合 \\(S\\subseteq\\mathbb{Z}_{\\ge 0}\\) が \\[\\begin{align*}\na+b\\in S\\qquad \\forall a,b\\in S\n\\end{align*}\\] を満たすとき、集合 \\(S\\) は和について閉じているという。 集合 \\(S(i)\\) は和について閉じている。 よって、任意の和について閉じている集合 \\(S\\subseteq\\mathbb{Z}_{\\ge 0}\\) について、 ある \\(r_0\\in\\mathbb{Z}_{\\ge 0}\\) が存在して、 \\[\\begin{align*}\n\\mathrm{gcd}(S)\\cdot r\\in S\\qquad\\forall r\\ge r_0\n\\end{align*}\\] を証明すれば十分である。\n\n\n定理 14.2 推移行列 \\(T\\) を持つマルコフ連鎖について、ある非周期的な状態 \\(i_0\\in S\\) が存在して、任意の \\(j\\in S\\) について \\(j\\le_T i_0\\) と仮定する。 このとき、唯一の定常分布 \\(\\mu\\in\\mathbb{R}^S\\) とある \\(C\\in\\mathbb{R}_{&gt;0}\\) と \\(\\delta\\in(0,1)\\) が存在して、 任意の確率ベクトル \\(\\pi\\in\\mathbb{R}^S\\) について \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1&\\le C\\delta^n\n\\end{align*}\\]\n\n\n証明. 任意の \\(j\\in S\\) について \\(j\\le_T i_0\\) より、ある \\(m(j)\\in\\mathbb{Z}_{\\ge 0}\\) が存在して、 \\[\\begin{align*}\n(T^{m(j)})_{j,i_0}&&gt; 0\n\\end{align*}\\] である。 また、補題 14.3 より、ある \\(r_0\\in\\mathbb{Z}_{\\ge 0}\\) が存在して、任意の \\(r\\ge r_0\\) について \\[\\begin{align*}\n(T^{r})_{i_0,i_0}&gt;0\n\\end{align*}\\] である。 よって、任意の \\(j\\in S\\) と \\(r\\ge r_0+m(j)\\) について、 \\[\\begin{align*}\n(T^{r})_{j,i_0}&gt;0\n\\end{align*}\\] よって、\\(M=r_0+\\max_{j\\in S} m(j)\\) について、 \\[\\begin{align*}\n(T^{M})_{j,i_0}&gt;0\\qquad\\forall j\\in S\n\\end{align*}\\] である。 \\[\\begin{align*}\n\\epsilon &= \\min_{j\\in S} (T^{M})_{j,i_0}\n\\end{align*}\\] とおくと、補題 14.1 より、 \\[\\begin{align*}\n\\|\\pi T^n - \\mu\\|_1 &\\le 2(1-\\epsilon)^{\\lfloor n/M\\rfloor}\n\\le\\frac{2}{1-\\epsilon}\\left((1-\\epsilon)^{1/M}\\right)^n\n\\end{align*}\\] が成り立つ。よって \\[\\begin{align*}\nC &= \\frac{2}{1-\\epsilon}&\n\\delta &= (1-\\epsilon)^{1/M}\n\\end{align*}\\] とおくと定理が成り立つ。\n\n\n系 14.1 既約で非周期的なマルコフ連鎖について、 このとき、唯一の定常分布 \\(\\mu\\in\\mathbb{R}^S\\) とある \\(C\\in\\mathbb{R}_{&gt;0}\\) と \\(\\delta\\in(0,1)\\) が存在して、 任意の確率ベクトル \\(\\pi\\in\\mathbb{R}^S\\) について \\[\\begin{align*}\n\\|\\pi T^n-\\mu\\|_1&\\le C\\delta^n.\n\\end{align*}\\]\n\n既約で非周期的なマルコフ連鎖をエルゴード的であるという。",
    "crumbs": [
      "マルコフ連鎖",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>エルゴード性</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Levin, David A, and Yuval Peres. 2017. Markov Chains and Mixing\nTimes. Vol. 107. American Mathematical Soc. https://pages.uoregon.edu/dlevin/MARKOV/.",
    "crumbs": [
      "参考文献"
    ]
  }
]