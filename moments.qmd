# 期待値、分散、モーメント

## 期待値

::: {#def-exp}
## 期待値

離散型確率変数 $X$ の**期待値**は

\begin{align*}
\expt{X}
% &= \sum_{\omega \in \Omega} X(\omega) P(\{\omega\})\\
%&= \sum_{x\in \mathrm{Image}(X)} x P(\{\omega\mid X(\omega)=x\})\\
&\coloneqq \sum_{x\in \mathrm{Image}(X)} x \Pr(X=x)\\
&= \sum_{x\in \mathrm{Image}(X)} x f_X(x)
\end{align*}

と定義される。ここで、**右辺の和が絶対収束しない場合は(適当な順番で和を取って収束したとしても)期待値は定義されない**。

連続型確率変数 $X$ が確率密度関数 $f_X$ を持つとき、その**期待値**は

$$
\expt{X}\coloneqq \int_{-\infty}^\infty x f_X(x) \mathrm{d}x
$$

と定義される。ただし、広義積分で上記の積分が存在する場合でも
$$
\int_{-\infty}^\infty |x| f_X(x) \mathrm{d}x
$$
が存在しない場合は期待値は定義されない。
:::

連続型確率変数の期待値に関する様々な証明はルベーグ積分の知識を必要とするので本書では扱わない。
以下、証明はすべて離散確率変数の場合に限って与える。

::: {#lem-exp-pair}
確率変数 $X,\,Y$ について
\begin{align*}
\expt{X+Y}&=\expt{X}+\expt{Y}
\end{align*}
である。
また、$X$ と $Y$ が独立のとき、
\begin{align*}
\expt{XY}&=\expt{X}\,\expt{Y}
\end{align*}
である。
:::
::: {.proof}
\begin{align*}
\expt{X+Y} &= \sum_{z} z f_{X+Y}(z)\\
&= \sum_{z} z \sum_x f_{X,\,Y}(x, z-x)\\
&= \sum_{x,\,y} (x+y) f_{X,\,Y}(x, y)\qquad (y=z-x)\\
&= \sum_{x,\,y} xf_{X,\,Y}(x,y) + \sum_{y,\,y} yf_{X,\,Y}(x,y)\\
&= \sum_{x} xf_{X}(x) + \sum_{y} yf_{Y}(y)\\
&= \expt{X} + \expt{Y}.
\end{align*}
$X$ と $Y$ が独立のとき、
\begin{align*}
\expt{XY} &= \sum_{z} z f_{XY}(z)\\
&= \sum_{z} z \sum_{x\ne 0}f_{X,\,Y}(x,z/x)\\
&= \sum_{z} z \sum_{x\ne 0}f_{X}(x)f_Y(z/x)\\
&= \sum_{x\ne 0,\, y} xy f_{X}(x)f_Y(y)\qquad(y=z/x)\\
&= \sum_{x,\, y} xy f_{X}(x)f_Y(y)\\
&= \left(\sum_{x} xf_{X}(x)\right)\left(\sum_y yf_Y(y)\right)\\
&= \expt{X}\,\expt{Y}
\end{align*}
:::

::: {#lem-lotus}
### Law of the unconscious statistician (LOTUS)
任意の関数 $g\colon\mathbb{R}\to\mathbb{R}$ について、

1. $X$ が離散型確率変数のとき、
\begin{align*}
\expt{g(X)} &= \sum_{x} g(x) f_X(x).
\end{align*}
1. $X$ が連続型確率変数で確率密度関数を持つとき、
\begin{align*}
\expt{g(X)} &= \int_{-\infty}^\infty g(x) f_X(x) \mathrm{d}x.
\end{align*}
:::
::: {.proof}
$X$ を離散型確率変数とする。
\begin{align*}
\expt{g(X)}
%&= \sum_{x} x f_{g(X)}(x)\\
&= \sum_{x} x \Pr(g(X) = x)\\
&= \sum_{x} x \Pr(\{\omega\in\Omega\mid g(X(\omega)) = x\})\\
&= \sum_{x} x \Pr\left(\bigcup_{y\in\mathrm{Image}(X)\colon\, g(y) = x}\{\omega\in\Omega\mid X(\omega) = y\}\right)\\
&= \sum_{x}\sum_{y\in\mathrm{Image}(X)\colon\, g(y) = x} x \Pr\left(\{\omega\in\Omega\mid X(\omega) = y\}\right)\\
&= \sum_{y\in\mathrm{Image}(X)} g(y) f_X(y).
\end{align*}
<!--
$X$ が連続型確率変数で確率密度関数を持つとする。
\begin{align*}
\expt{g(X)}
&= \int_{-\infty}^\infty x f_{g(X)}(x)\mathrm{d}x\\
\end{align*}
-->
:::

::: {#prp-exp}
## 期待値の性質

任意の確率変数 $X$ と $a\in\mathbb{R}$ について
\begin{align*}
\expt{X+a} &= \expt{X}+a\\
\expt{aX} &= a\expt{X}.
\end{align*}
:::


::: {#thm-markov}
## マルコフの不等式

**非負**確率変数 $X$ と $a>0$ について
$$
\Pr(X\ge a)\le\frac{\expt{X}}{a}.
$$
:::
::: {.proof}
\begin{align*}
\expt{X} &= \sum_{x\in \mathrm{Image}(X)} f_X(x) x\\
&= \sum_{\mathrm{Image}(X)\colon\, x\ge a} f_X(x) x + \sum_{\mathrm{Image}(X)\colon\, x < a} f_X(x) x\\
&\ge \sum_{\mathrm{Image}(X)\colon\, x\ge a} f_X(x) x\qquad\qquad (\Pr(X\ge 0)=1)\\
&\ge \sum_{\mathrm{Image}(X)\colon\, x\ge a} f_X(x) a\\
&= \Pr(X\ge a) a.
\end{align*}
:::

<!--
::: {#exm-exp}
## 確率変数と期待値の例

非負整数に値を取る確率変数が

$$
\Pr(X = n) = \frac1{2^{n+1}}
$$

を満たすとき、

\begin{align*}
\expt{X} &= \sum_{n\ge 0}\frac{n}{2^{n+1}}\\
&= \left.\sum_{n\ge 0}\frac{n}{x^{n+1}}\right|_{x=2}\\
&= \left.\left(-\sum_{n\ge 0}\frac{1}{x^{n}}\right)'\right|_{x=2}\\
&= \left.\left(-\frac{1}{1-x^{-1}}\right)'\right|_{x=2}\\
\end{align*}
:::
-->

## 分散
::: {#def-var}
## 分散

確率変数 $X$ が期待値を持つとき、その**分散**を

$$
\var{X}\coloneqq  \expt{(X-\expt{X})^2}
$$

と定義する。
また、分散の平方根を**標準偏差**という。
:::

確率変数 $X$ が分散を持つとき、

\begin{align*}
\var{X} &= \expt{(X-\expt{X})^2}\\
&= \expt{X^2-2X\expt{X}+\expt{X}^2}\\
&= \expt{X^2}-2\expt{X}\expt{X}+\expt{X}^2\\
&= \expt{X^2}-\expt{X}^2
\end{align*}

である。
分散は定義より非負の値である。

::: {#prp-var}
## 分散の性質

任意の確率変数 $X$ と $a\in\mathbb{R}$ について
\begin{align*}
\var{X+a} &= \var{X}\\
\var{aX} &= a^2\var{X}.
\end{align*}
:::

分散は直感的には期待値からのはずれ具合を表す値である。

::: {#thm-chebyshev}
## チェビシェフの不等式

非負確率変数 $X$ と $a>0$ について
$$
\Pr(|X-\expt{X}|\ge a)\le\frac{\var{X}}{a^2}.
$$
:::
::: {.proof}
\begin{align*}
\Pr(|X-\expt{X}|\ge a)&= \Pr((X-\expt{X})^2\ge a^2)\\
&\le
\frac{\expt{(X-\expt{X})^2}}{a^2} = \frac{\var{X}}{a^2}.
\end{align*}
:::

::: {#lem-pairwise-var}
## 互いに独立な確率変数の和

確率変数 $X_1,\,X_2,\dotsc,X_n$ が互いに独立のとき

\begin{align*}
\var{X_1+\dotsb+X_n} &= \var{X_1} +\dotsb + \var{X_n}.
\end{align*}
:::
::: {.proof}
\begin{align*}
\var{X_1+\dotsb+X_n} &= \expt{\left((X_1+\dotsb+X_n) - \expt{X_1+\dotsb+X_n}\right)^2}\\
&= \expt{\left((X_1- \expt{X_1}) + \dotsb + (X_n-\expt{X_n})\right)^2}\\
&= \expt{\sum_i (X_i- \expt{X_i})^2  + 2\sum_{i < j}\left(X_i-\expt{X_i}\right)\left(X_j-\expt{X_j}\right)}\\
&= \sum_i \expt{(X_i- \expt{X_i})^2} +  2\sum_{i < j}\expt{\left(X_i-\expt{X_i}\right)\left(X_j-\expt{X_j}\right)}\\
&= \sum_i \expt{(X_i- \expt{X_i})^2} +  2\sum_{i < j}\expt{X_i-\expt{X_i}}\expt{X_j-\expt{X_j}}\\
&= \sum_i \expt{(X_i- \expt{X_i})^2}
=\sum_i \var{X_i}.
\end{align*}
:::

::: {#exm-pairwise}
互いに独立な確率変数 $X_1,\dotsc,X_n$ のそれぞれが確率変数 $X$ と同分布であるとし、
\begin{align*}
Y&\coloneqq \frac1{n} (X_1+\dotsb+X_n)
\end{align*}
と定義する。
このとき、
\begin{align*}
\expt{Y} &= \expt{X}\\
\var{Y} &= \frac1{n}\var{X}
\end{align*}
である。互いに独立な確率変数の平均を取ると期待値は変わらず、分散は小さくなる。
:::

::: {#exm-pairwise-exp}
独立確率変数 $X_1,\dotsc,X_n\sim\mathrm{Ber}(1/2)$ について
\begin{align*}
Y_S &\coloneqq \sum_{i\in S} X_i \mod 2\qquad\forall S\subseteq\{1,2,\dotsc,n\} 
\end{align*}
と定義すると、これらは互いに独立である。
また、$S\ne\varnothing$ について $Y_S\sim\mathrm{Ber}(1/2)$ である。
任意の関数 $g\colon\,\{0,1\}\to\mathbb{R}$ について、
\begin{align*}
Y&\coloneqq \frac1{2^n-1} \sum_{S\subseteq\{1,\dotsc,n\}\colon\, S\ne\varnothing} g(Y_S)
\end{align*}
と定義すると、$X\sim\mathrm{Ber}(1/2)$ について、
\begin{align*}
\expt{Y} &= \expt{g(X)}\\
\var{Y} &= \frac1{2^n-1}\var{g(X)}.
\end{align*}
:::

## 共分散
::: {#def-exp}
## 共分散

確率変数 $X,Y$ が期待値を持つとき、その**共分散**を

\begin{align*}
\cov{X}{Y} &\coloneqq \expt{(X-\expt{X})(Y-\expt{Y})}\\
&= \expt{XY}-\expt{X}\,\expt{Y}
\end{align*}

と定義する。
共分散がゼロである確率変数のペアを**無相関**であるという。
:::

定義より、$\cov{X}{X}=\var{X}$ であることが分かる。

::: {#prp-ind-cov}
独立確率変数 $X,Y$ は無相関である。
:::

逆に無相関であっても独立とは限らない。

::: {#exm-ind-cov}
確率変数 $X$ を
\begin{align*}
f_X(0)= f_X(+1)= f_X(-1)= \frac13
\end{align*}
を満たすものとし、$Y=X^2$ とする。
このとき、
\begin{align*}
\cov{X}{Y} &= \expt{XY} - \expt{X}\expt{Y}\\
&= \expt{X^3} - \expt{X}\expt{X^2}\\
&= \expt{X} - \expt{X}\expt{X^2}\\
&= \expt{X}(1-\expt{X^2})\\
&= 0
\end{align*}
なので、$X$ と $Y$ は無相関である。
一方で
\begin{align*}
f_{Y}(0) &= \frac13&
f_{Y}(1) &= \frac23\\
f_{X,\,Y}(0, 0) &= \frac13&
f_{X,\,Y}(1, 1) &= \frac13&
f_{X,\,Y}(-1, 1) &= \frac13&
\end{align*}
なので $X$ と $Y$ は独立ではない。
:::

共分散は正の値も負の値も取り得る。
大雑把に言うと、

* $X$ と $Y$ の共分散が正 $\iff$ $X$ が大きいとき $Y$ も大きい
* $X$ と $Y$ の共分散が負 $\iff$ $X$ が大きいとき $Y$ は小さい

という意味になる。


::: {#lem-var-sum}
任意の確率変数 $X_1,\dotsc,X_n$ について
\begin{align*}
\var{\sum_i X_i} &= \sum_i \var{X_i} + 2\sum_{i < j} \cov{X_i}{X_j}.
\end{align*}
:::
::: {.proof}
@lem-pairwise-var の証明参照。
:::

## モーメントとモーメント母関数

::: {#def-moment}
## モーメント

確率変数 $X$ と正の整数 $n\ge 1$ について、

$$
\mu_n(X)\coloneqq \expt{X^n}
$$

を $X$ の $n$ 次モーメントという。
:::

::: {#def-mg}
## モーメント母関数(積率母関数)

確率変数 $X$ について、

$$
M_X(t) \coloneqq \expt{\mathrm{e}^{tX}}\qquad t\in\mathbb{R}
$$

を $X$ の**モーメント母関数**という。
すべての $t\in\mathbb{R}$ で $M_X(t)$ が存在しない場合もある。
また、

$$
K_X(t) \coloneqq \log M_X(t)
$$
を $X$ の**キュムラント母関数**という。
:::

<!--
::: {#thm-convergence}

## ルベーグの優収束定理(概要)

関数列 $(f_n)_{n\ge 0}$ がある関数 $f$ に各点収束するとする。
また、ある関数 $g$ が存在し、

1. $|f_n(x)|\le g(x)$.
1. $\int_{-\infty}^\infty g(x)\mathrm{d}x<\infty$.

を満たすとする。
このとき、

$$
\lim_{n\to\infty} \int_{-\infty}^\infty f_n(x)\mathrm{d}x = \int_{-\infty}^\infty f(x)\mathrm{d}x.
$$

:::
-->

今後は以下の補題を認めることにする。証明にはルベーグ積分の知識が必要である。

::: {#lem-moment}

確率変数 $X$ について、ある $\epsilon >0$ が存在し、モーメント母関数 $M_X(t)$ が **$t\in(-\epsilon,\epsilon)$ で存在するとき**、

\begin{align*}
M_X(t) &=\sum_{n\ge 0}\frac{\expt{X^n}}{n!}t^n\qquad\forall t\in(-\epsilon,\epsilon)\\
\mu_n(X) &= \left.\frac{\mathrm{d}^n M_X(t)}{\mathrm{d} t^n}\right|_{t=0}.
\end{align*}
:::
::: {.proof}
(概要)
\begin{align*}
M_X(t) &= \expt{\mathrm{e}^{tX}}\\
&=\expt{\sum_{n\ge 0}\frac{(tX)^n}{n!}}\\
&=\sum_{n\ge 0}\expt{\frac{(tX)^n}{n!}}\qquad\text{\textsf{(この無限和と期待値の交換が定理の条件より正当化される)}}.
\end{align*}
:::

::: {#cor-cumulant}
確率変数 $X$ について、ある $\epsilon >0$ が存在し、モーメント母関数 $M_X(t)$ が **$t\in(-\epsilon,\epsilon)$ で存在するとき**、

\begin{align*}
\left.\frac{\mathrm{d} K_X(t)}{\mathrm{d} t}\right|_{t=0} &= \expt{X}\\
\left.\frac{\mathrm{d}^2 K_X(t)}{\mathrm{d} t^2}\right|_{t=0} &=  \var{X}.
\end{align*}
:::
::: {.proof}
\begin{align*}
\left.\frac{\mathrm{d} K_X(t)}{\mathrm{d} t}\right|_{t=0} &= \left.\frac{M'_X(t)}{M_X(t)}\right|_{t=0}=\expt{X}\\
\left.\frac{\mathrm{d}^2 K_X(t)}{\mathrm{d} t^2}\right|_{t=0} &= \left.\frac{M''_X(t)M_X(t) - M'_X(t)^2}{M_X(t)^2}\right|_{t=0} = M''_X(0) - M'_X(0)^2 = \var{X}.
\end{align*}
:::

また、重要度は低くなるが、

\begin{align*}
\left.\frac{\mathrm{d}^3 K_X(t)}{\mathrm{d} t^3}\right|_{t=0} &= \expt{(X - \expt{X})^3}\\
\left.\frac{\mathrm{d}^4 K_X(t)}{\mathrm{d} t^4}\right|_{t=0} &= \expt{(X - \expt{X})^4} - 3\var{X}^2
\end{align*}

が成り立つ。
一般に
\begin{align*}
\kappa_n(X) &\coloneqq \left.\frac{\mathrm{d}^n K_X(t)}{\mathrm{d} t^n}\right|_{t=0}
\end{align*}
を $X$ の **$n$ 次キュムラント** と呼ぶ。

::: {#thm-moment}
確率変数 $X$ と $Y$ のモーメント母関数が0を含む開区間 $(-\epsilon,\,\epsilon)$ で存在し、それらが等しいとき、$X$ の分布と $Y$ の分布は等しい。
:::
::: {.proof}
$\mathrm{Image}(X)$ と $\mathrm{Image}(Y)$ が有限の場合に限って証明を与える
(この場合はモーメント母関数は $\mathbb{R}$ 全体で存在するのだが)。
\begin{align*}
\{x_0,\dotsc,x_{N-1}\} &\coloneqq \mathrm{Image}(X) \cup \mathrm{Image}(Y)
\end{align*}
とする。
\begin{align*}
M_X(t) &= \sum_{k=0}^{N-1} f_X(x_k) \mathrm{e}^{tx_k}\\
M_Y(t) &= \sum_{k=0}^{N-1} f_Y(x_k) \mathrm{e}^{tx_k}
\end{align*}
なので、
\begin{align*}
0 = M_X(t) - M_Y(t) &= \sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \mathrm{e}^{tx_k}\qquad\forall t\in(-\epsilon,\epsilon)
\end{align*}
各 $k\in\{0,1,\dotsc,N-1\}$ について、$t_k\coloneqq \epsilon\frac{k}{N}$ とおくと、
\begin{align}
\sum_{k=0}^{N-1} (f_X(x_k)-f_Y(x_k)) \mathrm{e}^{t_\ell x_k}&=0\qquad\forall \ell\in\{0,1,\dotsc,N-1\}
\end{align}
である。
ここで、$N\times N$ 実行列 $V$ を
\begin{align*}
V_{\ell k} &= \mathrm{e}^{t_\ell x_k}
= \mathrm{e}^{\frac{\epsilon x_k}{N} \ell}\qquad\forall k,\ell\in\{0,1,\dotsc,N-1\}
\end{align*}
とおく。
この行列 $V$ は Vandermonde行列の転置であり正則なので、
\begin{align*}
&\sum_{k=0}^{N-1} V_{\ell k} g_k=0\qquad\forall \ell\in\{0,1,\dotsc,N-1\}\\
\implies& g_k = 0 \qquad\forall k\in\{0,1,\dotsc,N-1\}
\end{align*}
よって、
\begin{align*}
f_X(x_k) &= f_Y(x_k) \qquad\forall k\in\{0,1,\dotsc,N-1\}
\end{align*}
である。
:::

@thm-moment より、モーメント母関数には確率変数の分布のすべての情報が含まれていると言える。
ただし、モーメント母関数は原点まわりで存在しないこともあるので、分布の情報をすべて含む関数としては**特性関数**
\begin{align*}
\varphi_X(t) &\coloneqq \expt{\mathrm{e}^{itX}}\qquad\forall t\in\mathbb{R}
\end{align*}
の方が優秀である。
一方でモーメント母関数は確率の集中を示す文脈では中心的な役割を果たす。


<!--
## 特性関数
-->
